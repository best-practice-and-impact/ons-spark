

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Optimising Joins &#8212; Spark at the ONS</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/accessibility.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-95MGHSRD0S"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-95MGHSRD0S');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'raw-notebooks/join-concepts/join-concepts';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Spark at the ONS - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Spark at the ONS - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Spark overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../spark-overview/spark-start.html">Getting Started with Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-overview/when-to-use-spark.html">When To Use Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-overview/spark-session-guidance.html">Guidance on Spark Sessions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-overview/example-spark-sessions.html">Example Spark Sessions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-overview/spark-defaults.html">Configuration Hierarchy and <code class="docutils literal notranslate"><span class="pre">spark-defaults.conf</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-overview/data-types.html">Data Types in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-overview/creating-dataframes.html">Creating DataFrames Manually</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-overview/reading-and-writing-data-spark.html">Reading and Writing Data in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-overview/data-storage.html">Data Storage</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to PySpark</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../pyspark-intro/pyspark-intro.html">Introduction to PySpark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pyspark-intro/returning-data.html">Returning Data from Cluster to Driver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pyspark-intro/f-col.html">Reference columns by name: <code class="docutils literal notranslate"><span class="pre">F.col()</span></code></a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to sparklyr</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../sparklyr-intro/sparklyr-intro.html">Introduction to sparklyr</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sparklyr-intro/sparklyr-functions.html">Using Spark functions in sparklyr</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Spark functions</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../spark-functions/union-dataframes-with-different-columns.html">Union two DataFrames with different columns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-functions/padding.html">Add leading zeros with <code class="docutils literal notranslate"><span class="pre">lpad()</span></code></a></li>

<li class="toctree-l1"><a class="reference internal" href="../../spark-functions/sampling.html">Sampling: an overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-functions/pivot-tables.html">Pivot tables in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-functions/rounding.html">Rounding differences in Python, R and Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-functions/window-functions.html">Window Functions in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-functions/cross-joins.html">Cross Joins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-functions/arrays.html">Arrays Functions in PySpark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-functions/date-functions.html">Date functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-functions/writing-data.html">Writing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-functions/job-description-notebook.html">Set Spark Job Description</a></li>




<li class="toctree-l1"><a class="reference internal" href="../../spark-functions/median.html">Median in Spark</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Understanding and Optimising Spark</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/optimisation-tips.html">Ideas for optimising Spark code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/spark-application-and-ui.html">Spark Application and UI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/groups-not-loops.html">Groups not Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/shuffling.html">Shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/join-concepts.html">Optimising Joins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/salted-joins.html">Salted Joins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/partitions.html">Managing Partitions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/persistence.html">Persisting in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/cache.html">Caching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/checkpoint-staging.html">Checkpoints and Staging Tables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/garbage-collection.html">Garbage Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/df-order.html">Spark DataFrames Are Not Ordered</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-concepts/exercises.html">Exercises</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Analysis in Spark</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../spark-analysis/big-data-workflow.html">Big data workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-analysis/interpolation.html">Interpolation in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-analysis/logistic-regression.html">Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-analysis/visualisation.html">Spark and Visualisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-analysis/flags.html">Flags in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-analysis/bin-continuous-variable.html">Data binning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark-analysis/cramer_v.html">Calculating Cramér’s V from a Spark DataFrame</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Testing and Debugging</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../testing-debugging/spark-errors.html">Understanding and Handling Spark Errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../testing-debugging/unit-testing.html">Unit Testing in Spark</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ancillary Topics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ancillary-topics/module-imports.html">Naming Conflicts in Module Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ancillary-topics/pydoop.html">Pydoop: HDFS to pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ancillary-topics/creating-a-SQL-view-in-HDFS.html">Creating a SQL view in HDFS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ancillary-topics/pandas-udfs.html">Pandas UDFs</a></li>
</ul>

        </div>
    </nav></div>
            <div class="bd-sidebar__bottom">
                <!-- To handle the deprecated key -->
                
                <div class="navbar_extra_footer">
                <div>
        <p>Book version 2022.6</p>
    </div>
    
                </div>
                
            </div>
        </div>
        <div id="rtd-footer-container"></div>
    </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/best-practice-and-impact/ons-spark" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/best-practice-and-impact/ons-spark/issues/new?title=Issue%20on%20page%20%2Fraw-notebooks/join-concepts/join-concepts.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/raw-notebooks/join-concepts/join-concepts.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Optimising Joins</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-join-algorithms-in-spark">The Join Algorithms in Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shuffle-hash-join">Shuffle Hash Join</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sort-merge-join">Sort Merge Join</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sort-merge-join-example">Sort Merge Join Example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-sort-merge-join">Understanding Sort Merge Join</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#broadcast-join">Broadcast Join</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-using-a-broadcast-hint">Example: Using a Broadcast Hint</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#replacing-a-join-with-a-narrow-transformation">Replacing a join with a narrow transformation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-narrow-transformations">Example: Narrow Transformations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#when-to-use-each-method">When to use each method</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#salted-joins">Salted Joins</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-resources">Further Resources</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="optimising-joins">
<h1>Optimising Joins<a class="headerlink" href="#optimising-joins" title="Permalink to this heading">#</a></h1>
<p>Joining DataFrames is a common and often essential operation in Spark. However, joins are one of the more expensive operations in terms of processing time. This is because by default both source DataFrames are first sorted, which is a <em>wide transformation</em>, causing a <em>shuffle</em> (or <em>exchange</em>). As such, it is worth paying extra attention to where joins occur in the code and trying to figure out which method to use to make them more efficient.</p>
<p>This article describes the different join algorithms in Spark, explains how they work, when to use them, and shows examples of each. It also covers replacing joins entirely with narrow transformations, and gives a brief overview of <span class="xref myst"><em>salted joins</em></span>, that can be used when the data are skewed.</p>
<p>Before reading this article ensure that you understand how to join two DataFrames in Spark. Knowledge of <span class="xref myst">shuffles</span> and the difference between wide and narrow transformations will also help understanding of why some methods are faster than others, although not mandatory. Useful resources on this include the <a class="reference external" href="https://databricks.com/glossary/what-are-transformations">DataBricks Transformations definition</a>, and the <span class="xref myst">Spark Application and UI</span>, <span class="xref myst">Shuffling</span> and <span class="xref myst">Partitions</span> articles in this book.</p>
<p>It is important to note that in this notebook when we talk about different joins and the way they are processed we are not talking about left, right, inner or outer joins, but how it is processed on the cluster. The result of the join will always be the same, regardless of which of the algorithms described in this article is used.</p>
<section id="the-join-algorithms-in-spark">
<h2>The Join Algorithms in Spark<a class="headerlink" href="#the-join-algorithms-in-spark" title="Permalink to this heading">#</a></h2>
<p>You do not need to know how joins work when writing Spark code, but you can make them more efficient by understanding that there are different ways for them to be processed and coding appropriately. These are:</p>
<ul class="simple">
<li><p>Shuffle Hash Join</p></li>
<li><p>Sort Merge Join</p></li>
<li><p>Broadcast Join</p></li>
<li><p>Other Methods</p></li>
</ul>
<p>We will look at each in more detail, get a better idea of how they are processed by looking at the Spark UI. We will then compare them and give the advantages and disadvantages of using each.</p>
</section>
<section id="shuffle-hash-join">
<h2>Shuffle Hash Join<a class="headerlink" href="#shuffle-hash-join" title="Permalink to this heading">#</a></h2>
<p>In the development of Spark, the shuffle hash join was the original join implementation.</p>
<p>This consists of two stages: <em>shuffle</em> and <em>hash</em>. First a <em>shuffle</em>, where data with the same keys from both DataFrames are moved to the same executors. Once all the data are on the relevant executors, they are joined using the hash join algorithm. This involves building a hash table in memory and may fail for some larger joins.</p>
<p>Shuffle hash joins will not be explored further as they have been superseded by sort merge join, which is similar apart from the processing stage.</p>
</section>
<section id="sort-merge-join">
<h2>Sort Merge Join<a class="headerlink" href="#sort-merge-join" title="Permalink to this heading">#</a></h2>
<p>This is now the default method of joining two DataFrames in Spark.</p>
<p>It consists of two key stages, as suggested by the name: <em>sort</em> and <em>merge</em>.</p>
<p>First of all, the data in each DataFrame will be sorted. A sort operation requires a shuffle on each DataFrame. This will also ensure that all the same key values are on the same partition. This also means that the join can be done in parallel on each partition, although it can potentially be a problem if your data are skewed (in which case a <em>salted join</em> may be useful).</p>
<p>Now that both DataFrames are ordered, it is easy to iterate over each row in the DataFrames and see if they have a matching key; if they do, they can be returned as part of the resulting DataFrame. In most circumstances this will be more efficient than the shuffle hash join.</p>
<p>This diagram should help explain this visually:</p>
<figure class="align-default" id="sortmergediagram">
<a class="reference internal image-reference" href="raw-notebooks/images/sort_merge_join.png"><img alt="Diagram showing two partitioned DataFrames being sorted before being merged" src="raw-notebooks/images/sort_merge_join.png" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">Sort Merge join</span><a class="headerlink" href="#sortmergediagram" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Both sort merge joins and shuffle hash joins use a shuffle; the difference is in the processing stage, where the former uses a searching algorithm and the latter uses a hash table.</p>
<section id="sort-merge-join-example">
<h3>Sort Merge Join Example<a class="headerlink" href="#sort-merge-join-example" title="Permalink to this heading">#</a></h3>
<p>Let us see an example of a sort merge join and then look at the plan and the Spark UI. The example uses the Animal Rescue (as parquet) and Population (as parquet) datasets, left joining on the <code class="docutils literal notranslate"><span class="pre">postcode_district</span></code>. Note that we are disabling automatic broadcast joins by setting <code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code> to <code class="docutils literal notranslate"><span class="pre">-1</span></code>; broadcast joins are covered in the next section. First, start a Spark session, read the data and select and rename the relevant columns:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">yaml</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span><span class="p">,</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span><span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[2]&quot;</span><span class="p">)</span>
         <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;joins&quot;</span><span class="p">)</span>
         <span class="c1"># Disable broadcast join by default</span>
         <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.sql.autoBroadcastJoinThreshold&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
         <span class="o">.</span><span class="n">getOrCreate</span><span class="p">())</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;../../../config.yaml&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    
<span class="n">rescue_path</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;rescue_path&quot;</span><span class="p">]</span>
<span class="n">population_path</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;population_path&quot;</span><span class="p">]</span>

<span class="n">rescue</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">rescue_path</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="s2">&quot;incident_number&quot;</span><span class="p">,</span> <span class="s2">&quot;cal_year&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;animal_group&quot;</span><span class="p">,</span> <span class="s2">&quot;postcode_district&quot;</span><span class="p">)</span>

<span class="n">population</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">population_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">sparklyr</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>

<span class="n">joins_config</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_config</span><span class="p">()</span>
<span class="c1"># Disable broadcast join by default</span>
<span class="n">joins_config</span><span class="o">$</span><span class="n">spark.sql.autoBroadcastJoinThreshold</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">-1</span>

<span class="n">sc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_connect</span><span class="p">(</span>
<span class="w">    </span><span class="n">master</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;local[2]&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">app_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;joins&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">joins_config</span><span class="p">)</span>

<span class="n">config</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">yaml</span><span class="o">::</span><span class="nf">yaml.load_file</span><span class="p">(</span><span class="s">&quot;ons-spark/config.yaml&quot;</span><span class="p">)</span>

<span class="n">rescue</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_read_parquet</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span><span class="w"> </span><span class="n">config</span><span class="o">$</span><span class="n">rescue_path</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="n">incident_number</span><span class="p">,</span>
<span class="w">                     </span><span class="n">cal_year</span><span class="p">,</span>
<span class="w">                     </span><span class="n">animal_group</span><span class="p">,</span>
<span class="w">                     </span><span class="n">postcode_district</span><span class="p">,</span>
<span class="w">                     </span><span class="n">origin_of_call</span><span class="p">)</span>

<span class="n">population</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_read_parquet</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span><span class="w"> </span><span class="n">config</span><span class="o">$</span><span class="n">population_path</span><span class="p">)</span><span class="w">          </span>
</pre></div>
</div>
<p>Preview both DataFrames; we can see the desired join column, <code class="docutils literal notranslate"><span class="pre">postcode_district</span></code>, is present and contains data in a standard postcode format:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">population</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+---------------+--------+------------+-----------------+
|incident_number|cal_year|animal_group|postcode_district|
+---------------+--------+------------+-----------------+
|       80771131|    2013|         Cat|              IG1|
|      141817141|    2014|       Horse|              DA5|
|143166-22102016|    2016|        Bird|             SW20|
|       43051141|    2014|         Cat|               E6|
|        9393131|    2013|         Dog|              UB4|
+---------------+--------+------------+-----------------+
only showing top 5 rows

+-----------------+----------+
|postcode_district|population|
+-----------------+----------+
|              DH7|     41076|
|              NW3|     52376|
|              NR4|     22331|
|             SO31|     44742|
|             CT18|     14357|
+-----------------+----------+
only showing top 5 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">print</span><span class="p">()</span>
<span class="w">    </span>
<span class="n">population</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>We can now join these on <code class="docutils literal notranslate"><span class="pre">PostcodeDistrict</span></code>, using <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.join.html"><code class="docutils literal notranslate"><span class="pre">.join()</span></code></a> with <code class="docutils literal notranslate"><span class="pre">how=&quot;left&quot;</span></code> in PySpark or <a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/join.tbl_spark.html"><code class="docutils literal notranslate"><span class="pre">left_join()</span></code></a> in sparklyr, then preview:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">rescue</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">population</span><span class="p">,</span>
        <span class="n">on</span><span class="o">=</span><span class="s2">&quot;postcode_district&quot;</span><span class="p">,</span>
        <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">rescue_with_pop</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+-----------------+---------------+--------+------------+----------+
|postcode_district|incident_number|cal_year|animal_group|population|
+-----------------+---------------+--------+------------+----------+
|             SE17|      131625111|    2011|         Cat|     32866|
|             SE17|       35594151|    2015|         Cat|     32866|
|             SE17|       64851111|    2011|         Dog|     32866|
|             SE17|141546-05102018|    2018|         Fox|     32866|
|             SE17|       18990151|    2015|         Cat|     32866|
+-----------------+---------------+--------+------------+----------+
only showing top 5 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rescue</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">left_join</span><span class="p">(</span><span class="n">population</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="o">=</span><span class="s">&quot;postcode_district&quot;</span><span class="p">)</span>

<span class="n">rescue_with_pop</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>Note that the order of the DataFrame has not been preserved and that this preview has only given us rows with idential <code class="docutils literal notranslate"><span class="pre">PostcodeDistrict</span></code> values. This is due to two Spark concepts: lazy evaluation and the sort merge join algorithm. As the action only requires five rows to be returned, Spark can get all these from the first partition rather than having to return data from multiple partitions, ensuring that the job is completed faster. The sort merge join algorithm has sorted the DataFrame by the hashed join key, and put all these values in the first partition, and so these are the values that are returned. See the article on <span class="xref myst">partitions</span> for more information.</p>
<p>We know the result of the join, but to see how Spark actually processed the join we need to look at the <em>plan</em>. Remember that Spark has the concept of <em>lazy evaluation</em>, in which rather than process code line-by-line like in a pandas or base R DataFrame, we instead create a <em>plan</em> which gets executed on the cluster in one go when an <em>action</em> is called. We can see this plan with <code class="docutils literal notranslate"><span class="pre">explain()</span></code>, a <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.explain.html">DataFrame method</a> in PySpark and <a class="reference external" href="https://dplyr.tidyverse.org/reference/explain.html">dplyr function</a> in sparklyr.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>== Physical Plan ==
*(5) Project [postcode_district#770, incident_number#749, cal_year#751, animal_group#759, population#806L]
+- SortMergeJoin [postcode_district#770], [postcode_district#805], LeftOuter
   :- *(2) Sort [postcode_district#770 ASC NULLS FIRST], false, 0
   :  +- Exchange hashpartitioning(postcode_district#770, 200)
   :     +- *(1) FileScan parquet [incident_number#749,cal_year#751,animal_group#759,postcode_district#770] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/animal_rescue.parquet], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;incident_number:string,cal_year:int,animal_group:string,postcode_district:string&gt;
   +- *(4) Sort [postcode_district#805 ASC NULLS FIRST], false, 0
      +- Exchange hashpartitioning(postcode_district#805, 200)
         +- *(3) Project [postcode_district#805, population#806L]
            +- *(3) Filter isnotnull(postcode_district#805)
               +- *(3) FileScan parquet [postcode_district#805,population#806L] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/population.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(postcode_district)], ReadSchema: struct&lt;postcode_district:string,population:bigint&gt;
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">dplyr</span><span class="o">::</span><span class="nf">explain</span><span class="p">()</span>
</pre></div>
</div>
<p>Spark plans can be tricky to read if you are not familiar with them but we can see some key terms being used:</p>
<ul class="simple">
<li><p>We are doing a <code class="docutils literal notranslate"><span class="pre">SortMergeJoin</span></code>, of type <code class="docutils literal notranslate"><span class="pre">LeftOuter</span></code></p></li>
<li><p>Before that, each DataFrame is being sorted and shuffled; the name for this on the plan is an <code class="docutils literal notranslate"><span class="pre">Exchange</span></code>.</p></li>
<li><p>The data are being read with <code class="docutils literal notranslate"><span class="pre">FileScan</span> <span class="pre">parquet</span></code></p></li>
<li><p>As this was a left join, we do not need to return any values from <code class="docutils literal notranslate"><span class="pre">population</span></code> where <code class="docutils literal notranslate"><span class="pre">OutwardCode</span></code> is <code class="docutils literal notranslate"><span class="pre">null</span></code>, so Spark is filtering these out at source with <code class="docutils literal notranslate"><span class="pre">PushedFilters:</span> <span class="pre">[IsNotNull(OutwardCode)]</span></code>.</p></li>
</ul>
<p>We can view the plan visually with the Spark UI on the SQL tab. The Spark UI for a local session is <a class="reference external" href="http://localhost:4040/jobs">http://localhost:4040/jobs</a>.</p>
<p>See the <span class="xref myst">Spark Application and UI</span> article for details on how to access the Spark UI, and the <span class="xref myst">Persisting</span> article for more details on interpreting the information in the SQL tab.</p>
<figure class="align-default" id="sortmergedag">
<a class="reference internal image-reference" href="raw-notebooks/images/sort_merge_join_ui.png"><img alt="SQL DAG in Spark UI for sort merge join, showing an exchange for both DataFrames" src="raw-notebooks/images/sort_merge_join_ui.png" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">SQL DAG for a SortMergeJoin</span><a class="headerlink" href="#sortmergedag" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>This diagram has the same information as the <code class="docutils literal notranslate"><span class="pre">explain()</span></code>, just presented in a much nicer way. Again, we can see that there is an <strong>Exchange</strong> for each DataFrame, before the <strong>SortMergeJoin</strong>, and a <strong>Filter</strong> when reading the parquet.</p>
</section>
<section id="understanding-sort-merge-join">
<h3>Understanding Sort Merge Join<a class="headerlink" href="#understanding-sort-merge-join" title="Permalink to this heading">#</a></h3>
<p>The sort merge join involves two <strong>Exchanges</strong> (also called <em>shuffles</em>), one for the sorting of each source DataFrame (see the Shuffles article for a full discussion of this topic). Spark is most powerful when it can process data in parallel (<em>narrow transformations</em>), and sorting is instead a <em>wide transformation</em>, causing a <em>shuffle</em>, meaning that a sort merge join can take significant time to process, depending on the size and composition of your data. There is a full discussion in the when to use each join method section.</p>
<p>The sort merge join is the <em>default</em> join although not always chosen automatically; the next section on <em>broadcast joins</em> explains this further.</p>
</section>
</section>
<section id="broadcast-join">
<h2>Broadcast Join<a class="headerlink" href="#broadcast-join" title="Permalink to this heading">#</a></h2>
<p>The other common method is the broadcast join. This can be used when you are joining a small DataFrame to a large one. The smaller DataFrame is copied to every node on the cluster and then a traditional hash join is performed. This avoids the need for the sorting step that exists in the sort merge join, and therefore the expensive shuffles.</p>
<p>Broadcast joins are suitable when you are joining a small DataFrame to a larger one. As one DataFrame is pushed to several places, this may actually be too slow or impossible if you are joining two large DataFrames.</p>
<p>The diagram below shows how a broadcast join works visually:</p>
<figure class="align-default" id="broadcostjoindiagram">
<a class="reference internal image-reference" href="raw-notebooks/images/broadcast_join.png"><img alt="Diagram showing a small DataFrame being copied, or broadcast, to all partitions of a larger DataFrame" src="raw-notebooks/images/broadcast_join.png" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">Diagram of broadcast join</span><a class="headerlink" href="#broadcostjoindiagram" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>There are two ways to trigger a broadcast join:</p>
<ol class="arabic simple">
<li><p>Use the broadcast hint: <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.broadcast.html"><code class="docutils literal notranslate"><span class="pre">F.broadcast()</span></code></a> in PySpark or <a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/sdf_broadcast.html"><code class="docutils literal notranslate"><span class="pre">sdf_broadcast()</span></code></a> in sparklyr</p></li>
<li><p>Spark will use a broadcast join by default if the size of the DataFrame to be broadcast is known and smaller 10MB; this value can be changed with the <a class="reference external" href="https://spark.apache.org/docs/latest/sql-performance-tuning.html"><code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code></a> configuration setting.</p></li>
</ol>
<section id="example-using-a-broadcast-hint">
<h3>Example: Using a Broadcast Hint<a class="headerlink" href="#example-using-a-broadcast-hint" title="Permalink to this heading">#</a></h3>
<p>We can use the same source DataFrames as the sort merge join example, <code class="docutils literal notranslate"><span class="pre">rescue</span></code> and <code class="docutils literal notranslate"><span class="pre">population</span></code>. To perform a broadcast join, we just add the broadcast join hint <code class="docutils literal notranslate"><span class="pre">F.broadcast()</span></code>/<code class="docutils literal notranslate"><span class="pre">sdf_broadcast()</span></code> around <code class="docutils literal notranslate"><span class="pre">population</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_broadcast</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">rescue</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">F</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">population</span><span class="p">),</span>
        <span class="n">on</span><span class="o">=</span><span class="s2">&quot;postcode_district&quot;</span><span class="p">,</span>
        <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">rescue_with_pop_broadcast</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+-----------------+---------------+--------+------------+----------+
|postcode_district|incident_number|cal_year|animal_group|population|
+-----------------+---------------+--------+------------+----------+
|              IG1|       80771131|    2013|         Cat|     63585|
|              DA5|      141817141|    2014|       Horse|     20525|
|             SW20|143166-22102016|    2016|        Bird|     28423|
|               E6|       43051141|    2014|         Cat|     78955|
|              UB4|        9393131|    2013|         Dog|     39573|
+-----------------+---------------+--------+------------+----------+
only showing top 5 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_broadcast</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rescue</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">left_join</span><span class="p">(</span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_broadcast</span><span class="p">(</span><span class="n">population</span><span class="p">),</span><span class="w"> </span><span class="n">by</span><span class="o">=</span><span class="s">&quot;postcode_district&quot;</span><span class="p">)</span>

<span class="n">rescue_with_pop_broadcast</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>Unlike the first example, the <code class="docutils literal notranslate"><span class="pre">postcode_district</span></code> values are not identical. The DataFrame has not needed to be shuffled and so the same <code class="docutils literal notranslate"><span class="pre">PostcodeDistrict</span></code> values may be on different partitions.</p>
<p><code class="docutils literal notranslate"><span class="pre">explain()</span></code> will confirm that a broadcast join was used:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_broadcast</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>== Physical Plan ==
*(2) Project [postcode_district#770, incident_number#749, cal_year#751, animal_group#759, population#806L]
+- *(2) BroadcastHashJoin [postcode_district#770], [postcode_district#805], LeftOuter, BuildRight
   :- *(2) FileScan parquet [incident_number#749,cal_year#751,animal_group#759,postcode_district#770] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/animal_rescue.parquet], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;incident_number:string,cal_year:int,animal_group:string,postcode_district:string&gt;
   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))
      +- *(1) Project [postcode_district#805, population#806L]
         +- *(1) Filter isnotnull(postcode_district#805)
            +- *(1) FileScan parquet [postcode_district#805,population#806L] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/population.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(postcode_district)], ReadSchema: struct&lt;postcode_district:string,population:bigint&gt;
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_broadcast</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">dplyr</span><span class="o">::</span><span class="nf">explain</span><span class="p">()</span>
</pre></div>
</div>
<p>We can see that we are now using a <strong>BroadcastHashJoin</strong>. Let us look at the UI again:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span><span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[2]&quot;</span><span class="p">)</span>
         <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;joins&quot;</span><span class="p">)</span>
          <span class="c1"># Automatically broadcast DataFrames less than 10MB</span>
          <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.sql.autoBroadcastJoinThreshold&quot;</span><span class="p">,</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
          <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_disconnect</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>

<span class="n">joins_config</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_config</span><span class="p">()</span>
<span class="c1"># Automatically broadcast DataFrames less than 10MB</span>
<span class="n">joins_config</span><span class="o">$</span><span class="n">spark.sql.autoBroadcastJoinThreshold</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">1024</span><span class="o">**</span><span class="m">2</span>

<span class="n">sc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_connect</span><span class="p">(</span>
<span class="w">    </span><span class="n">master</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;local[2]&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">app_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;joins&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">joins_config</span><span class="p">)</span>
</pre></div>
</div>
<p>As this is a new Spark session our old DataFrames no longer exist, so we need to create them again:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">rescue_path</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="s2">&quot;incident_number&quot;</span><span class="p">,</span> <span class="s2">&quot;cal_year&quot;</span><span class="p">,</span> <span class="s2">&quot;animal_group&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;postcode_district&quot;</span><span class="p">,</span> <span class="s2">&quot;origin_of_call&quot;</span><span class="p">)</span>

<span class="n">population</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">population_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_read_parquet</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span><span class="w"> </span><span class="n">config</span><span class="o">$</span><span class="n">rescue_path</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="n">incident_number</span><span class="p">,</span>
<span class="w">                     </span><span class="n">cal_year</span><span class="p">,</span>
<span class="w">                     </span><span class="n">animal_group</span><span class="p">,</span>
<span class="w">                     </span><span class="n">postcode_district</span><span class="p">,</span>
<span class="w">                     </span><span class="n">origin_of_call</span><span class="p">)</span>


<span class="n">population</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_read_parquet</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span><span class="w"> </span><span class="n">config</span><span class="o">$</span><span class="n">population_path</span><span class="p">)</span><span class="w"> </span>
</pre></div>
</div>
<p>Now try the join. Note that this is identical code to in the sort merge join example, but it will be automatically broadcast as the second DataFrame is below 10MB.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_auto_broadcast</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">rescue</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">population</span><span class="p">,</span>
        <span class="n">on</span><span class="o">=</span><span class="s2">&quot;postcode_district&quot;</span><span class="p">,</span>
        <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">rescue_with_pop_auto_broadcast</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+-----------------+---------------+--------+------------+------------------+----------+
|postcode_district|incident_number|cal_year|animal_group|    origin_of_call|population|
+-----------------+---------------+--------+------------+------------------+----------+
|              IG1|       80771131|    2013|         Cat|   Person (mobile)|     63585|
|              DA5|      141817141|    2014|       Horse|   Person (mobile)|     20525|
|             SW20|143166-22102016|    2016|        Bird|   Person (mobile)|     28423|
|               E6|       43051141|    2014|         Cat|Person (land line)|     78955|
|              UB4|        9393131|    2013|         Dog|   Person (mobile)|     39573|
+-----------------+---------------+--------+------------+------------------+----------+
only showing top 5 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_auto_broadcast</span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rescue</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">left_join</span><span class="p">(</span><span class="n">population</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="o">=</span><span class="s">&quot;postcode_district&quot;</span><span class="p">)</span>

<span class="n">rescue_with_pop_auto_broadcast</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>This can be confirmed with <code class="docutils literal notranslate"><span class="pre">explain()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_auto_broadcast</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>== Physical Plan ==
*(2) Project [postcode_district#892, incident_number#871, cal_year#873, animal_group#881, origin_of_call#882, population#929L]
+- *(2) BroadcastHashJoin [postcode_district#892], [postcode_district#928], LeftOuter, BuildRight
   :- *(2) Project [incident_number#871, cal_year#873, animal_group#881, postcode_district#892, origin_of_call#882]
   :  +- *(2) FileScan parquet [incident_number#871,cal_year#873,animal_group#881,origin_of_call#882,postcode_district#892] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/animal_rescue.parquet], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;incident_number:string,cal_year:int,animal_group:string,origin_of_call:string,postcode_dis...
   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))
      +- *(1) Project [postcode_district#928, population#929L]
         +- *(1) Filter isnotnull(postcode_district#928)
            +- *(1) FileScan parquet [postcode_district#928,population#929L] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/population.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(postcode_district)], ReadSchema: struct&lt;postcode_district:string,population:bigint&gt;
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_auto_broadcast</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">dplyr</span><span class="o">::</span><span class="nf">explain</span><span class="p">()</span>
</pre></div>
</div>
<p>Both ways of broadcasting give the same result. You can leave it to Spark to decide, or if you want more control over how you DataFrames are joined, turn off automatic broadcasting by setting <code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code> to <code class="docutils literal notranslate"><span class="pre">-1</span></code>.</p>
<p>Note that Spark will not always be able to determine the size of the data in which case it will default to a sort merge join, even when this would be significantly less efficient. Spark does have some non-instinctive behaviour when it comes to automatic broadcasting; generally, if the raw file is less than 10MB it will be broadcast regardless of file type. Large parquet files which are filtered or grouped to reduce the size should be broadcast but large CSV files will not be automatically broadcast even if they are filtered/grouped to a smaller size. If unsure, use <code class="docutils literal notranslate"><span class="pre">explain()</span></code> to check or manually broadcast with the broadcast hint.</p>
</section>
</section>
<section id="replacing-a-join-with-a-narrow-transformation">
<h2>Replacing a join with a narrow transformation<a class="headerlink" href="#replacing-a-join-with-a-narrow-transformation" title="Permalink to this heading">#</a></h2>
<p>If your second DataFrame is tiny, you could potentially even not do a join at all, and replace it with a series of <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.when.html"><code class="docutils literal notranslate"><span class="pre">F.when()</span></code></a> statements in PySpark or <a class="reference external" href="https://dplyr.tidyverse.org/reference/case_when.html"><code class="docutils literal notranslate"><span class="pre">case_when()</span></code></a> in sparklyr. These will be processed as a <em>narrow transformation</em> in parallel rather than a <em>wide transformation</em>, meaning that it should be quicker than joining using the usual methods.</p>
<p>The following diagram from the  shows how this works visually; the <code class="docutils literal notranslate"><span class="pre">F.when()</span></code>/<code class="docutils literal notranslate"><span class="pre">case_when()</span></code> method is a narrow <em>narrow transformation</em> is within the same stage, rather than a <em>wide transformation</em> between stages:</p>
<figure class="align-default" id="sparkapplication">
<a class="reference internal image-reference" href="raw-notebooks/images/application_and_ui.png"><img alt="Diagram showing parallel and serial operations representing narrow and wide transformations respectively" src="raw-notebooks/images/application_and_ui.png" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">Narrow and wide transformations</span><a class="headerlink" href="#sparkapplication" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<section id="example-narrow-transformations">
<h3>Example: Narrow Transformations<a class="headerlink" href="#example-narrow-transformations" title="Permalink to this heading">#</a></h3>
<p>The rescue data has a column, <code class="docutils literal notranslate"><span class="pre">origin_of_call</span></code>, which contains information about who reported the incident.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+---------------------+
|origin_of_call       |
+---------------------+
|Coastguard           |
|Person (mobile)      |
|Person (land line)   |
|Other FRS            |
|Not known            |
|Police               |
|Person (running call)|
|Ambulance            |
+---------------------+
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="n">origin_of_call</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_distinct</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>Let us categorise these into <code class="docutils literal notranslate"><span class="pre">Emergency</span> <span class="pre">Services</span></code> and <code class="docutils literal notranslate"><span class="pre">Member</span> <span class="pre">of</span> <span class="pre">Public</span></code>; there is also a <code class="docutils literal notranslate"><span class="pre">Not</span> <span class="pre">known</span></code> value which can be mapped to <code class="docutils literal notranslate"><span class="pre">null</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">call_origin</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s2">&quot;Coastguard&quot;</span><span class="p">,</span> <span class="s2">&quot;Emergency Services&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Police&quot;</span><span class="p">,</span> <span class="s2">&quot;Emergency Services&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Ambulance&quot;</span><span class="p">,</span> <span class="s2">&quot;Emergency Services&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Other FRS&quot;</span><span class="p">,</span> <span class="s2">&quot;Emergency Services&quot;</span><span class="p">],</span> <span class="c1">#Other fire and rescue services</span>
    <span class="p">[</span><span class="s2">&quot;Person (mobile)&quot;</span><span class="p">,</span> <span class="s2">&quot;Member of Public&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Person (land line)&quot;</span><span class="p">,</span> <span class="s2">&quot;Member of Public&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Person (running call)&quot;</span><span class="p">,</span> <span class="s2">&quot;Member of Public&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Not known&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],],</span>
    <span class="p">[</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">,</span> <span class="s2">&quot;origin_type&quot;</span><span class="p">])</span>

<span class="n">call_origin</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+---------------------+------------------+
|origin_of_call       |origin_type       |
+---------------------+------------------+
|Coastguard           |Emergency Services|
|Police               |Emergency Services|
|Ambulance            |Emergency Services|
|Other FRS            |Emergency Services|
|Person (mobile)      |Member of Public  |
|Person (land line)   |Member of Public  |
|Person (running call)|Member of Public  |
|Not known            |null              |
+---------------------+------------------+
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">call_origin</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_copy_to</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span>
<span class="w">    </span><span class="s">&quot;origin_of_call&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Coastguard&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Police&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Ambulance&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Other FRS&quot;</span><span class="p">,</span>
<span class="w">                         </span><span class="s">&quot;Person (mobile)&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Person (land line)&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Person (running call)&quot;</span><span class="p">,</span>
<span class="w">                         </span><span class="s">&quot;Not known&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="s">&quot;origin_type&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Emergency Services&quot;</span><span class="p">),</span><span class="w"> </span><span class="m">4</span><span class="p">),</span>
<span class="w">                      </span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Member of Public&quot;</span><span class="p">),</span><span class="w"> </span><span class="m">3</span><span class="p">),</span>
<span class="w">                      </span><span class="kc">NA</span><span class="p">)))</span>

<span class="n">call_origin</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>We can do a left join, as we have done previously. As the DataFrame is small, we will ensure it is broadcast with the broadcast hint:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_origin</span> <span class="o">=</span> <span class="n">rescue</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">call_origin</span><span class="p">),</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>

<span class="n">rescue_with_origin</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s2">&quot;incident_number&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+------------------+----------------+--------+--------------------------------+-----------------+------------------+
|origin_of_call    |incident_number |cal_year|animal_group                    |postcode_district|origin_type       |
+------------------+----------------+--------+--------------------------------+-----------------+------------------+
|Other FRS         |000014-03092018M|2018    |Unknown - Heavy Livestock Animal|CR8              |Emergency Services|
|Person (mobile)   |000099-01012017 |2017    |Dog                             |BR2              |Member of Public  |
|Person (land line)|000260-01012017 |2017    |Bird                            |CR0              |Member of Public  |
|Person (mobile)   |000375-01012017 |2017    |Dog                             |TW8              |Member of Public  |
|Person (mobile)   |000477-01012017 |2017    |Deer                            |HA7              |Member of Public  |
+------------------+----------------+--------+--------------------------------+-----------------+------------------+
only showing top 5 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_origin</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rescue</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">left_join</span><span class="p">(</span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_broadcast</span><span class="p">(</span><span class="n">call_origin</span><span class="p">),</span><span class="w"> </span><span class="n">by</span><span class="o">=</span><span class="s">&quot;origin_of_call&quot;</span><span class="p">)</span>

<span class="n">rescue_with_origin</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">dplyr</span><span class="o">::</span><span class="nf">arrange</span><span class="p">(</span><span class="n">incident_number</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>An alternative to a join here is using chained <code class="docutils literal notranslate"><span class="pre">F.when()</span></code> statements in PySpark or <code class="docutils literal notranslate"><span class="pre">case_when</span></code> inside <code class="docutils literal notranslate"><span class="pre">mutate</span></code> in sparklyr.</p>
<p>The three <code class="docutils literal notranslate"><span class="pre">origin_of_call</span></code> which map to <code class="docutils literal notranslate"><span class="pre">Member</span> <span class="pre">of</span> <span class="pre">Public</span></code> all begin with <code class="docutils literal notranslate"><span class="pre">Person</span></code>. We can take the first six characters with <code class="docutils literal notranslate"><span class="pre">substr()</span></code> (a <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.substr.html">column method</a> in PySpark and a <a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#substr">Spark SQL function</a> in sparklyr), and if this equals <code class="docutils literal notranslate"><span class="pre">Person</span></code> we know that this is <code class="docutils literal notranslate"><span class="pre">Member</span> <span class="pre">of</span> <span class="pre">Public</span></code>.</p>
<p>We can put the values which map to <code class="docutils literal notranslate"><span class="pre">Emergency</span> <span class="pre">Services</span></code> in an <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.isin.html"><code class="docutils literal notranslate"><span class="pre">.isin()</span></code></a> (PySpark) or <code class="docutils literal notranslate"><span class="pre">%in%</span></code> (sparklyr) statement.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">Not</span> <span class="pre">known</span></code>, a simple equality statement can be used.</p>
<p>Finally, any values not matching any of these criteria can be mapped to <code class="docutils literal notranslate"><span class="pre">null</span></code> with <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.otherwise.html"><code class="docutils literal notranslate"><span class="pre">F.otherwise()</span></code></a> (PySpark) or <code class="docutils literal notranslate"><span class="pre">TRUE</span> <span class="pre">~</span> <span class="pre">NA</span></code> (sparklyr), although no values will match this criteria in our example. Note that this is the default value and could be omitted, but it is better to be explicit where we can.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_origin_when</span> <span class="o">=</span> <span class="n">rescue</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;origin_type&quot;</span><span class="p">,</span>
                  <span class="n">F</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">substr</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;Person&quot;</span><span class="p">,</span> <span class="s2">&quot;Member of Public&quot;</span><span class="p">)</span>
                   <span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span>
                       <span class="s2">&quot;Coastguard&quot;</span><span class="p">,</span> <span class="s2">&quot;Police&quot;</span><span class="p">,</span> <span class="s2">&quot;Ambulance&quot;</span><span class="p">,</span> <span class="s2">&quot;Other FRS&quot;</span><span class="p">),</span> <span class="s2">&quot;Emergency Services&quot;</span><span class="p">)</span>
                   <span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;Not known&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                   <span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>

<span class="n">rescue_with_origin_when</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s2">&quot;incident_number&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+----------------+--------+--------------------------------+-----------------+------------------+------------------+
|incident_number |cal_year|animal_group                    |postcode_district|origin_of_call    |origin_type       |
+----------------+--------+--------------------------------+-----------------+------------------+------------------+
|000014-03092018M|2018    |Unknown - Heavy Livestock Animal|CR8              |Other FRS         |Emergency Services|
|000099-01012017 |2017    |Dog                             |BR2              |Person (mobile)   |Member of Public  |
|000260-01012017 |2017    |Bird                            |CR0              |Person (land line)|Member of Public  |
|000375-01012017 |2017    |Dog                             |TW8              |Person (mobile)   |Member of Public  |
|000477-01012017 |2017    |Deer                            |HA7              |Person (mobile)   |Member of Public  |
+----------------+--------+--------------------------------+-----------------+------------------+------------------+
only showing top 5 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_origin_when</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rescue</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">origin_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">case_when</span><span class="p">(</span>
<span class="w">        </span><span class="nf">substr</span><span class="p">(</span><span class="n">origin_of_call</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">6</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;Person&quot;</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="s">&quot;Member of Public&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="n">origin_of_call</span><span class="w"> </span><span class="o">%in%</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Coastguard&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Police&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Ambulance&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Other FRS&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="s">&quot;Emergency Services&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="n">origin_of_call</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;Not known&quot;</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="kc">NA</span><span class="p">,</span>
<span class="w">        </span><span class="kc">TRUE</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="kc">NA</span><span class="p">))</span>

<span class="n">rescue_with_origin_when</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">dplyr</span><span class="o">::</span><span class="nf">arrange</span><span class="p">(</span><span class="n">incident_number</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_origin_when</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>== Physical Plan ==
*(1) Project [incident_number#871, cal_year#873, animal_group#881, postcode_district#892, origin_of_call#882, CASE WHEN (substring(origin_of_call#882, 1, 6) = Person) THEN Member of Public WHEN origin_of_call#882 IN (Coastguard,Police,Ambulance,Other FRS) THEN Emergency Services WHEN (origin_of_call#882 = Not known) THEN null ELSE null END AS origin_type#998]
+- *(1) FileScan parquet [incident_number#871,cal_year#873,animal_group#881,origin_of_call#882,postcode_district#892] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/animal_rescue.parquet], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;incident_number:string,cal_year:int,animal_group:string,origin_of_call:string,postcode_dis...
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_origin_when</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">dplyr</span><span class="o">::</span><span class="nf">explain</span><span class="p">()</span>
</pre></div>
</div>
<p>The plan here confirms that no join is taking place; instead, the conditional statements are interpreted as an SQL style <code class="docutils literal notranslate"><span class="pre">CASE</span> <span class="pre">WHEN</span></code> statement. There are only narrow transformations, meaning that the data can stay within the partitions and no shuffle is needed and therefore should be more efficient than a join.</p>
<p>This can be confirmed by looking at the Spark UI:</p>
<figure class="align-default" id="narrowtransformationdag">
<a class="reference internal image-reference" href="raw-notebooks/images/when_ui.png"><img alt="Simple SQL DAG representing a process where a join was replaced with a narrow transformation, showing no exchanges" src="raw-notebooks/images/when_ui.png" style="width: 50%;" /></a>
<figcaption>
<p><span class="caption-text">SQL DAG for narrow transformation</span><a class="headerlink" href="#narrowtransformationdag" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>This plan is far simpler than the other two we saw.</p>
<p>Although it may be tempting to use this method be careful. It is trickier to code and harder to read than a conventional join and also will not work if the source data changes, so if a new value appeared in <code class="docutils literal notranslate"><span class="pre">origin_of_call</span></code> (e.g. the RSPCA or the army, which may want a different <code class="docutils literal notranslate"><span class="pre">origin_type</span></code>) we would have to change the actual code rather than adding new lines to a reference file.</p>
<p>In production code, it is best practice to use unit tests. These are very important when making efficiency improvements, since it is important that any changes do not affect the functionality of the code. See the articles on <span class="xref myst">Unit Testing in Spark</span> for more details.</p>
</section>
</section>
<section id="when-to-use-each-method">
<h2>When to use each method<a class="headerlink" href="#when-to-use-each-method" title="Permalink to this heading">#</a></h2>
<p>We have seen examples of three ways of joining data:</p>
<ul class="simple">
<li><p>Sort Merge Join</p></li>
<li><p>Broadcast Join</p></li>
<li><p>Replacing joins with a narrow transformation</p></li>
</ul>
<p>When should each be used?</p>
<p>First of all, it is most important that your code works. Optimising your code prematurely can lead to errors, so it is often best to not concern yourself with the detail initially and let Spark make the decision.</p>
<p>Once your code is working, the main question to answer is <em>is the second DataFrame small enough to be broadcast effectively?</em> If so, then a broadcast join is the best option. If not, use a sort merge join.</p>
<p>Another question to answer is <em>should I turn the automatic broadcasting on or off</em>? Automatic broadcasting is useful if you are unsure as Spark will decide for you. It is also good for future-proofing if your source data grows in size, since it will automatically change to a sort merge join once it goes over the threshold; often large datasets started out as a small ones! However, only DataFrames which Spark can calculate the size of will be automatically broadcast; if not, a sort merge join will be used, even if the second DataFrame is tiny. If you are using automatic broadcasting, check the Spark UI or use <code class="docutils literal notranslate"><span class="pre">explain()</span></code> to verify the type of join.</p>
<p>Some users prefer to have complete control, by setting <code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code> to <code class="docutils literal notranslate"><span class="pre">-1</span></code> and using the broadcast hints (<code class="docutils literal notranslate"><span class="pre">F.broadcast()</span></code>/<code class="docutils literal notranslate"><span class="pre">sdf_broadcast</span></code>). Be careful not to broadcast a DataFrame which grows in size over time if you choose to do this.</p>
<p>You can change the value of <code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code>, which may be useful for those using either very small or very large Spark sessions.</p>
<p>The narrow transformation method was shown mainly to demonstrate that you can replace a join with a narrow transformation in certain circumstances. In practice, as such DataFrames will be tiny they can be broadcast anyway so it is not recommended. Only use this if your source data will never change, and be careful to extensively test and comment your code.</p>
<p>The analysis above assumes that the join keys in the DataFrames are roughly equally partitioned. If your DataFrame is skewed so that some partitions contain significantly more data than others, then the efficiency of the join could be affected. See the article on <span class="xref myst">partitions</span> for more detail. The solution here is to use a <em>salted join</em>.</p>
</section>
<section id="salted-joins">
<h2>Salted Joins<a class="headerlink" href="#salted-joins" title="Permalink to this heading">#</a></h2>
<p>A sort merge join will move all the data with the same join keys to the same partition, which can lead to skew in the DataFrame and cause the join to process inefficiently, or not at all in some cases. This can be resolved with a <em>salted join</em>: splitting the join keys, so that the DataFrame is distributed into more equal partition sizes. See the article on <span class="xref myst">salted joins</span> for more information.</p>
</section>
<section id="further-resources">
<h2>Further Resources<a class="headerlink" href="#further-resources" title="Permalink to this heading">#</a></h2>
<p>Spark at the ONS Articles:</p>
<ul class="simple">
<li><p><span class="xref myst">Salted Joins</span></p></li>
<li><p><span class="xref myst">Shuffling</span></p></li>
<li><p><span class="xref myst">Spark Application and UI</span></p></li>
<li><p><span class="xref myst">Partitions</span></p></li>
<li><p><span class="xref myst">Persisting</span></p></li>
<li><p><span class="xref myst">Unit Testing in Spark</span></p></li>
</ul>
<p>PySpark Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.join.html"><code class="docutils literal notranslate"><span class="pre">.join()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.explain.html"><code class="docutils literal notranslate"><span class="pre">.explain()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.broadcast.html"><code class="docutils literal notranslate"><span class="pre">F.broadcast()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.when.html"><code class="docutils literal notranslate"><span class="pre">F.when()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.otherwise.html"><code class="docutils literal notranslate"><span class="pre">F.otherwise()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.substr.html"><code class="docutils literal notranslate"><span class="pre">substr()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.isin.html"><code class="docutils literal notranslate"><span class="pre">.isin()</span></code></a></p></li>
</ul>
<p>sparklyr and tidyverse Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/join.tbl_spark.html"><code class="docutils literal notranslate"><span class="pre">left_join()</span></code></a></p></li>
<li><p><a class="reference external" href="https://dplyr.tidyverse.org/reference/explain.html"><code class="docutils literal notranslate"><span class="pre">explain()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/sdf_broadcast.html"><code class="docutils literal notranslate"><span class="pre">sdf_broadcast()</span></code></a></p></li>
<li><p><a class="reference external" href="https://dplyr.tidyverse.org/reference/case_when.html"><code class="docutils literal notranslate"><span class="pre">case_when()</span></code></a></p></li>
</ul>
<p>Spark SQL Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#substr"><code class="docutils literal notranslate"><span class="pre">substr</span></code></a></p></li>
</ul>
<p>Spark Documentation</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/sql-performance-tuning.html">Performance tuning</a>: details of <code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code></p></li>
</ul>
<p>Other links:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://databricks.com/glossary/what-are-transformations">DataBricks Transformations definition</a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./raw-notebooks/join-concepts"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-join-algorithms-in-spark">The Join Algorithms in Spark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shuffle-hash-join">Shuffle Hash Join</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sort-merge-join">Sort Merge Join</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sort-merge-join-example">Sort Merge Join Example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-sort-merge-join">Understanding Sort Merge Join</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#broadcast-join">Broadcast Join</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-using-a-broadcast-hint">Example: Using a Broadcast Hint</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#replacing-a-join-with-a-narrow-transformation">Replacing a join with a narrow transformation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-narrow-transformations">Example: Narrow Transformations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#when-to-use-each-method">When to use each method</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#salted-joins">Salted Joins</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-resources">Further Resources</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Analysis Standards and Pipelines in Quality and Improvement, Office for National Statistics
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>