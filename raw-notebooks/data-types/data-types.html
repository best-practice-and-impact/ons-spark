
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Data Types in Spark &#8212; Spark at the ONS</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/accessibility.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/tabs.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-95MGHSRD0S"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-95MGHSRD0S');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Spark at the ONS</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Spark overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/spark-start.html">
   Getting Started with Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/when-to-use-spark.html">
   When To Use Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/spark-session-guidance.html">
   Guidance on Spark Sessions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/example-spark-sessions.html">
   Example Spark Sessions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/spark-defaults.html">
   Configuration Hierarchy and
   <code class="docutils literal notranslate">
    <span class="pre">
     spark-defaults.conf
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/data-types.html">
   Data Types in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/creating-dataframes.html">
   Creating DataFrames Manually
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/data-storage.html">
   Data Storage
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to PySpark
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyspark-intro/pyspark-intro.html">
   Introduction to PySpark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyspark-intro/reading-data-pyspark.html">
   Reading Data in PySpark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyspark-intro/returning-data.html">
   Returning Data from Cluster to Driver
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyspark-intro/f-col.html">
   Reference columns by name:
   <code class="docutils literal notranslate">
    <span class="pre">
     F.col()
    </span>
   </code>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to sparklyr
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../sparklyr-intro/sparklyr-intro.html">
   Introduction to sparklyr
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sparklyr-intro/reading-data-sparklyr.html">
   Reading Data in sparklyr
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sparklyr-intro/sparklyr-functions.html">
   Using Spark functions in sparklyr
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Spark functions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/union-dataframes-with-different-columns.html">
   Union two DataFrames with different columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/padding.html">
   Add leading zeros with
   <code class="docutils literal notranslate">
    <span class="pre">
     lpad()
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/sampling.html">
   Sampling:
   <code class="docutils literal notranslate">
    <span class="pre">
     .sample()
    </span>
   </code>
   and
   <code class="docutils literal notranslate">
    <span class="pre">
     sdf_sample()
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/pivot-tables.html">
   Pivot tables in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/rounding.html">
   Rounding differences in Python, R and Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/window-functions.html">
   Window Functions in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/cross-joins.html">
   Cross Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/arrays.html">
   Arrays Functions in PySpark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/writing-data.html">
   Writing Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/job-description.html">
   Set Spark Job Description
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Understanding and Optimising Spark
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/optimisation-tips.html">
   Ideas for optimising Spark code
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/spark-application-and-ui.html">
   Spark Application and UI
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/shuffling.html">
   Shuffling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/join-concepts.html">
   Optimising Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/salted-joins.html">
   Salted Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/partitions.html">
   Managing Partitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/persistence.html">
   Persisting in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/cache.html">
   Caching
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../checkpoint-staging/checkpoint-staging.html">
   Checkpoint
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/garbage-collection.html">
   Garbage Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/df-order.html">
   Spark DataFrames Are Not Ordered
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/exercises.html">
   Exercises
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Testing and Debugging
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../testing-debugging/spark-errors.html">
   Understanding and Handling Spark Errors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../testing-debugging/unit-testing.html">
   Unit Testing in Spark
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ancillary Topics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ancillary-topics/visualisation.html">
   Spark and Visualisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ancillary-topics/module-imports.html">
   Naming Conflicts in Module Imports
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ancillary-topics/pydoop.html">
   Pydoop: HDFS to pandas
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/best-practice-and-impact/ons-spark/main?urlpath=tree/docs/raw-notebooks/data-types/data-types.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/best-practice-and-impact/ons-spark"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/best-practice-and-impact/ons-spark/issues/new?title=Issue%20on%20page%20%2Fraw-notebooks/data-types/data-types.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/raw-notebooks/data-types/data-types.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#importing-data-types">
   Importing Data Types
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#common-data-types">
   Common Data Types
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#numeric-types">
     Numeric types
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#string-types">
     String types
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#datetime-types">
     Datetime types
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-types">
     Other types
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#schemas">
   Schemas
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#casting-changing-data-types">
   <em>
    Casting
   </em>
   : Changing Data Types
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-resources">
   Further Resources
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#acknowledgements">
     Acknowledgements
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Data Types in Spark</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#importing-data-types">
   Importing Data Types
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#common-data-types">
   Common Data Types
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#numeric-types">
     Numeric types
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#string-types">
     String types
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#datetime-types">
     Datetime types
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-types">
     Other types
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#schemas">
   Schemas
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#casting-changing-data-types">
   <em>
    Casting
   </em>
   : Changing Data Types
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-resources">
   Further Resources
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#acknowledgements">
     Acknowledgements
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="data-types-in-spark">
<h1>Data Types in Spark<a class="headerlink" href="#data-types-in-spark" title="Permalink to this headline">#</a></h1>
<p>Unlike some languages data types are not explicitly declared in Python or R by default. Instead, the data type is inferred when a value is assigned to a variable. Spark works in a similar way; data types often <em>can</em> be explicitly declared but in the absence of this they are inferred. We can have give greater control over the data types by supplying a <em>schema</em>, or explicitly casting one data type to another.</p>
<p>Data types are important in Spark and it is worth familiarising yourself with those that are most frequently used.</p>
<p>This article gives an overview of the most common data types and shows how to use schemas and cast a column from one data type to another.</p>
<p><em>Data types</em> in this article refers specifically to the data types of the <em>columns</em> of the DataFrame; PySpark and sparklyr DataFrames are of course themselves Python and R objects respectively.</p>
<section id="importing-data-types">
<h2>Importing Data Types<a class="headerlink" href="#importing-data-types" title="Permalink to this headline">#</a></h2>
<p>In PySpark, data types are in the <a class="reference external" href="https://spark.apache.org/docs/latest/sql-ref-datatypes.html"><code class="docutils literal notranslate"><span class="pre">pyspark.sql.types</span></code></a> module. The documentation uses the <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">*</span></code> style; we prefer to <span class="xref myst">import only the data types needed</span>, e.g. from <code class="docutils literal notranslate"><span class="pre">pyspark.sql.types</span> <span class="pre">import</span> <span class="pre">IntegerType</span></code>.</p>
<p>In R, there is no need to import data types, as they can be handled with base R (e.g. <a class="reference external" href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/numeric.html"><code class="docutils literal notranslate"><span class="pre">as.numeric()</span></code></a> or a Spark function e.g. <a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#bigint"><code class="docutils literal notranslate"><span class="pre">bigint()</span></code></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Structural types</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span> <span class="n">StructField</span>

<span class="c1"># String type</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StringType</span>

<span class="c1"># Numeric types</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">IntegerType</span><span class="p">,</span> <span class="n">DecimalType</span><span class="p">,</span> <span class="n">DoubleType</span>

<span class="c1"># Date types</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">DateType</span><span class="p">,</span> <span class="n">TimestampType</span>
</pre></div>
</div>
</div>
</div>
<p>In order to run our examples, we also need to start a Spark session:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span><span class="p">,</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="nn">yaml</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;../../../config.yaml&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span><span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[2]&quot;</span><span class="p">)</span>
         <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;data-types&quot;</span><span class="p">)</span>
         <span class="o">.</span><span class="n">getOrCreate</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">sparklyr</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>

<span class="nf">options</span><span class="p">(</span><span class="n">pillar.max_dec_width</span> <span class="o">=</span> <span class="m">14</span><span class="p">)</span>

<span class="n">sc</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_connect</span><span class="p">(</span>
    <span class="n">master</span> <span class="o">=</span> <span class="s">&quot;local[2]&quot;</span><span class="p">,</span>
    <span class="n">app_name</span> <span class="o">=</span> <span class="s">&quot;data-types&quot;</span><span class="p">,</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_config</span><span class="p">())</span>

<span class="n">config</span> <span class="o">&lt;-</span> <span class="n">yaml</span><span class="o">::</span><span class="nf">yaml.load_file</span><span class="p">(</span><span class="s">&quot;ons-spark/config.yaml&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="common-data-types">
<h2>Common Data Types<a class="headerlink" href="#common-data-types" title="Permalink to this headline">#</a></h2>
<p>The <a class="reference external" href="https://spark.apache.org/docs/latest/sql-ref-datatypes.html">documentation</a> explains all the data types available in Spark. Here we focus on a few common ones and their practical usage, e.g. when you might choose one data type over another.</p>
<p>There are more data types used in PySpark than sparklyr, due to the way that the code is complied in the Spark cluster. Also note that although <em>factors</em> are common in R they do not exist in sparklyr as they cannot be mapped to a Spark data type.</p>
<section id="numeric-types">
<h3>Numeric types<a class="headerlink" href="#numeric-types" title="Permalink to this headline">#</a></h3>
<p>The choice of numeric type depends on two factors:</p>
<ul class="simple">
<li><p>Is the column all whole numbers, or does it contain decimals?</p></li>
<li><p>How large are the values?</p></li>
</ul>
<p>Note that there are more available data types in PySpark than sparklyr, so be careful if you use both languages.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Python Explanation</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">R Explanation</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><p>If the column only contains integers, then <code class="docutils literal notranslate"><span class="pre">IntegerType</span></code> or <code class="docutils literal notranslate"><span class="pre">LongType</span></code> will be the most suitable. <code class="docutils literal notranslate"><span class="pre">IntegerType</span></code> has a maximum range of approximately <span class="math notranslate nohighlight">\(\pm 2.1 \times 10^9\)</span>, so if there is any possibility of the values exceeding this, use <code class="docutils literal notranslate"><span class="pre">LongType</span></code>.</p>
<p>For decimals, you can use often use <code class="docutils literal notranslate"><span class="pre">DoubleType</span></code>. For larger numbers or those with a lot of decimal places, <code class="docutils literal notranslate"><span class="pre">DecimalType</span></code> gives greater precision as you can specify the <code class="docutils literal notranslate"><span class="pre">precision</span></code> and <code class="docutils literal notranslate"><span class="pre">scale</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">precision=5</span></code> and <code class="docutils literal notranslate"><span class="pre">scale=2</span></code> has values between <span class="math notranslate nohighlight">\(\pm 999.99\)</span>.</p>
<p>The types given by <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.printSchema.html"><code class="docutils literal notranslate"><span class="pre">.printSchema()</span></code></a> are simpler than the full Spark type name, e.g. <code class="docutils literal notranslate"><span class="pre">IntegerType</span></code> is <code class="docutils literal notranslate"><span class="pre">integer</span></code>.</p>
<p>As a quick example, we can see what happens when a value is too long for <code class="docutils literal notranslate"><span class="pre">IntegerType</span></code>, and also see that the <code class="docutils literal notranslate"><span class="pre">DecimalType</span></code> has a fixed width to the right of the decimal point:</p>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><p>If the column only contains integers, then <code class="docutils literal notranslate"><span class="pre">IntegerType</span></code> may be the most suitable. <code class="docutils literal notranslate"><span class="pre">IntegerType</span></code> has a maximum range of approximately <span class="math notranslate nohighlight">\(\pm 2.1 \times 10^9\)</span>, so if there is any possibility of the values exceeding this, use <code class="docutils literal notranslate"><span class="pre">DoubleType</span></code>. Note that <code class="docutils literal notranslate"><span class="pre">LongType</span></code> does not exist in sparklyr; instead, <code class="docutils literal notranslate"><span class="pre">DoubleType</span></code> is used.</p>
<p><code class="docutils literal notranslate"><span class="pre">DoubleType</span></code> is also used for decimals; there is no <code class="docutils literal notranslate"><span class="pre">DecimalType</span></code> in sparklyr.</p>
<p>The types given by <a class="reference external" href="https://pillar.r-lib.org/reference/glimpse.html"><code class="docutils literal notranslate"><span class="pre">glimpse()</span></code></a> are abbreviated, e.g. <code class="docutils literal notranslate"><span class="pre">IntegerType</span></code> is <code class="docutils literal notranslate"><span class="pre">&lt;int&gt;</span></code>. You can see the automatic conversion of data types in the example below:</p>
</div></div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">numeric_df</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
              <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;really_big_number_long&quot;</span><span class="p">,</span>
                          <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span><span class="o">**</span><span class="mi">9</span><span class="p">)</span>
              <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;really_big_number_int&quot;</span><span class="p">,</span>
                          <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;really_big_number_long&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">IntegerType</span><span class="p">()))</span>
              <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;small_number&quot;</span><span class="p">,</span>
                          <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">9998</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
              <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;small_number_decimal&quot;</span><span class="p">,</span>
                          <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;small_number&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">DecimalType</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
              <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">))</span>

<span class="n">numeric_df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="n">numeric_df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>root
 |-- really_big_number_long: long (nullable = false)
 |-- really_big_number_int: integer (nullable = false)
 |-- small_number: double (nullable = true)
 |-- small_number_decimal: decimal(5,2) (nullable = true)

+----------------------+---------------------+------------+--------------------+
|really_big_number_long|really_big_number_int|small_number|small_number_decimal|
+----------------------+---------------------+------------+--------------------+
|                     0|                    0|       99.98|               99.98|
|            1000000000|           1000000000|       99.99|               99.99|
|            2000000000|           2000000000|       100.0|              100.00|
|            3000000000|          -1294967296|      100.01|              100.01|
|            4000000000|           -294967296|      100.02|              100.02|
+----------------------+---------------------+------------+--------------------+
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">numeric_df</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_seq</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="m">4</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span>
        <span class="n">really_big_number_double</span> <span class="o">=</span> <span class="n">id</span> <span class="o">*</span> <span class="m">10</span><span class="o">**</span><span class="m">9</span><span class="p">,</span>
        <span class="n">small_number_double</span> <span class="o">=</span> <span class="n">id</span> <span class="o">/</span> <span class="m">10</span><span class="p">)</span>

<span class="n">pillar</span><span class="o">::</span><span class="nf">glimpse</span><span class="p">(</span><span class="n">numeric_df</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">numeric_df</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="string-types">
<h3>String types<a class="headerlink" href="#string-types" title="Permalink to this headline">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">StringType</span></code> is the default for character values, and can contain any string. One relatively common scenario that you may encounter is numeric values being stored as strings. See the section on Casting for information on changing data types.</p>
<p>In Spark 3, the fixed character width <code class="docutils literal notranslate"><span class="pre">CharType</span></code> and maximum character width <code class="docutils literal notranslate"><span class="pre">VarcharType</span></code> exist, but not in <code class="docutils literal notranslate"><span class="pre">pyspark.sql.types</span></code>; you will have to use DDL notation for these.</p>
</section>
<section id="datetime-types">
<h3>Datetime types<a class="headerlink" href="#datetime-types" title="Permalink to this headline">#</a></h3>
<p>The two datetime types are <code class="docutils literal notranslate"><span class="pre">DateType</span></code> and <code class="docutils literal notranslate"><span class="pre">TimestampType</span></code>. <code class="docutils literal notranslate"><span class="pre">DateType</span></code> is easier to read, but is not always supported when writing out data as a Hive table, so <code class="docutils literal notranslate"><span class="pre">TimestampType</span></code> is preferred for storage. See the section on Casting for details of how to convert between the two.</p>
<p>Note that there are differences in how dates are handled in Spark 3 and Spark 2.4. See the <a class="reference external" href="https://databricks.com/blog/2020/07/22/a-comprehensive-look-at-dates-and-timestamps-in-apache-spark-3-0.html">DataBricks blog</a> for more details.</p>
<p>The defaults when creating a DataFrame in PySpark and sparklyr are also different, as can be seen from the examples:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="n">dates</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span>
         <span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
             <span class="p">[</span><span class="s2">&quot;March&quot;</span><span class="p">,</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2022</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
             <span class="p">[</span><span class="s2">&quot;April&quot;</span><span class="p">,</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2022</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
             <span class="p">[</span><span class="s2">&quot;May&quot;</span><span class="p">,</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2022</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]],</span>
             <span class="p">[</span><span class="s2">&quot;month_name&quot;</span><span class="p">,</span> <span class="s2">&quot;example_timestamp&quot;</span><span class="p">])</span>
         <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;example_date&quot;</span><span class="p">,</span>
                     <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;example_timestamp&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">DateType</span><span class="p">())))</span>

<span class="n">dates</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">dates</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+----------+-------------------+------------+
|month_name|  example_timestamp|example_date|
+----------+-------------------+------------+
|     March|2022-03-01 00:00:00|  2022-03-01|
|     April|2022-04-01 00:00:00|  2022-04-01|
|       May|2022-05-01 00:00:00|  2022-05-01|
+----------+-------------------+------------+

root
 |-- month_name: string (nullable = true)
 |-- example_timestamp: timestamp (nullable = true)
 |-- example_date: date (nullable = true)
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">dates</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_copy_to</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="nf">data.frame</span><span class="p">(</span>
        <span class="s">&quot;month_name&quot;</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&quot;March&quot;</span><span class="p">,</span> <span class="s">&quot;April&quot;</span><span class="p">,</span> <span class="s">&quot;May&quot;</span><span class="p">),</span>
        <span class="s">&quot;example_date&quot;</span> <span class="o">=</span> <span class="n">lubridate</span><span class="o">::</span><span class="nf">ymd</span><span class="p">(</span>
            <span class="nf">c</span><span class="p">(</span><span class="s">&quot;2022-03-01&quot;</span><span class="p">,</span> <span class="s">&quot;2022-04-01&quot;</span><span class="p">,</span> <span class="s">&quot;2022-05-01&quot;</span><span class="p">))))</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">example_timestamp</span> <span class="o">=</span> <span class="nf">to_timestamp</span><span class="p">(</span><span class="n">example_date</span><span class="p">))</span>

<span class="n">pillar</span><span class="o">::</span><span class="nf">glimpse</span><span class="p">(</span><span class="n">dates</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">dates</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="other-types">
<h3>Other types<a class="headerlink" href="#other-types" title="Permalink to this headline">#</a></h3>
<p>Other common types are <code class="docutils literal notranslate"><span class="pre">BooleanType</span></code>; although this is boolean remember that it can also contain null values in addition to <code class="docutils literal notranslate"><span class="pre">True</span></code> and <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>For arrays, use <code class="docutils literal notranslate"><span class="pre">ArrayType</span></code>. For more details on arrays, see the <span class="xref myst">Arrays in PySpark</span> article.</p>
</section>
</section>
<section id="schemas">
<h2>Schemas<a class="headerlink" href="#schemas" title="Permalink to this headline">#</a></h2>
<p>The <em>schema</em> refers to the structure of the data, in the example of a Spark DataFrame, the column names and data types.</p>
<p>When reading parquet files or Hive tables with Spark the schema is already defined. For instance, We can read the Animal Rescue parquet file and then preview the data types:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_path_parquet</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;rescue_path&quot;</span><span class="p">]</span>
<span class="n">rescue_from_parquet</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">rescue_path_parquet</span><span class="p">)</span>
                       <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;incident_number&quot;</span><span class="p">,</span> <span class="s2">&quot;date_time_of_call&quot;</span><span class="p">,</span> <span class="s2">&quot;cal_year&quot;</span><span class="p">,</span> <span class="s2">&quot;fin_year&quot;</span><span class="p">))</span>

<span class="n">rescue_from_parquet</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>root
 |-- incident_number: string (nullable = true)
 |-- date_time_of_call: string (nullable = true)
 |-- cal_year: integer (nullable = true)
 |-- fin_year: string (nullable = true)
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_from_parquet</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_read_parquet</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">config</span><span class="o">$</span><span class="n">rescue_path</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="n">incident_number</span><span class="p">,</span> <span class="n">date_time_of_call</span><span class="p">,</span> <span class="n">cal_year</span><span class="p">,</span> <span class="n">fin_year</span><span class="p">)</span>

<span class="n">pillar</span><span class="o">::</span><span class="nf">glimpse</span><span class="p">(</span><span class="n">rescue_from_parquet</span><span class="p">)</span>
</pre></div>
</div>
<p>CSV files (and other text storage formats) do not have any schema attached to them. There are two options for determining the data types in a DataFrame when the source data is a CSV file: use <code class="docutils literal notranslate"><span class="pre">inferSchema</span></code>/<code class="docutils literal notranslate"><span class="pre">infer_schema</span></code>, or supply a schema directly with the <code class="docutils literal notranslate"><span class="pre">schema</span></code>/<code class="docutils literal notranslate"><span class="pre">columns</span></code> option when reading the data in.</p>
<p>Inferring the schema means that Spark will scan the CSV file when reading in and try and automatically determine the data types. This may sometimes not be the exact data type that you want. Scanning the file in this way is also relatively slow, which is one of the reasons why parquet files are a better storage choice for Spark than CSVs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_path_csv</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;rescue_path_csv&quot;</span><span class="p">]</span>
<span class="n">rescue_from_csv</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">rescue_path_csv</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                   <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;IncidentNumber&quot;</span><span class="p">,</span> <span class="s2">&quot;DateTimeOfCall&quot;</span><span class="p">,</span> <span class="s2">&quot;CalYear&quot;</span><span class="p">,</span> <span class="s2">&quot;FinYear&quot;</span><span class="p">))</span>

<span class="n">rescue_from_csv</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>root
 |-- IncidentNumber: string (nullable = true)
 |-- DateTimeOfCall: string (nullable = true)
 |-- CalYear: integer (nullable = true)
 |-- FinYear: string (nullable = true)
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_from_csv</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_read_csv</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span>
                                            <span class="n">config</span><span class="o">$</span><span class="n">rescue_path_csv</span><span class="p">,</span>
                                            <span class="n">header</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span>
                                            <span class="n">infer_schema</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="n">IncidentNumber</span><span class="p">,</span> <span class="n">DateTimeOfCall</span><span class="p">,</span> <span class="n">CalYear</span><span class="p">,</span> <span class="n">FinYear</span><span class="p">)</span>
    
<span class="n">pillar</span><span class="o">::</span><span class="nf">glimpse</span><span class="p">(</span><span class="n">rescue_from_csv</span><span class="p">)</span>
</pre></div>
</div>
<p>The alternative is to use the <code class="docutils literal notranslate"><span class="pre">schema</span></code>/<code class="docutils literal notranslate"><span class="pre">columns</span></code> argument to supply a schema directly. This is done with a list of the column names and types. You can also use DDL notation if using PySpark.</p>
<p>In PySpark, supply a list of <code class="docutils literal notranslate"><span class="pre">StructField</span></code> wrapped in <code class="docutils literal notranslate"><span class="pre">StructType</span></code> to <code class="docutils literal notranslate"><span class="pre">schema</span></code>. A <code class="docutils literal notranslate"><span class="pre">StructField</span></code> consists of a column name and type. The types need to be imported from <code class="docutils literal notranslate"><span class="pre">pyspark.sql.types</span></code> and end with brackets, e.g. <code class="docutils literal notranslate"><span class="pre">StructField(&quot;incident_number&quot;,</span> <span class="pre">StringType())</span></code>.</p>
<p>In sparklyr, use a standard named R list as an input to <code class="docutils literal notranslate"><span class="pre">columns</span></code>, with data types entered as strings.</p>
<p>Note that we are not supplying an entry for every column in the raw data here, just the first four columns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span> <span class="n">StructField</span><span class="p">,</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">IntegerType</span>

<span class="n">rescue_schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;incident_number&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()),</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;date_time_of_call&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()),</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;cal_year&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">()),</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;fin_year&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">rescue_from_csv_schema</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">rescue_path_csv</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="n">rescue_schema</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">rescue_from_csv_schema</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>root
 |-- incident_number: string (nullable = true)
 |-- date_time_of_call: string (nullable = true)
 |-- cal_year: integer (nullable = true)
 |-- fin_year: string (nullable = true)
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_schema</span> <span class="o">&lt;-</span> <span class="nf">list</span><span class="p">(</span>
    <span class="n">incident_number</span> <span class="o">=</span> <span class="s">&quot;character&quot;</span><span class="p">,</span>
    <span class="n">date_time_of_call</span> <span class="o">=</span> <span class="s">&quot;character&quot;</span><span class="p">,</span>
    <span class="n">cal_year</span> <span class="o">=</span> <span class="s">&quot;integer&quot;</span><span class="p">,</span>
    <span class="n">fin_year</span> <span class="o">=</span> <span class="s">&quot;character&quot;</span>
<span class="p">)</span>

<span class="n">rescue_from_csv_schema</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_read_csv</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span>
                                                   <span class="n">config</span><span class="o">$</span><span class="n">rescue_path_csv</span><span class="p">,</span>
                                                   <span class="n">columns</span><span class="o">=</span><span class="n">rescue_schema</span><span class="p">,</span>
                                                   <span class="n">infer_schema</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span>

<span class="n">pillar</span><span class="o">::</span><span class="nf">glimpse</span><span class="p">(</span><span class="n">rescue_from_csv_schema</span><span class="p">)</span>
</pre></div>
</div>
<p>In PySpark, using Data Definition Language (DDL) to define a schema is generally quicker and easier. You may be familiar with DDL when creating database tables with SQL. Just use the names of the columns followed by their data type and then separated with commas. For ease of reading it is better to use a multi-line string and put each entry on a new line. Remember that multi-line strings in Python need to be opened and closed with <code class="docutils literal notranslate"><span class="pre">&quot;&quot;&quot;</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_schema_ddl</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    `incident_number` string,</span>
<span class="s2">    `date_time_of_call` string,</span>
<span class="s2">    `cal_year` int,</span>
<span class="s2">    `fin_year` string</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">rescue_from_csv_ddl</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">rescue_path_csv</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="n">rescue_schema_ddl</span><span class="p">)</span>
<span class="n">rescue_from_csv_ddl</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>root
 |-- incident_number: string (nullable = true)
 |-- date_time_of_call: string (nullable = true)
 |-- cal_year: integer (nullable = true)
 |-- fin_year: string (nullable = true)
</pre></div>
</div>
</div>
</div>
</section>
<section id="casting-changing-data-types">
<h2><em>Casting</em>: Changing Data Types<a class="headerlink" href="#casting-changing-data-types" title="Permalink to this headline">#</a></h2>
<p>The process of changing data types is referred to as <em>casting</em>. For instance, if a string column contains numbers you may want to cast this as an integer.</p>
<p>In PySpark, use the column methods <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.cast.html"><code class="docutils literal notranslate"><span class="pre">.cast()</span></code></a> or <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.astype.html"><code class="docutils literal notranslate"><span class="pre">.astype()</span></code></a>. These methods are identical and just aliases of each other. It is good to be consistent within your project as to which one you use.</p>
<p>In sparklyr, casting can be done with either base R methods (when available), e.g. <a class="reference external" href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/double.html"><code class="docutils literal notranslate"><span class="pre">as.double()</span></code></a>, or <span class="xref myst">Spark functions</span>, e.g. <a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#double"><code class="docutils literal notranslate"><span class="pre">double()</span></code></a>, <a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#to_timestamp"><code class="docutils literal notranslate"><span class="pre">to_timestamp()</span></code></a>. Spark functions are preferred as they are easier for Spark to compile.</p>
<p>Be careful when casting an existing column as this can make the code harder to read and amend. Instead you may want to create a new column to hold the casted value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">casted_df</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
             <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;id_double&quot;</span><span class="p">,</span>
                         <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">DoubleType</span><span class="p">())))</span>
<span class="n">casted_df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="n">casted_df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>root
 |-- id: long (nullable = false)
 |-- id_double: double (nullable = false)

+---+---------+
| id|id_double|
+---+---------+
|  0|      0.0|
|  1|      1.0|
|  2|      2.0|
|  3|      3.0|
|  4|      4.0|
+---+---------+
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">casted_df</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_seq</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="m">4</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">id_double</span> <span class="o">=</span> <span class="nf">double</span><span class="p">(</span><span class="n">id</span><span class="p">))</span>

<span class="n">pillar</span><span class="o">::</span><span class="nf">glimpse</span><span class="p">(</span><span class="n">casted_df</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">casted_df</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="further-resources">
<h2>Further Resources<a class="headerlink" href="#further-resources" title="Permalink to this headline">#</a></h2>
<p>Spark at the ONS Articles:</p>
<ul class="simple">
<li><p><span class="xref myst">Avoiding Module Import Conflicts</span></p></li>
<li><p><span class="xref myst">Arrays in PySpark</span></p></li>
<li><p><span class="xref myst">Using Spark Functions in sparklyr</span></p></li>
</ul>
<p>PySpark Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.printSchema.html"><code class="docutils literal notranslate"><span class="pre">.printSchema()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/sql-ref-datatypes.html"><code class="docutils literal notranslate"><span class="pre">pyspark.sql.types</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.cast.html"><code class="docutils literal notranslate"><span class="pre">.cast()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.astype.html"><code class="docutils literal notranslate"><span class="pre">.astype()</span></code></a></p></li>
</ul>
<p>sparklyr and tidyverse Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pillar.r-lib.org/reference/glimpse.html"><code class="docutils literal notranslate"><span class="pre">glimpse()</span></code></a></p></li>
</ul>
<p>Base R Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/numeric.html"><code class="docutils literal notranslate"><span class="pre">as.numeric()</span></code></a></p></li>
<li><p><a class="reference external" href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/double.html"><code class="docutils literal notranslate"><span class="pre">as.double()</span></code></a></p></li>
</ul>
<p><span class="xref myst">Spark SQL Functions</span> Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#bigint"><code class="docutils literal notranslate"><span class="pre">bigint</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#double"><code class="docutils literal notranslate"><span class="pre">double</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#to_timestamp"><code class="docutils literal notranslate"><span class="pre">to_timestamp</span></code></a></p></li>
</ul>
<p>sparklyr Source Code:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/sparklyr/sparklyr/blob/eb3e795447887908d9e795512ad08eeeb32eede5/R/dbi_spark_connection.R#L38">dbi_spark_connection.R</a>: shows data type mapping in sparklyr</p></li>
</ul>
<p>Other links:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://databricks.com/blog/2020/07/22/a-comprehensive-look-at-dates-and-timestamps-in-apache-spark-3-0.html">DataBricks blog: A Comprehensive Look at Dates and Timestamps in Apache Spark 3.0</a></p></li>
</ul>
<section id="acknowledgements">
<h3>Acknowledgements<a class="headerlink" href="#acknowledgements" title="Permalink to this headline">#</a></h3>
<p>Thanks to Diogo Marques for assistance with the differences between dates in Spark 2.4 and 3.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./raw-notebooks\data-types"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Wil Roberts & Adrian Prince<br/>
  
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>