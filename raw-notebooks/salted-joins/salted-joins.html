
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Salted Joins &#8212; Spark at the ONS</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-95MGHSRD0S"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-95MGHSRD0S');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Spark at the ONS</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Spark overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/spark-start.html">
   Getting Started with Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/when-to-use-spark.html">
   When To Use Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/spark-session-guidance.html">
   Guidance on Spark Sessions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/example-spark-sessions.html">
   Example Spark Sessions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/spark-defaults.html">
   Configuration Hierarchy and
   <code class="docutils literal notranslate">
    <span class="pre">
     spark-defaults.conf
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/data-types.html">
   Data Types in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/creating-dataframes.html">
   Creating DataFrames Manually
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/data-storage.html">
   Data Storage
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to PySpark
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyspark-intro/pyspark-intro.html">
   Introduction to PySpark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyspark-intro/reading-data-pyspark.html">
   Reading Data in PySpark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyspark-intro/returning-data.html">
   Returning Data from Cluster to Driver
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyspark-intro/f-col.html">
   Reference columns by name:
   <code class="docutils literal notranslate">
    <span class="pre">
     F.col()
    </span>
   </code>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to sparklyr
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../sparklyr-intro/sparklyr-intro.html">
   Introduction to sparklyr
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sparklyr-intro/reading-data-sparklyr.html">
   Reading Data in sparklyr
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sparklyr-intro/sparklyr-functions.html">
   Using Spark functions in sparklyr
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Spark functions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/union-dataframes-with-different-columns.html">
   Union two DataFrames with different columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/padding.html">
   Add leading zeros with
   <code class="docutils literal notranslate">
    <span class="pre">
     lpad()
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/sampling.html">
   Sampling:
   <code class="docutils literal notranslate">
    <span class="pre">
     .sample()
    </span>
   </code>
   and
   <code class="docutils literal notranslate">
    <span class="pre">
     sdf_sample()
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/pivot-tables.html">
   Pivot tables in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/rounding.html">
   Rounding differences in Python, R and Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/window-functions.html">
   Window Functions in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/cross-joins.html">
   Cross Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/arrays.html">
   Arrays Functions in PySpark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/writing-data.html">
   Writing Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/job-description.html">
   Set Spark Job Description
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Understanding and Optimising Spark
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/optimisation-tips.html">
   Ideas for optimising Spark code
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/spark-application-and-ui.html">
   Spark Application and UI
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/shuffling.html">
   Shuffling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/join-concepts.html">
   Optimising Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/salted-joins.html">
   Salted Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/partitions.html">
   Managing Partitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/persistence.html">
   Persisting in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/cache.html">
   Caching
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../checkpoint-staging/checkpoint-staging.html">
   Checkpoint
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/garbage-collection.html">
   Garbage Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/df-order.html">
   Spark DataFrames Are Not Ordered
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/exercises.html">
   Exercises
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Testing and Debugging
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../testing-debugging/spark-errors.html">
   Understanding and Handling Spark Errors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../testing-debugging/unit-testing.html">
   Unit Testing in Spark
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ancillary Topics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ancillary-topics/visualisation.html">
   Spark and Visualisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ancillary-topics/module-imports.html">
   Naming Conflicts in Module Imports
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ancillary-topics/pydoop.html">
   Pydoop: HDFS to pandas
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/best-practice-and-impact/ons-spark/main?urlpath=tree/docs/raw-notebooks/salted-joins/salted-joins.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/best-practice-and-impact/ons-spark"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/best-practice-and-impact/ons-spark/issues/new?title=Issue%20on%20page%20%2Fraw-notebooks/salted-joins/salted-joins.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/raw-notebooks/salted-joins/salted-joins.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#salted-join-example">
   Salted Join Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#salting-alternatives">
   Salting Alternatives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-resources">
   Further Resources
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Salted Joins</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#salted-join-example">
   Salted Join Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#salting-alternatives">
   Salting Alternatives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-resources">
   Further Resources
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="salted-joins">
<h1>Salted Joins<a class="headerlink" href="#salted-joins" title="Permalink to this headline">#</a></h1>
<p>When joining DataFrames in Spark with a Sort Merge Join, all the data with the same join keys will be moved to the same partition. Spark works best when partitions are of roughly equal size. If the data are skewed so that some partitions are much larger than others, then a disproportionate amount of time will be spent on dealing with data in one partition.</p>
<p>Attempting to force a repartition of the DataFrame with <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.repartition.html"><code class="docutils literal notranslate"><span class="pre">.repartition()</span></code></a> (PySpark) or <a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/sdf_repartition.html"><code class="docutils literal notranslate"><span class="pre">sdf_repartition()</span></code></a> (sparklyr) will not work, as a Sort Merge Join will then automatically shuffle the data based on join keys. Note that this issue will not occur if the smaller DataFrame is able to be broadcast, since that does not force a shuffle of the DataFrames.</p>
<p>To resolve this issue, we can change the join keys manually, so that the larger partitions get split into smaller ones. This is called <em>salting</em>.</p>
<section id="salted-join-example">
<h2>Salted Join Example<a class="headerlink" href="#salted-join-example" title="Permalink to this headline">#</a></h2>
<p>First, create a Spark session. Note that the DataFrame used in this example is artificially created and is ten million rows long, so this may not work if using a local session with only a small amount of memory. Note that broadcast joins are being disabled by default.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
from pyspark.sql import SparkSession, functions as F

spark = (SparkSession.builder.master(&quot;local[2]&quot;)
         .appName(&quot;joins&quot;)
         # Disable Broadcast join by default
         .config(&quot;spark.sql.autoBroadcastJoinThreshold&quot;, -1)
         .getOrCreate())
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">sparklyr</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>

<span class="n">no_broadcast_config</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_config</span><span class="p">()</span>

<span class="c1"># Disable Broadcast join by default</span>
<span class="n">no_broadcast_config</span><span class="o">$</span><span class="n">spark.sql.autoBroadcastJoinThreshold</span> <span class="o">&lt;-</span> <span class="m">-1</span>

<span class="n">sc</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_connect</span><span class="p">(</span>
  <span class="n">master</span> <span class="o">=</span> <span class="s">&quot;local[2]&quot;</span><span class="p">,</span>
  <span class="n">app_name</span> <span class="o">=</span> <span class="s">&quot;joins&quot;</span><span class="p">,</span>
  <span class="n">config</span> <span class="o">=</span> <span class="n">no_broadcast_config</span><span class="p">)</span>
</pre></div>
</div>
<p>Create a DataFrame with excessive skew by using <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.range.html"><code class="docutils literal notranslate"><span class="pre">spark.range()</span></code></a>/<a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/sdf_seq.html"><code class="docutils literal notranslate"><span class="pre">sdf_seq()</span></code></a> to create a one column DF with an <code class="docutils literal notranslate"><span class="pre">id</span></code> column, then assigning an arbitrary letter from <code class="docutils literal notranslate"><span class="pre">A</span></code> to <code class="docutils literal notranslate"><span class="pre">E</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>row_ct = 10**7
skewed_df = spark.range(row_ct).withColumn(&quot;join_col&quot;, F.when(F.col(&quot;id&quot;) &lt; 100, &quot;A&quot;)
                               .when(F.col(&quot;id&quot;) &lt; 1000, &quot;B&quot;)
                               .when(F.col(&quot;id&quot;) &lt; 10000, &quot;C&quot;)
                               .when(F.col(&quot;id&quot;) &lt; 100000, &quot;D&quot;)
                               .otherwise(&quot;E&quot;))
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">row_ct</span> <span class="o">&lt;-</span> <span class="m">10</span> <span class="o">**</span> <span class="m">7</span>
<span class="n">skewed_df</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_seq</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="n">row_ct</span> <span class="o">-</span> <span class="m">1</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">join_col</span> <span class="o">=</span> <span class="n">dplyr</span><span class="o">::</span><span class="nf">case_when</span><span class="p">(</span>
        <span class="n">id</span> <span class="o">&lt;</span> <span class="m">100</span> <span class="o">~</span> <span class="s">&quot;A&quot;</span><span class="p">,</span>
        <span class="n">id</span> <span class="o">&lt;</span> <span class="m">1000</span> <span class="o">~</span> <span class="s">&quot;B&quot;</span><span class="p">,</span>
        <span class="n">id</span> <span class="o">&lt;</span> <span class="m">10000</span> <span class="o">~</span> <span class="s">&quot;C&quot;</span><span class="p">,</span>
        <span class="n">id</span> <span class="o">&lt;</span> <span class="m">100000</span> <span class="o">~</span> <span class="s">&quot;D&quot;</span><span class="p">,</span>
        <span class="kc">TRUE</span> <span class="o">~</span> <span class="s">&quot;E&quot;</span><span class="p">))</span>
</pre></div>
</div>
<p>To show just how skewed this DF is, group the data by <code class="docutils literal notranslate"><span class="pre">join_col</span></code> and get the row count; 99% of the values of <code class="docutils literal notranslate"><span class="pre">join_col</span></code> are <code class="docutils literal notranslate"><span class="pre">&quot;E&quot;</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>(skewed_df
    .groupBy(&quot;join_col&quot;)
    .count()
    .withColumn(&quot;pct_of_data&quot;, F.round((F.col(&quot;count&quot;) / row_ct) * 100, 3))
    .show())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+--------+-------+-----------+
|join_col|  count|pct_of_data|
+--------+-------+-----------+
|       E|9900000|       99.0|
|       B|    900|      0.009|
|       D|  90000|        0.9|
|       C|   9000|       0.09|
|       A|    100|      0.001|
+--------+-------+-----------+
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">skewed_df</span> <span class="o">%&gt;%</span>
    <span class="n">dplyr</span><span class="o">::</span><span class="nf">group_by</span><span class="p">(</span><span class="n">join_col</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">dplyr</span><span class="o">::</span><span class="nf">summarise</span><span class="p">(</span><span class="n">count</span> <span class="o">=</span> <span class="nf">n</span><span class="p">())</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">pct_of_data</span> <span class="o">=</span> <span class="nf">round</span><span class="p">((</span><span class="n">count</span> <span class="o">/</span> <span class="n">row_ct</span><span class="p">)</span> <span class="o">*</span> <span class="m">100</span><span class="p">,</span> <span class="m">3</span><span class="p">))</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>Create another DF, <code class="docutils literal notranslate"><span class="pre">small_df</span></code> that will be joined to <code class="docutils literal notranslate"><span class="pre">skewed_df</span></code>. This is a simple mapping of letters to numbers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>small_df = spark.createDataFrame([
    [&quot;A&quot;, 1],
    [&quot;B&quot;, 2],
    [&quot;C&quot;, 3],
    [&quot;D&quot;, 4],
    [&quot;E&quot;, 5]
], [&quot;join_col&quot;, &quot;number_col&quot;])
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">small_df</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_copy_to</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="nf">data.frame</span><span class="p">(</span>
    <span class="n">join_col</span> <span class="o">=</span> <span class="kc">LETTERS</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">],</span>
    <span class="n">number_col</span> <span class="o">=</span> <span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">))</span>
</pre></div>
</div>
<p>Now join, using the default Sort Merge Join:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>joined_df = skewed_df.join(small_df, on=&quot;join_col&quot;, how=&quot;left&quot;)
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">joined_df</span> <span class="o">&lt;-</span> <span class="n">skewed_df</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">left_join</span><span class="p">(</span><span class="n">small_df</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s">&quot;join_col&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We want to see how the DataFrame is processed on the cluster using the Spark UI, so use <code class="docutils literal notranslate"><span class="pre">.count()</span></code> and <span class="xref myst">set the job description</span> with <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.SparkContext.setJobDescription.html"><code class="docutils literal notranslate"><span class="pre">.setJobDescription()</span></code></a>/<a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/invoke.html"><code class="docutils literal notranslate"><span class="pre">invoke(&quot;setJobDescription&quot;,</span> <span class="pre">...)</span></code></a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>spark.sparkContext.setJobDescription(&quot;Row Count&quot;)
joined_df.count()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>10000000
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_context</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">invoke</span><span class="p">(</span><span class="s">&quot;setJobDescription&quot;</span><span class="p">,</span> <span class="s">&quot;Row Count&quot;</span><span class="p">)</span>

<span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_nrow</span><span class="p">(</span><span class="n">joined_df</span><span class="p">)</span>
</pre></div>
</div>
<p>Group the data to verify the result of the join:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>spark.sparkContext.setJobDescription(&quot;Show Grouped Data&quot;)
joined_df.groupBy(&quot;join_col&quot;, &quot;number_col&quot;).count().show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+--------+----------+-------+
|join_col|number_col|  count|
+--------+----------+-------+
|       E|         5|9900000|
|       B|         2|    900|
|       D|         4|  90000|
|       C|         3|   9000|
|       A|         1|    100|
+--------+----------+-------+
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_context</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">invoke</span><span class="p">(</span><span class="s">&quot;setJobDescription&quot;</span><span class="p">,</span> <span class="s">&quot;Show Grouped Data&quot;</span><span class="p">)</span>

<span class="n">joined_df</span> <span class="o">%&gt;%</span>
    <span class="n">dplyr</span><span class="o">::</span><span class="nf">group_by</span><span class="p">(</span><span class="n">join_col</span><span class="p">,</span> <span class="n">number_col</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">dplyr</span><span class="o">::</span><span class="nf">summarise</span><span class="p">(</span><span class="n">count</span> <span class="o">=</span> <span class="nf">n</span><span class="p">())</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>Looking at the <span class="xref myst">Spark UI</span> (the Spark UI link for a local session is <a class="reference external" href="http://localhost:4040/jobs/">http://localhost:4040/jobs/</a>) for the <code class="docutils literal notranslate"><span class="pre">Row</span> <span class="pre">Count</span></code> job, we can see that one partition is taking much longer than the rest to process:</p>
<figure class="align-default" id="skewedjointimeline">
<a class="reference internal image-reference" href="raw-notebooks/images/presalt_ui.png"><img alt="Stage details page in Spark UI showing inefficient processing of a skewed DF" src="raw-notebooks/images/presalt_ui.png" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">Timeline for skewed join</span><a class="headerlink" href="#skewedjointimeline" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>This is because all of the data with the same join key will be on the same partition. To split this up, we can <em>salt</em> the keys. Salting is the process of artificially creating new join keys. For instance, the <code class="docutils literal notranslate"><span class="pre">E</span></code> key could be split into ten new keys, called <code class="docutils literal notranslate"><span class="pre">E-0</span></code>, <code class="docutils literal notranslate"><span class="pre">E-1</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">E-9</span></code>. Provided the salting is identical in both DataFrames the result of the join will be correct. As with any similar process, ensure that your code is fully tested.</p>
<p>The easiest way to do this is by concatenating a random number to the key in both DataFrames. We are using a seed here for reproducibility.</p>
<p>In this example we will salt every key as we do not have many unique values in our key column, but you can also use <code class="docutils literal notranslate"><span class="pre">F.when()</span></code> to salt only specified values if you wish.</p>
<p>We could change <code class="docutils literal notranslate"><span class="pre">salt_count</span></code> here; 10 is used as an example but you can change this depending on just how skewed your data are. Our example of 99% of the join keys being the same value is deliberately extreme and a higher <code class="docutils literal notranslate"><span class="pre">salt_count</span></code> would likely improve the efficiency. As with a lot of Spark issues, it is good to experiment and see what works best for your own situation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>spark.sparkContext.setJobDescription(&quot;Salted Join&quot;)
salt_count = 10
seed_no = 123
skewed_df = skewed_df.withColumn(&quot;salted_col&quot;,
                                 F.concat(
                                     # Salted column will be in the format A-0, A-1...E-9
                                     F.col(&quot;join_col&quot;),
                                     F.lit(&quot;-&quot;),
                                     F.floor(F.rand(seed_no) * salt_count)))
skewed_df.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+---+--------+----------+
| id|join_col|salted_col|
+---+--------+----------+
|  0|       A|       A-5|
|  1|       A|       A-9|
|  2|       A|       A-8|
|  3|       A|       A-8|
|  4|       A|       A-3|
|  5|       A|       A-4|
|  6|       A|       A-1|
|  7|       A|       A-5|
|  8|       A|       A-9|
|  9|       A|       A-1|
| 10|       A|       A-8|
| 11|       A|       A-2|
| 12|       A|       A-2|
| 13|       A|       A-0|
| 14|       A|       A-4|
| 15|       A|       A-7|
| 16|       A|       A-9|
| 17|       A|       A-7|
| 18|       A|       A-4|
| 19|       A|       A-1|
+---+--------+----------+
only showing top 20 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_context</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">invoke</span><span class="p">(</span><span class="s">&quot;setJobDescription&quot;</span><span class="p">,</span> <span class="s">&quot;Salted Join&quot;</span><span class="p">)</span>

<span class="n">salt_count</span> <span class="o">&lt;-</span> <span class="m">10</span>
<span class="n">seed_no</span> <span class="o">&lt;-</span> <span class="m">123L</span>
<span class="n">skewed_df</span> <span class="o">&lt;-</span> <span class="n">skewed_df</span> <span class="o">%&gt;%</span>
    <span class="c1"># Salted column will be in the format A-0, A-1...E-9</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">salted_col</span> <span class="o">=</span> <span class="nf">concat_ws</span><span class="p">(</span><span class="s">&quot;-&quot;</span><span class="p">,</span> <span class="n">join_col</span><span class="p">,</span> <span class="nf">floor</span><span class="p">(</span><span class="nf">rand</span><span class="p">(</span><span class="n">seed_no</span><span class="p">)</span> <span class="o">*</span> <span class="n">salt_count</span><span class="p">)))</span>

<span class="n">skewed_df</span> <span class="o">%&gt;%</span>
    <span class="nf">head</span><span class="p">(</span><span class="m">20</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>We now need to join on <code class="docutils literal notranslate"><span class="pre">salted_col</span></code>, so obviously need to create this column in <code class="docutils literal notranslate"><span class="pre">skewed_df</span></code> too. We can achieve this with a <span class="xref myst">cross join</span> (also sometimes called the cartesian product), to generate all the combinations of the salted values. Be careful when using cross joins as the number of rows returned will be the product of the row count in the two DataFrames.</p>
<p>Create a DataFrame of the numbers 0 to 9:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>salt_df = spark.range(salt_count)
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">salt_df</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_seq</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="m">0</span><span class="p">,</span> <span class="n">salt_count</span> <span class="o">-</span> <span class="m">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Cross join this to <code class="docutils literal notranslate"><span class="pre">small_df</span></code> to generate every combination, then concatenate it in the same way as previously:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>small_df_salted = (small_df
                   .crossJoin(salt_df)
                   .withColumn(&quot;salted_col&quot;,
                               F.concat(
                                   F.col(&quot;join_col&quot;),
                                   F.lit(&quot;-&quot;),
                                   F.col(&quot;id&quot;)
                               ))
                   .drop(&quot;id&quot;, &quot;join_col&quot;))
small_df_salted.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+----------+----------+
|number_col|salted_col|
+----------+----------+
|         1|       A-0|
|         1|       A-1|
|         1|       A-2|
|         1|       A-3|
|         1|       A-4|
|         2|       B-0|
|         2|       B-1|
|         2|       B-2|
|         2|       B-3|
|         2|       B-4|
|         1|       A-5|
|         1|       A-6|
|         1|       A-7|
|         1|       A-8|
|         1|       A-9|
|         2|       B-5|
|         2|       B-6|
|         2|       B-7|
|         2|       B-8|
|         2|       B-9|
+----------+----------+
only showing top 20 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">small_df_salted</span> <span class="o">&lt;-</span> <span class="n">small_df</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">full_join</span><span class="p">(</span><span class="n">salt_df</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="nf">character</span><span class="p">())</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">salted_col</span> <span class="o">=</span> <span class="nf">concat_ws</span><span class="p">(</span><span class="s">&quot;-&quot;</span><span class="p">,</span> <span class="n">join_col</span><span class="p">,</span> <span class="n">id</span><span class="p">))</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">id</span><span class="p">,</span> <span class="o">-</span><span class="n">join_col</span><span class="p">)</span>

<span class="n">small_df_salted</span> <span class="o">%&gt;%</span>
    <span class="nf">head</span><span class="p">(</span><span class="m">20</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>Now join on <code class="docutils literal notranslate"><span class="pre">salted_col</span></code> and <code class="docutils literal notranslate"><span class="pre">.count()</span></code> the DataFrame, once again setting the job description first:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>salted_join_df = skewed_df.join(small_df_salted, on=&quot;salted_col&quot;, how=&quot;left&quot;)
spark.sparkContext.setJobDescription(&quot;Salted Join Row Count&quot;)
salted_join_df.count()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>10000000
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">salted_join_df</span> <span class="o">&lt;-</span> <span class="n">skewed_df</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">left_join</span><span class="p">(</span><span class="n">small_df_salted</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s">&quot;salted_col&quot;</span><span class="p">)</span>

<span class="n">sc</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_context</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">invoke</span><span class="p">(</span><span class="s">&quot;setJobDescription&quot;</span><span class="p">,</span> <span class="s">&quot;Salted Join Row Count&quot;</span><span class="p">)</span>

<span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_nrow</span><span class="p">(</span><span class="n">salted_join_df</span><span class="p">)</span>
</pre></div>
</div>
<p>Verify that the result was the same as before:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>spark.sparkContext.setJobDescription(&quot;Salted Join Show Grouped Data&quot;)
salted_join_df.groupBy(&quot;join_col&quot;, &quot;number_col&quot;).count().show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+--------+----------+-------+
|join_col|number_col|  count|
+--------+----------+-------+
|       D|         4|  90000|
|       A|         1|    100|
|       E|         5|9900000|
|       C|         3|   9000|
|       B|         2|    900|
+--------+----------+-------+
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_context</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">invoke</span><span class="p">(</span><span class="s">&quot;setJobDescription&quot;</span><span class="p">,</span> <span class="s">&quot;Salted Join Show Grouped Data&quot;</span><span class="p">)</span>

<span class="n">joined_df</span> <span class="o">%&gt;%</span>
    <span class="n">dplyr</span><span class="o">::</span><span class="nf">group_by</span><span class="p">(</span><span class="n">join_col</span><span class="p">,</span> <span class="n">number_col</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">dplyr</span><span class="o">::</span><span class="nf">summarise</span><span class="p">(</span><span class="n">count</span> <span class="o">=</span> <span class="nf">n</span><span class="p">())</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>Finally, look at the Spark UI for <code class="docutils literal notranslate"><span class="pre">Salted</span> <span class="pre">Join</span> <span class="pre">Row</span> <span class="pre">Count</span></code> to see that the parallelism is improved:</p>
<figure class="align-default" id="saltedjointimeline">
<a class="reference internal image-reference" href="raw-notebooks/images/salt_ui.png"><img alt="Stage details page in Spark UI showing improved efficiency of a salted DF being joined" src="raw-notebooks/images/salt_ui.png" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">Timeline for salted join</span><a class="headerlink" href="#saltedjointimeline" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The key metric here is not the overall time, but how the work is distributed. It is shared more equally and there is no longer one long green bar taking far longer than the other processes. In real life examples where salting is essential you will find that the Spark UI looks much more efficient; obviously this is only a minimal example.</p>
</section>
<section id="salting-alternatives">
<h2>Salting Alternatives<a class="headerlink" href="#salting-alternatives" title="Permalink to this headline">#</a></h2>
<p>Salting is not the only option for dealing with skewed DataFrames:</p>
<ul class="simple">
<li><p><a class="reference external" href="../spark-concepts/join-concepts.html#broadcast-join">Broadcasting</a> the smaller DataFrame removes the need for a shuffle of the larger DF, and so the partitioning will remain the same. A broadcast join should also be more efficient than salting.</p></li>
<li><p>Some parts of the join could be achieved with conditional statements, e.g. split the DF into two and use <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.when.html"><code class="docutils literal notranslate"><span class="pre">F.when()</span></code></a>/<a class="reference external" href="https://dplyr.tidyverse.org/reference/case_when.html"><code class="docutils literal notranslate"><span class="pre">case_when()</span></code></a> for the larger join keys then a regular join for the rest.</p></li>
<li><p>Reducing the size of the larger DataFrame may be possible in some circumstances, e.g. by grouping or filtering earlier in the process.</p></li>
<li><p>If salting only leads to minor improvements in efficiency you may prefer not to salt and just use a regular <a class="reference external" href="../spark-concepts/join-concepts.html#sort-merge-join">sort merge join</a>; you may feel that the benefits of the code being more readable and requiring less testing are worth a small sacrifice of efficiency</p></li>
</ul>
</section>
<section id="further-resources">
<h2>Further Resources<a class="headerlink" href="#further-resources" title="Permalink to this headline">#</a></h2>
<p>Spark at the ONS Articles:</p>
<ul class="simple">
<li><p><span class="xref myst">Spark Application and UI</span></p></li>
<li><p><span class="xref myst">Set Spark Job Description</span></p></li>
<li><p><span class="xref myst">Cross Joins</span></p></li>
<li><p><span class="xref myst">Optimising Joins</span></p>
<ul>
<li><p><a class="reference external" href="../spark-concepts/join-concepts.html#broadcast-join">Broadcast Join</a></p></li>
<li><p><a class="reference external" href="../spark-concepts/join-concepts.html#sort-merge-join">Sort Merge Join</a></p></li>
</ul>
</li>
</ul>
<p>PySpark Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.repartition.html"><code class="docutils literal notranslate"><span class="pre">.repartition()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.range.html"><code class="docutils literal notranslate"><span class="pre">spark.range()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.when.html"><code class="docutils literal notranslate"><span class="pre">F.when()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.SparkContext.setJobDescription.html"><code class="docutils literal notranslate"><span class="pre">.setJobDescription()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rand.html"><code class="docutils literal notranslate"><span class="pre">F.rand()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.concat.html"><code class="docutils literal notranslate"><span class="pre">F.concat()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.floor.html"><code class="docutils literal notranslate"><span class="pre">F.floor()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.crossJoin.html"><code class="docutils literal notranslate"><span class="pre">.crossJoin()</span></code></a></p></li>
</ul>
<p>sparklyr and tidyverse Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/sdf_repartition.html"><code class="docutils literal notranslate"><span class="pre">sdf_repartition()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/sdf_seq.html"><code class="docutils literal notranslate"><span class="pre">sdf_seq()</span></code></a></p></li>
<li><p><a class="reference external" href="https://dplyr.tidyverse.org/reference/case_when.html"><code class="docutils literal notranslate"><span class="pre">case_when()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/invoke.html"><code class="docutils literal notranslate"><span class="pre">invoke()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/join.tbl_spark.html"><code class="docutils literal notranslate"><span class="pre">full_join()</span></code></a>: there is no native cross join function in sparklyr; the documentation recommends using <code class="docutils literal notranslate"><span class="pre">by=character()</span></code></p></li>
</ul>
<p>Spark SQL Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#case_when"><code class="docutils literal notranslate"><span class="pre">case_when</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#rand"><code class="docutils literal notranslate"><span class="pre">rand</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#concat_ws"><code class="docutils literal notranslate"><span class="pre">concat_ws</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#floor"><code class="docutils literal notranslate"><span class="pre">floor</span></code></a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./raw-notebooks/salted-joins"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Wil Roberts & Adrian Prince<br/>
  
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>