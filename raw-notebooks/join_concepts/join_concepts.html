
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Optimising Joins &#8212; Spark at the ONS</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Spark at the ONS</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Introduction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Spark overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/spark-session-guidance.html">
   Spark Sessions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/example-spark-sessions.html">
   Example Spark Sessions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-overview/spark-defaults.html">
   Configuration Hierarchy and
   <code class="docutils literal notranslate">
    <span class="pre">
     spark-defaults.conf
    </span>
   </code>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to PySpark
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyspark-intro/pyspark-intro.html">
   Introduction to PySpark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyspark-intro/pyspark-intro-exercises.html">
   Introduction to PySpark: Exercises
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pyspark-intro/f-col.html">
   Reference columns by name:
   <code class="docutils literal notranslate">
    <span class="pre">
     F.col()
    </span>
   </code>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to sparklyr
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../sparklyr-intro/sparklyr_functions.html">
   Using Spark functions in sparklyr
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Spark functions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/union_dataframes_with_different_columns.html">
   Union two DataFrames with different columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/padding.html">
   Add leading zeros with
   <code class="docutils literal notranslate">
    <span class="pre">
     lpad()
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/sampling.html">
   Sampling:
   <code class="docutils literal notranslate">
    <span class="pre">
     .sample()
    </span>
   </code>
   and
   <code class="docutils literal notranslate">
    <span class="pre">
     sdf_sample()
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/pivot-tables.html">
   Pivot tables in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/rounding.html">
   Rounding differences in Python, R and Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/window-functions.html">
   Window Functions in Spark
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Understanding and Optimising Spark
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/spark_application_and_ui.html">
   Spark Application and UI
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/shuffling.html">
   Shuffling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/join_concepts.html">
   Optimising Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-functions/cross_joins.html">
   Cross Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/salted_joins.html">
   Salted Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/partitions.html">
   Managing partitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../spark-concepts/exercises.html">
   Exercises
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ancillary Topics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ancillary-topics/visualisation.html">
   Spark and Visualisation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/raw-notebooks/join_concepts/join_concepts.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/robertswh/Spark at the ONS"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/robertswh/Spark at the ONS/issues/new?title=Issue%20on%20page%20%2Fraw-notebooks/join_concepts/join_concepts.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/robertswh/Spark at the ONS/main?urlpath=tree/docs/raw-notebooks/join_concepts/join_concepts.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-join-algorithms-in-spark">
   The Join Algorithms in Spark
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#shuffle-hash-join">
   Shuffle Hash Join
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sort-merge-join">
   Sort Merge Join
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sort-merge-join-example">
     Sort Merge Join Example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#understanding-sort-merge-join">
     Understanding Sort Merge Join
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#broadcast-join">
   Broadcast Join
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-using-a-broadcast-hint">
     Example: Using a Broadcast Hint
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-automatic-broadcasting">
     Example: Automatic Broadcasting
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#replacing-a-join-with-a-narrow-transformation">
   Replacing a join with a narrow transformation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-narrow-transformations">
     Example: Narrow Transformations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#when-to-use-each-method">
   When to use each method
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#salted-joins">
   Salted Joins
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-resources">
   Further Resources
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Optimising Joins</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-join-algorithms-in-spark">
   The Join Algorithms in Spark
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#shuffle-hash-join">
   Shuffle Hash Join
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sort-merge-join">
   Sort Merge Join
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sort-merge-join-example">
     Sort Merge Join Example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#understanding-sort-merge-join">
     Understanding Sort Merge Join
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#broadcast-join">
   Broadcast Join
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-using-a-broadcast-hint">
     Example: Using a Broadcast Hint
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-automatic-broadcasting">
     Example: Automatic Broadcasting
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#replacing-a-join-with-a-narrow-transformation">
   Replacing a join with a narrow transformation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-narrow-transformations">
     Example: Narrow Transformations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#when-to-use-each-method">
   When to use each method
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#salted-joins">
   Salted Joins
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-resources">
   Further Resources
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="section" id="optimising-joins">
<h1>Optimising Joins<a class="headerlink" href="#optimising-joins" title="Permalink to this headline">¶</a></h1>
<p>Joining DataFrames is a common and often essential operation in Spark. However, joins are one of the more expensive operations in terms of processing time. This is because by default both source DataFrames are first sorted, which is a <em>wide transformation</em>, causing a <em>shuffle</em> (or <em>exchange</em>). As such, it is worth paying extra attention to where joins occur in the code and trying to figure out which method to use to make them more efficient.</p>
<p>This article describes the different join algorithms in Spark, explains how they work, when to use them, and shows examples of each. It also covers replacing joins entirely with narrow transformations, and gives a brief overview of <em>salted joins</em>, that can be used when the data are skewed.</p>
<p>Before reading this article ensure that you understand how to join two DataFrames in Spark. Knowledge of shuffles and the difference between wide and narrow transformations will also help understanding of why some methods are faster than others, although not mandatory. Useful resources on this include the <a class="reference external" href="https://databricks.com/glossary/what-are-transformations">DataBricks Transformations definition</a>, and the Spark Application and UI, Shuffles and Partitions articles in this book.</p>
<p>It’s important to note that in this notebook when we talk about different joins and the way they are processed we aren’t talking about left, right, inner or outer joins, but how it is processed on the cluster. The result of the join will always be the same, regardless of which of the algorithms described in this article is used.</p>
<p>This article uses both PySpark and sparklyr examples; note that the outputs from the cells are from Python, the R output may be formatted slightly differently.</p>
<div class="section" id="the-join-algorithms-in-spark">
<h2>The Join Algorithms in Spark<a class="headerlink" href="#the-join-algorithms-in-spark" title="Permalink to this headline">¶</a></h2>
<p>You do not need to know how joins work when writing Spark code, but you can make them more efficient by understanding that there are different ways for them to be processed and coding appropriately. These are:</p>
<ul class="simple">
<li><p>Shuffle Hash Join</p></li>
<li><p>Sort Merge Join</p></li>
<li><p>Broadcast Join</p></li>
<li><p>Other Methods</p></li>
</ul>
<p>We will look at each in more detail, get a better idea of how they are processed by looking at the Spark UI. We will then compare them and give the advantages and disadvantages of using each.</p>
</div>
<div class="section" id="shuffle-hash-join">
<h2>Shuffle Hash Join<a class="headerlink" href="#shuffle-hash-join" title="Permalink to this headline">¶</a></h2>
<p>In the development of Spark, the shuffle hash join was the original join implementation.</p>
<p>This consists of two stages: <em>shuffle</em> and <em>hash</em>. First a <em>shuffle</em>, where data with the same keys from both DataFrames are moved to the same executors. Once all the data are on the relevant executors, they are joined using the hash join algorithm. This involves building a hash table in memory and may fail for some larger joins.</p>
<p>Shuffle hash joins will not be explored further as they have been superseded by sort merge join, which is similar apart from the processing stage.</p>
</div>
<div class="section" id="sort-merge-join">
<h2>Sort Merge Join<a class="headerlink" href="#sort-merge-join" title="Permalink to this headline">¶</a></h2>
<p>This is now the default method of joining two DataFrames in Spark.</p>
<p>It consists of two key stages, as suggested by the name: <em>sort</em> and <em>merge</em>.</p>
<p>First of all, the data in each DataFrame will be sorted. A sort operation requires a shuffle on each DataFrame. This will also ensure that all the same key values are on the same partition. This also means that the join can be done in parallel on each partition, although it can potentially be a problem if your data are skewed (in which case a <em>salted join</em> may be useful).</p>
<p>Now that both DataFrames are ordered, it is easy to iterate over each row in the DataFrames and see if they have a matching key; if they do, they can be returned as part of the resulting DataFrame. In most circumstances this will be more efficient than the shuffle hash join.</p>
<p>This diagram should help explain this visually:</p>
<p><img alt="Diagram showing how a sort merge join works" src="raw-notebooks/images/sort_merge_join.png" /></p>
<p>Both sort merge joins and shuffle hash joins use a shuffle; the difference is in the processing stage, where the former uses a searching algorithm and the latter uses a hash table.</p>
<div class="section" id="sort-merge-join-example">
<h3>Sort Merge Join Example<a class="headerlink" href="#sort-merge-join-example" title="Permalink to this headline">¶</a></h3>
<p>Let’s see an example of a sort merge join and then look at the plan and the Spark UI. The example uses the Animal Rescue (as CSV) and Population (as parquet) datasets, left joining on the <code class="docutils literal notranslate"><span class="pre">postcode_district</span></code>. Note that we are disabling automatic broadcast joins by setting <code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code> to <code class="docutils literal notranslate"><span class="pre">-1</span></code>; broadcast joins are covered in the next section. First, start a Spark session, read the data and select and rename the relevant columns:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">yaml</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span><span class="p">,</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span><span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[2]&quot;</span><span class="p">)</span>
         <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;joins&quot;</span><span class="p">)</span>
         <span class="c1"># Disable broadcast join by default</span>
         <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.sql.autoBroadcastJoinThreshold&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
         <span class="o">.</span><span class="n">getOrCreate</span><span class="p">())</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;../../../config.yaml&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    
<span class="n">rescue_path</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;rescue_path_csv&quot;</span><span class="p">]</span>
<span class="n">population_path</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;population_path&quot;</span><span class="p">]</span>

<span class="n">rescue</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">rescue_path</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;IncidentNumber&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;incident_number&quot;</span><span class="p">),</span>
    <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;CalYear&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;cal_year&quot;</span><span class="p">),</span>
    <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;AnimalGroupParent&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;animal_group&quot;</span><span class="p">),</span>
    <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;PostcodeDistrict&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;postcode_district&quot;</span><span class="p">))</span>

<span class="n">population</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">population_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">sparklyr</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>

<span class="n">joins_config</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_config</span><span class="p">()</span>
<span class="c1"># Disable broadcast join by default</span>
<span class="n">joins_config</span><span class="o">$</span><span class="n">spark.sql.autoBroadcastJoinThreshold</span> <span class="o">&lt;-</span> <span class="m">-1</span>

<span class="n">sc</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_connect</span><span class="p">(</span>
    <span class="n">master</span> <span class="o">=</span> <span class="s">&quot;local[2]&quot;</span><span class="p">,</span>
    <span class="n">app_name</span> <span class="o">=</span> <span class="s">&quot;joins&quot;</span><span class="p">,</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">joins_config</span><span class="p">)</span>

<span class="n">config</span> <span class="o">&lt;-</span> <span class="n">yaml</span><span class="o">::</span><span class="nf">yaml.load_file</span><span class="p">(</span><span class="s">&quot;ons-spark/config.yaml&quot;</span><span class="p">)</span>

<span class="n">rescue</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_read_csv</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">config</span><span class="o">$</span><span class="n">rescue_path_csv</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="n">incident_number</span> <span class="o">=</span> <span class="n">IncidentNumber</span><span class="p">,</span>
                     <span class="n">cal_year</span><span class="o">=</span> <span class="n">CalYear</span><span class="p">,</span>
                     <span class="n">animal_group</span> <span class="o">=</span> <span class="n">AnimalGroupParent</span><span class="p">,</span>
                     <span class="n">postcode_district</span> <span class="o">=</span> <span class="n">PostcodeDistrict</span><span class="p">)</span>


<span class="n">population</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_read_parquet</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">config</span><span class="o">$</span><span class="n">population_path</span><span class="p">)</span>            
</pre></div>
</div>
<p>Preview both DataFrames; we can see the desired join column, <code class="docutils literal notranslate"><span class="pre">postcode_district</span></code>, is present and contains data in a standard postcode format:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">population</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+---------------+--------+------------+-----------------+
|incident_number|cal_year|animal_group|postcode_district|
+---------------+--------+------------+-----------------+
|         139091|    2009|         Dog|             SE19|
|         275091|    2009|         Fox|             SE25|
|        2075091|    2009|         Dog|              SM5|
|        2872091|    2009|       Horse|              UB9|
|        3553091|    2009|      Rabbit|              RM3|
+---------------+--------+------------+-----------------+
only showing top 5 rows

+-----------------+----------+
|postcode_district|population|
+-----------------+----------+
|              DH7|     41076|
|              NW3|     52376|
|              NR4|     22331|
|             SO31|     44742|
|             CT18|     14357|
+-----------------+----------+
only showing top 5 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue</span> <span class="o">%&gt;%</span>
    <span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
    
<span class="n">population</span> <span class="o">%&gt;%</span>
    <span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>We can now join these on <code class="docutils literal notranslate"><span class="pre">PostcodeDistrict</span></code>, using <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.join.html"><code class="docutils literal notranslate"><span class="pre">.join()</span></code></a> with <code class="docutils literal notranslate"><span class="pre">how=&quot;left&quot;</span></code> in PySpark or <a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/join.tbl_spark.html"><code class="docutils literal notranslate"><span class="pre">left_join()</span></code></a> in sparklyr, then preview:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">rescue</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">population</span><span class="p">,</span>
        <span class="n">on</span><span class="o">=</span><span class="s2">&quot;postcode_district&quot;</span><span class="p">,</span>
        <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">rescue_with_pop</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+-----------------+---------------+--------+--------------------+----------+
|postcode_district|incident_number|cal_year|        animal_group|population|
+-----------------+---------------+--------+--------------------+----------+
|             SE17|        6259091|    2009|Unknown - Domesti...|     32866|
|             SE17|        6317091|    2009|                 Cat|     32866|
|             SE17|       17297091|    2009|                 Dog|     32866|
|             SE17|       74801101|    2010|            Squirrel|     32866|
|             SE17|       64851111|    2011|                 Dog|     32866|
+-----------------+---------------+--------+--------------------+----------+
only showing top 5 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop</span> <span class="o">&lt;-</span> <span class="n">rescue</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">left_join</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s">&quot;postcode_district&quot;</span><span class="p">)</span>

<span class="n">rescue_with_pop</span> <span class="o">%&gt;%</span>
    <span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>Note that the order of the DataFrame hasn’t been preserved and that this preview has only given us rows with idential <code class="docutils literal notranslate"><span class="pre">PostcodeDistrict</span></code> values. This is due to two Spark concepts: lazy evaluation and the sort merge join algorithm. As the action only requires five rows to be returned, Spark can get all these from the first partition rather than having to return data from multiple partitions, ensuring that the job is completed faster. The sort merge join algorithm has sorted the DataFrame by the hashed join key, and put all these values in the first partition, and so these are the values that are returned. See the article on partitions for more information.</p>
<p>We know the result of the join, but to see how Spark actually processed the join we need to look at the <em>plan</em>. Remember that Spark has the concept of <em>lazy evaluation</em>, in which rather than process code line-by-line like in a pandas or base R DataFrame, we instead create a <em>plan</em> which gets executed on the cluster in one go when an <em>action</em> is called. We can see this plan with <code class="docutils literal notranslate"><span class="pre">explain()</span></code>, a <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.explain.html">DataFrame method</a> in PySpark and <a class="reference external" href="https://dplyr.tidyverse.org/reference/explain.html">dplyr function</a> in sparklyr.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>== Physical Plan ==
*(5) Project [postcode_district#65, incident_number#62, cal_year#63, animal_group#64, population#71L]
+- SortMergeJoin [postcode_district#65], [postcode_district#70], LeftOuter
   :- *(2) Sort [postcode_district#65 ASC NULLS FIRST], false, 0
   :  +- Exchange hashpartitioning(postcode_district#65, 200)
   :     +- *(1) Project [IncidentNumber#10 AS incident_number#62, CalYear#12 AS cal_year#63, AnimalGroupParent#20 AS animal_group#64, PostcodeDistrict#31 AS postcode_district#65]
   :        +- *(1) FileScan csv [IncidentNumber#10,CalYear#12,AnimalGroupParent#20,PostcodeDistrict#31] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/animal_rescue.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;IncidentNumber:string,CalYear:int,AnimalGroupParent:string,PostcodeDistrict:string&gt;
   +- *(4) Sort [postcode_district#70 ASC NULLS FIRST], false, 0
      +- Exchange hashpartitioning(postcode_district#70, 200)
         +- *(3) Project [postcode_district#70, population#71L]
            +- *(3) Filter isnotnull(postcode_district#70)
               +- *(3) FileScan parquet [postcode_district#70,population#71L] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/population.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(postcode_district)], ReadSchema: struct&lt;postcode_district:string,population:bigint&gt;
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop</span> <span class="o">%&gt;%</span> <span class="n">dplyr</span><span class="o">::</span><span class="nf">explain</span><span class="p">()</span>
</pre></div>
</div>
<p>Spark plans can be tricky to read if you’re not familiar with them but we can see some key terms being used:</p>
<ul class="simple">
<li><p>We are doing a <code class="docutils literal notranslate"><span class="pre">SortMergeJoin</span></code>, of type <code class="docutils literal notranslate"><span class="pre">LeftOuter</span></code></p></li>
<li><p>Before that, each DataFrame is being sorted and shuffled; the name for this on the plan is an <code class="docutils literal notranslate"><span class="pre">Exchange</span></code>.</p></li>
<li><p>The data are being read with <code class="docutils literal notranslate"><span class="pre">FileScan</span> <span class="pre">csv</span></code> and <code class="docutils literal notranslate"><span class="pre">FileScan</span> <span class="pre">parquet</span></code></p></li>
<li><p>As this was a left join, we don’t need to return any values from <code class="docutils literal notranslate"><span class="pre">population</span></code> where <code class="docutils literal notranslate"><span class="pre">OutwardCode</span></code> is <code class="docutils literal notranslate"><span class="pre">null</span></code>, so Spark is filtering these out at source with <code class="docutils literal notranslate"><span class="pre">PushedFilters:</span> <span class="pre">[IsNotNull(OutwardCode)]</span></code>.</p></li>
</ul>
<p>We can view the plan visually with the Spark UI on the SQL tab. See the Spark Application and UI article for details on how to access the Spark UI, and the Persisting article for more details on interpreting the information in the SQL tab.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spark_ui_url</span> <span class="o">=</span> <span class="s2">&quot;spark-</span><span class="si">%s</span><span class="s2">.</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CDSW_ENGINE_ID&quot;</span><span class="p">],</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CDSW_DOMAIN&quot;</span><span class="p">])</span>
<span class="n">spark_ui_url</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;spark-rgho0m50if2n1upk.cdswmn-d01-01.ons.statistics.gov.uk&#39;
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">spark_ui_url</span> <span class="o">&lt;-</span> <span class="nf">paste0</span><span class="p">(</span>
    <span class="s">&quot;http://&quot;</span><span class="p">,</span>
    <span class="s">&quot;spark-&quot;</span><span class="p">,</span>
    <span class="nf">Sys.getenv</span><span class="p">(</span><span class="s">&quot;CDSW_ENGINE_ID&quot;</span><span class="p">),</span>
    <span class="s">&quot;.&quot;</span><span class="p">,</span>
    <span class="nf">Sys.getenv</span><span class="p">(</span><span class="s">&quot;CDSW_DOMAIN&quot;</span><span class="p">))</span>

<span class="n">spark_ui_url</span>
</pre></div>
</div>
<p><img alt="Spark UI for sort merge join, showing an exchange for both DataFrames" src="raw-notebooks/images/sort_merge_join_ui.png" /></p>
<p>This diagram has the same information as the <code class="docutils literal notranslate"><span class="pre">explain()</span></code>, just presented in a much nicer way. Again, we can see that there is an <strong>Exchange</strong> for each DataFrame, before the <strong>SortMergeJoin</strong>, and a <strong>Filter</strong> when reading the parquet.</p>
</div>
<div class="section" id="understanding-sort-merge-join">
<h3>Understanding Sort Merge Join<a class="headerlink" href="#understanding-sort-merge-join" title="Permalink to this headline">¶</a></h3>
<p>The sort merge join involves two <strong>Exchanges</strong> (also called <em>shuffles</em>), one for the sorting of each source DataFrame (see the Shuffles article for a full discussion of this topic). Spark is most powerful when it can process data in parallel (<em>narrow transformations</em>), and sorting is instead a <em>wide transformation</em>, causing a <em>shuffle</em>, meaning that a sort merge join can take significant time to process, depending on the size and composition of your data. There is a full discussion in the when to use each join method section.</p>
<p>The sort merge join is the <em>default</em> join although not always chosen automatically; the next section on <em>broadcast joins</em> explains this further.</p>
</div>
</div>
<div class="section" id="broadcast-join">
<h2>Broadcast Join<a class="headerlink" href="#broadcast-join" title="Permalink to this headline">¶</a></h2>
<p>The other common method is the broadcast join. This can be used when you are joining a small DataFrame to a large one. The smaller DataFrame is copied to every node on the cluster and then a traditional hash join is performed. This avoids the need for the sorting step that exists in the sort merge join, and therefore the expensive shuffles.</p>
<p>Broadcast joins are suitable when you are joining a small DataFrame to a larger one. As one DataFrame is pushed to several places, this may actually be too slow or impossible if you are joining two large DataFrames.</p>
<p>The diagram below shows how a broadcast join works visually:</p>
<p><img alt="Diagram showing how a broadcast join works" src="raw-notebooks/images/broadcast_join.png" /></p>
<p>There are two ways to trigger a broadcast join:</p>
<ol class="simple">
<li><p>Use the broadcast hint: <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.broadcast.html"><code class="docutils literal notranslate"><span class="pre">F.broadcast()</span></code></a> in PySpark or <a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/sdf_broadcast.html"><code class="docutils literal notranslate"><span class="pre">sdf_broadcast()</span></code></a> in sparklyr</p></li>
<li><p>Spark will use a broadcast join by default if the size of the DataFrame to be broadcast is known and smaller 10MB; this value can be changed with the <a class="reference external" href="https://spark.apache.org/docs/latest/sql-performance-tuning.html"><code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code></a> configuration setting.</p></li>
</ol>
<div class="section" id="example-using-a-broadcast-hint">
<h3>Example: Using a Broadcast Hint<a class="headerlink" href="#example-using-a-broadcast-hint" title="Permalink to this headline">¶</a></h3>
<p>We can use the same source DataFrames as the sort merge join example, <code class="docutils literal notranslate"><span class="pre">rescue</span></code> and <code class="docutils literal notranslate"><span class="pre">population</span></code>. To perform a broadcast join, we just add the broadcast join hint <code class="docutils literal notranslate"><span class="pre">F.broadcast()</span></code>/<code class="docutils literal notranslate"><span class="pre">sdf_broadcast()</span></code> around <code class="docutils literal notranslate"><span class="pre">population</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_broadcast</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">rescue</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">F</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">population</span><span class="p">),</span>
        <span class="n">on</span><span class="o">=</span><span class="s2">&quot;postcode_district&quot;</span><span class="p">,</span>
        <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">rescue_with_pop_broadcast</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+-----------------+---------------+--------+------------+----------+
|postcode_district|incident_number|cal_year|animal_group|population|
+-----------------+---------------+--------+------------+----------+
|             SE19|         139091|    2009|         Dog|     27639|
|             SE25|         275091|    2009|         Fox|     34521|
|              SM5|        2075091|    2009|         Dog|     38291|
|              UB9|        2872091|    2009|       Horse|     14336|
|              RM3|        3553091|    2009|      Rabbit|     40272|
+-----------------+---------------+--------+------------+----------+
only showing top 5 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_broadcast</span> <span class="o">&lt;-</span> <span class="n">rescue</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">left_join</span><span class="p">(</span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_broadcast</span><span class="p">(</span><span class="n">population</span><span class="p">),</span> <span class="n">by</span><span class="o">=</span><span class="s">&quot;postcode_district&quot;</span><span class="p">)</span>

<span class="n">rescue_with_pop_broadcast</span> <span class="o">%&gt;%</span>
    <span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>Unlike the first example, the <code class="docutils literal notranslate"><span class="pre">postcode_district</span></code> values are not identical. The DataFrame has not needed to be shuffled and so the same <code class="docutils literal notranslate"><span class="pre">PostcodeDistrict</span></code> values may be on different partitions.</p>
<p><code class="docutils literal notranslate"><span class="pre">explain()</span></code> will confirm that a broadcast join was used:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_broadcast</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>== Physical Plan ==
*(2) Project [postcode_district#65, incident_number#62, cal_year#63, animal_group#64, population#71L]
+- *(2) BroadcastHashJoin [postcode_district#65], [postcode_district#70], LeftOuter, BuildRight
   :- *(2) Project [IncidentNumber#10 AS incident_number#62, CalYear#12 AS cal_year#63, AnimalGroupParent#20 AS animal_group#64, PostcodeDistrict#31 AS postcode_district#65]
   :  +- *(2) FileScan csv [IncidentNumber#10,CalYear#12,AnimalGroupParent#20,PostcodeDistrict#31] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/animal_rescue.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;IncidentNumber:string,CalYear:int,AnimalGroupParent:string,PostcodeDistrict:string&gt;
   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))
      +- *(1) Project [postcode_district#70, population#71L]
         +- *(1) Filter isnotnull(postcode_district#70)
            +- *(1) FileScan parquet [postcode_district#70,population#71L] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/population.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(postcode_district)], ReadSchema: struct&lt;postcode_district:string,population:bigint&gt;
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_broadcast</span> <span class="o">%&gt;%</span> <span class="n">dplyr</span><span class="o">::</span><span class="nf">explain</span><span class="p">()</span>
</pre></div>
</div>
<p>We can see that we are now using a <strong>BroadcastHashJoin</strong>. Let’s look at the UI again:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spark_ui_url</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;spark-eejet47wnollgkuz.cdswmn-d01-01.ons.statistics.gov.uk&#39;
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">spark_ui_url</span>
</pre></div>
</div>
<p><img alt="Spark UI for broadcast join, showing a broadcast exchange" src="raw-notebooks/images/broadcast_join_ui.png" /></p>
<p>The difference from the sort merge join example is that rather than two shuffles, there is a <strong>BroadcastExchange</strong> then a <strong>BroadcastHashJoin</strong>. If the second DataFrame is small, pushing it to executors should take less time than the two full shuffles which occur in the sort merge join example.</p>
</div>
<div class="section" id="example-automatic-broadcasting">
<h3>Example: Automatic Broadcasting<a class="headerlink" href="#example-automatic-broadcasting" title="Permalink to this headline">¶</a></h3>
<p>In addition to broadcasting explicitly with the hint, Spark will use a broadcast join automatically if the size of the smaller DataFrame is known and below 10MB.</p>
<p>You can change this value with the <code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code> configuration setting. This has to be a <code class="docutils literal notranslate"><span class="pre">long</span></code> DataType, so 10MB is equal to <span class="math notranslate nohighlight">\(10\times1024^2\)</span>. Automatic broadcasting can be turned off by setting it to <code class="docutils literal notranslate"><span class="pre">-1</span></code>, as we did in the previous example.</p>
<p>As we already have a Spark session running, we need to close this down and create another, ensuring that a new value for <code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code> is defined. Be careful when closing and starting Spark sessions, as previous configuration settings will be used unless specifically overwritten.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span><span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[2]&quot;</span><span class="p">)</span>
         <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;joins&quot;</span><span class="p">)</span>
          <span class="c1"># Automatically broadcast DataFrames less than 10MB</span>
          <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.sql.autoBroadcastJoinThreshold&quot;</span><span class="p">,</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
          <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_disconnect</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>

<span class="n">joins_config</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_config</span><span class="p">()</span>
<span class="c1"># Automatically broadcast DataFrames less than 10MB</span>
<span class="n">joins_config</span><span class="o">$</span><span class="n">spark.sql.autoBroadcastJoinThreshold</span> <span class="o">&lt;-</span> <span class="m">10</span> <span class="o">*</span> <span class="m">1024</span><span class="o">**</span><span class="m">2</span>

<span class="n">sc</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_connect</span><span class="p">(</span>
    <span class="n">master</span> <span class="o">=</span> <span class="s">&quot;local[2]&quot;</span><span class="p">,</span>
    <span class="n">app_name</span> <span class="o">=</span> <span class="s">&quot;joins&quot;</span><span class="p">,</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">joins_config</span><span class="p">)</span>
</pre></div>
</div>
<p>As this is a new Spark session our old DataFrames no longer exist, so we need to create them again:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">rescue_path</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;IncidentNumber&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;incident_number&quot;</span><span class="p">),</span>
    <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;CalYear&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;cal_year&quot;</span><span class="p">),</span>
    <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;AnimalGroupParent&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;animal_group&quot;</span><span class="p">),</span>
    <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;PostcodeDistrict&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;postcode_district&quot;</span><span class="p">),</span>
    <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;OriginofCall&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">))</span>

<span class="n">population</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">population_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_read_csv</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">config</span><span class="o">$</span><span class="n">rescue_path_csv</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="n">incident_number</span> <span class="o">=</span> <span class="n">IncidentNumber</span><span class="p">,</span>
                     <span class="n">cal_year</span><span class="o">=</span> <span class="n">CalYear</span><span class="p">,</span>
                     <span class="n">animal_group</span> <span class="o">=</span> <span class="n">AnimalGroupParent</span><span class="p">,</span>
                     <span class="n">postcode_district</span> <span class="o">=</span> <span class="n">PostcodeDistrict</span><span class="p">,</span>
                     <span class="n">origin_of_call</span> <span class="o">=</span> <span class="n">OriginofCall</span><span class="p">)</span>

<span class="n">population</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">spark_read_parquet</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">config</span><span class="o">$</span><span class="n">population_path</span><span class="p">)</span>
</pre></div>
</div>
<p>Now try the join. Note that this is identical code to in the sort merge join example, but it will be automatically broadcast as the second DataFrame is below 10MB.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_auto_broadcast</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">rescue</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">population</span><span class="p">,</span>
        <span class="n">on</span><span class="o">=</span><span class="s2">&quot;postcode_district&quot;</span><span class="p">,</span>
        <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">rescue_with_pop_auto_broadcast</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+-----------------+---------------+--------+------------+------------------+----------+
|postcode_district|incident_number|cal_year|animal_group|    origin_of_call|population|
+-----------------+---------------+--------+------------+------------------+----------+
|             SE19|         139091|    2009|         Dog|Person (land line)|     27639|
|             SE25|         275091|    2009|         Fox|Person (land line)|     34521|
|              SM5|        2075091|    2009|         Dog|   Person (mobile)|     38291|
|              UB9|        2872091|    2009|       Horse|   Person (mobile)|     14336|
|              RM3|        3553091|    2009|      Rabbit|   Person (mobile)|     40272|
+-----------------+---------------+--------+------------+------------------+----------+
only showing top 5 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_auto_broadcast</span><span class="o">&lt;-</span> <span class="n">rescue</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">left_join</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s">&quot;postcode_district&quot;</span><span class="p">)</span>

<span class="n">rescue_with_pop_auto_broadcast</span> <span class="o">%&gt;%</span>
    <span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>This can be confirmed with <code class="docutils literal notranslate"><span class="pre">explain()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_auto_broadcast</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>== Physical Plan ==
*(2) Project [postcode_district#213, incident_number#210, cal_year#211, animal_group#212, origin_of_call#214, population#221L]
+- *(2) BroadcastHashJoin [postcode_district#213], [postcode_district#220], LeftOuter, BuildRight
   :- *(2) Project [IncidentNumber#158 AS incident_number#210, CalYear#160 AS cal_year#211, AnimalGroupParent#168 AS animal_group#212, PostcodeDistrict#179 AS postcode_district#213, OriginofCall#169 AS origin_of_call#214]
   :  +- *(2) FileScan csv [IncidentNumber#158,CalYear#160,AnimalGroupParent#168,OriginofCall#169,PostcodeDistrict#179] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/animal_rescue.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;IncidentNumber:string,CalYear:int,AnimalGroupParent:string,OriginofCall:string,PostcodeDis...
   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))
      +- *(1) Project [postcode_district#220, population#221L]
         +- *(1) Filter isnotnull(postcode_district#220)
            +- *(1) FileScan parquet [postcode_district#220,population#221L] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/population.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(postcode_district)], ReadSchema: struct&lt;postcode_district:string,population:bigint&gt;
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_pop_auto_broadcast</span> <span class="o">%&gt;%</span> <span class="n">dplyr</span><span class="o">::</span><span class="nf">explain</span><span class="p">()</span>
</pre></div>
</div>
<p>Both ways of broadcasting give the same result. You can leave it to Spark to decide, or if you want more control over how you DataFrames are joined, turn off automatic broadcasting by setting <code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code> to <code class="docutils literal notranslate"><span class="pre">-1</span></code>.</p>
<p>Note that Spark will not always be able to determine the size of the data in which case it will default to a sort merge join, even when this would be significantly less efficient. Spark does have some non-instinctive behaviour when it comes to automatic broadcasting; generally, if the raw file is less than 10MB it will be broadcast regardless of file type. Large parquet files which are filtered or grouped to reduce the size should be broadcast but the same is not true of CSVs. If unsure, use <code class="docutils literal notranslate"><span class="pre">explain()</span></code> to check or manually broadcast with the broadcast hint.</p>
</div>
</div>
<div class="section" id="replacing-a-join-with-a-narrow-transformation">
<h2>Replacing a join with a narrow transformation<a class="headerlink" href="#replacing-a-join-with-a-narrow-transformation" title="Permalink to this headline">¶</a></h2>
<p>If your second DataFrame is tiny, you could potentially even not do a join at all, and replace it with a series of <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.when.html"><code class="docutils literal notranslate"><span class="pre">F.when()</span></code></a> statements in PySpark or <a class="reference external" href="https://dplyr.tidyverse.org/reference/case_when.html"><code class="docutils literal notranslate"><span class="pre">case_when()</span></code></a> in sparklyr. These will be processed as a <em>narrow transformation</em> in parallel rather than a <em>wide transformation</em>, meaning that it should be quicker than joining using the usual methods.</p>
<p>The following diagram from the  shows how this works visually; the <code class="docutils literal notranslate"><span class="pre">F.when()</span></code>/<code class="docutils literal notranslate"><span class="pre">case_when()</span></code> method is a narrow <em>narrow transformation</em> is within the same stage, rather than a <em>wide transformation</em> between stages:</p>
<p><img alt="Diagram showing wide and narrow transformations" src="raw-notebooks/images/application_and_ui.png" /></p>
<div class="section" id="example-narrow-transformations">
<h3>Example: Narrow Transformations<a class="headerlink" href="#example-narrow-transformations" title="Permalink to this headline">¶</a></h3>
<p>The rescue data has a column, <code class="docutils literal notranslate"><span class="pre">origin_of_call</span></code>, which contains information about who reported the incident.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+---------------------+
|origin_of_call       |
+---------------------+
|Coastguard           |
|Person (mobile)      |
|Person (land line)   |
|Other FRS            |
|Not known            |
|Police               |
|Person (running call)|
|Ambulance            |
+---------------------+
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue</span> <span class="o">%&gt;%</span> 
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="n">origin_of_call</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_distinct</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>Let’s categorise these into <code class="docutils literal notranslate"><span class="pre">Emergency</span> <span class="pre">Services</span></code> and <code class="docutils literal notranslate"><span class="pre">Member</span> <span class="pre">of</span> <span class="pre">Public</span></code>; there is also a <code class="docutils literal notranslate"><span class="pre">Not</span> <span class="pre">known</span></code> value which can be mapped to <code class="docutils literal notranslate"><span class="pre">null</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">call_origin</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s2">&quot;Coastguard&quot;</span><span class="p">,</span> <span class="s2">&quot;Emergency Services&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Police&quot;</span><span class="p">,</span> <span class="s2">&quot;Emergency Services&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Ambulance&quot;</span><span class="p">,</span> <span class="s2">&quot;Emergency Services&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Other FRS&quot;</span><span class="p">,</span> <span class="s2">&quot;Emergency Services&quot;</span><span class="p">],</span> <span class="c1">#Other fire and rescue services</span>
    <span class="p">[</span><span class="s2">&quot;Person (mobile)&quot;</span><span class="p">,</span> <span class="s2">&quot;Member of Public&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Person (land line)&quot;</span><span class="p">,</span> <span class="s2">&quot;Member of Public&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Person (running call)&quot;</span><span class="p">,</span> <span class="s2">&quot;Member of Public&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Not known&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],],</span>
    <span class="p">[</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">,</span> <span class="s2">&quot;origin_type&quot;</span><span class="p">])</span>

<span class="n">call_origin</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+---------------------+------------------+
|origin_of_call       |origin_type       |
+---------------------+------------------+
|Coastguard           |Emergency Services|
|Police               |Emergency Services|
|Ambulance            |Emergency Services|
|Other FRS            |Emergency Services|
|Person (mobile)      |Member of Public  |
|Person (land line)   |Member of Public  |
|Person (running call)|Member of Public  |
|Not known            |null              |
+---------------------+------------------+
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">call_origin</span> <span class="o">&lt;-</span> <span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_copy_to</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="nf">data.frame</span><span class="p">(</span>
    <span class="s">&quot;origin_of_call&quot;</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&quot;Coastguard&quot;</span><span class="p">,</span> <span class="s">&quot;Police&quot;</span><span class="p">,</span> <span class="s">&quot;Ambulance&quot;</span><span class="p">,</span> <span class="s">&quot;Other FRS&quot;</span><span class="p">,</span>
                         <span class="s">&quot;Person (mobile)&quot;</span><span class="p">,</span> <span class="s">&quot;Person (land line)&quot;</span><span class="p">,</span> <span class="s">&quot;Person (running call)&quot;</span><span class="p">,</span>
                         <span class="s">&quot;Not known&quot;</span><span class="p">),</span>
    <span class="s">&quot;origin_type&quot;</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Emergency Services&quot;</span><span class="p">),</span> <span class="m">4</span><span class="p">),</span>
                      <span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Member of Public&quot;</span><span class="p">),</span> <span class="m">3</span><span class="p">),</span>
                      <span class="kc">NA</span><span class="p">)))</span>

<span class="n">call_origin</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>We can do a left join, as we have done previously. As the DataFrame is small, we will ensure it is broadcast with the broadcast hint:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_origin</span> <span class="o">=</span> <span class="n">rescue</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">call_origin</span><span class="p">),</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>

<span class="n">rescue_with_origin</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s2">&quot;incident_number&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+------------------+----------------+--------+--------------------------------+-----------------+------------------+
|origin_of_call    |incident_number |cal_year|animal_group                    |postcode_district|origin_type       |
+------------------+----------------+--------+--------------------------------+-----------------+------------------+
|Other FRS         |000014-03092018M|2018    |Unknown - Heavy Livestock Animal|CR8              |Emergency Services|
|Person (mobile)   |000099-01012017 |2017    |Dog                             |BR2              |Member of Public  |
|Person (land line)|000260-01012017 |2017    |Bird                            |CR0              |Member of Public  |
|Person (mobile)   |000375-01012017 |2017    |Dog                             |TW8              |Member of Public  |
|Person (mobile)   |000477-01012017 |2017    |Deer                            |HA7              |Member of Public  |
+------------------+----------------+--------+--------------------------------+-----------------+------------------+
only showing top 5 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_origin</span> <span class="o">&lt;-</span> <span class="n">rescue</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">left_join</span><span class="p">(</span><span class="n">sparklyr</span><span class="o">::</span><span class="nf">sdf_broadcast</span><span class="p">(</span><span class="n">call_origin</span><span class="p">),</span> <span class="n">by</span><span class="o">=</span><span class="s">&quot;origin_of_call&quot;</span><span class="p">)</span>

<span class="n">rescue_with_origin</span> <span class="o">%&gt;%</span>
    <span class="n">dplyr</span><span class="o">::</span><span class="nf">arrange</span><span class="p">(</span><span class="n">incident_number</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<p>An alternative to a join here is using chained <code class="docutils literal notranslate"><span class="pre">F.when()</span></code> statements in PySpark or <code class="docutils literal notranslate"><span class="pre">case_when</span></code> inside <code class="docutils literal notranslate"><span class="pre">mutate</span></code> in sparklyr.</p>
<p>The three <code class="docutils literal notranslate"><span class="pre">origin_of_call</span></code> which map to <code class="docutils literal notranslate"><span class="pre">Member</span> <span class="pre">of</span> <span class="pre">Public</span></code> all begin with <code class="docutils literal notranslate"><span class="pre">Person</span></code>. We can take the first six characters with <code class="docutils literal notranslate"><span class="pre">substr()</span></code> (a <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.substr.html">column method</a> in PySpark and a <a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#substr">Spark SQL function</a> in sparklyr), and if this equals <code class="docutils literal notranslate"><span class="pre">Person</span></code> we know that this is <code class="docutils literal notranslate"><span class="pre">Member</span> <span class="pre">of</span> <span class="pre">Public</span></code>.</p>
<p>We can put the values which map to <code class="docutils literal notranslate"><span class="pre">Emergency</span> <span class="pre">Services</span></code> in an <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.isin.html"><code class="docutils literal notranslate"><span class="pre">.isin()</span></code></a> (PySpark) or <code class="docutils literal notranslate"><span class="pre">%in%</span></code> (sparklyr) statement.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">Not</span> <span class="pre">known</span></code>, a simple equality statement can be used.</p>
<p>Finally, any values not matching any of these criteria can be mapped to <code class="docutils literal notranslate"><span class="pre">null</span></code> with <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.otherwise.html"><code class="docutils literal notranslate"><span class="pre">F.otherwise()</span></code></a> (PySpark) or <code class="docutils literal notranslate"><span class="pre">TRUE</span> <span class="pre">~</span> <span class="pre">NA</span></code> (sparklyr), although no values will match this criteria in our example. Note that this is the default value and could be omitted, but it’s better to be explicit where we can.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_origin_when</span> <span class="o">=</span> <span class="n">rescue</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;origin_type&quot;</span><span class="p">,</span>
                  <span class="n">F</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">substr</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;Person&quot;</span><span class="p">,</span> <span class="s2">&quot;Member of Public&quot;</span><span class="p">)</span>
                   <span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span>
                       <span class="s2">&quot;Coastguard&quot;</span><span class="p">,</span> <span class="s2">&quot;Police&quot;</span><span class="p">,</span> <span class="s2">&quot;Ambulance&quot;</span><span class="p">,</span> <span class="s2">&quot;Other FRS&quot;</span><span class="p">),</span> <span class="s2">&quot;Emergency Services&quot;</span><span class="p">)</span>
                   <span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;origin_of_call&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;Not known&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                   <span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>

<span class="n">rescue_with_origin_when</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s2">&quot;incident_number&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+----------------+--------+--------------------------------+-----------------+------------------+------------------+
|incident_number |cal_year|animal_group                    |postcode_district|origin_of_call    |origin_type       |
+----------------+--------+--------------------------------+-----------------+------------------+------------------+
|000014-03092018M|2018    |Unknown - Heavy Livestock Animal|CR8              |Other FRS         |Emergency Services|
|000099-01012017 |2017    |Dog                             |BR2              |Person (mobile)   |Member of Public  |
|000260-01012017 |2017    |Bird                            |CR0              |Person (land line)|Member of Public  |
|000375-01012017 |2017    |Dog                             |TW8              |Person (mobile)   |Member of Public  |
|000477-01012017 |2017    |Deer                            |HA7              |Person (mobile)   |Member of Public  |
+----------------+--------+--------------------------------+-----------------+------------------+------------------+
only showing top 5 rows
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_origin_when</span> <span class="o">&lt;-</span> <span class="n">rescue</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">origin_type</span> <span class="o">=</span> <span class="nf">case_when</span><span class="p">(</span>
        <span class="nf">substr</span><span class="p">(</span><span class="n">origin_of_call</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="m">6</span><span class="p">)</span> <span class="o">==</span> <span class="s">&quot;Person&quot;</span> <span class="o">~</span> <span class="s">&quot;Member of Public&quot;</span><span class="p">,</span>
        <span class="n">origin_of_call</span> <span class="o">%in%</span> <span class="nf">c</span><span class="p">(</span><span class="s">&quot;Coastguard&quot;</span><span class="p">,</span> <span class="s">&quot;Police&quot;</span><span class="p">,</span> <span class="s">&quot;Ambulance&quot;</span><span class="p">,</span> <span class="s">&quot;Other FRS&quot;</span><span class="p">)</span> <span class="o">~</span> <span class="s">&quot;Emergency Services&quot;</span><span class="p">,</span>
        <span class="n">origin_of_call</span> <span class="o">==</span> <span class="s">&quot;Not known&quot;</span> <span class="o">~</span> <span class="kc">NA</span><span class="p">,</span>
        <span class="kc">TRUE</span> <span class="o">~</span> <span class="kc">NA</span><span class="p">))</span>

<span class="n">rescue_with_origin_when</span> <span class="o">%&gt;%</span>
    <span class="n">dplyr</span><span class="o">::</span><span class="nf">arrange</span><span class="p">(</span><span class="n">incident_number</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="nf">head</span><span class="p">(</span><span class="m">5</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">sparklyr</span><span class="o">::</span><span class="nf">collect</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">print</span><span class="p">()</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_origin_when</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>== Physical Plan ==
*(1) Project [IncidentNumber#158 AS incident_number#210, CalYear#160 AS cal_year#211, AnimalGroupParent#168 AS animal_group#212, PostcodeDistrict#179 AS postcode_district#213, OriginofCall#169 AS origin_of_call#214, CASE WHEN (substring(OriginofCall#169, 1, 6) = Person) THEN Member of Public WHEN OriginofCall#169 IN (Coastguard,Police,Ambulance,Other FRS) THEN Emergency Services WHEN (OriginofCall#169 = Not known) THEN null ELSE null END AS origin_type#301]
+- *(1) FileScan csv [IncidentNumber#158,CalYear#160,AnimalGroupParent#168,OriginofCall#169,PostcodeDistrict#179] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/cdsw/ons-spark/ons-spark/data/animal_rescue.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;IncidentNumber:string,CalYear:int,AnimalGroupParent:string,OriginofCall:string,PostcodeDis...
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">rescue_with_origin_when</span> <span class="o">%&gt;%</span> <span class="n">dplyr</span><span class="o">::</span><span class="nf">explain</span><span class="p">()</span>
</pre></div>
</div>
<p>The plan here confirms that no join is taking place; instead, the conditional statements are interpreted as an SQL style <code class="docutils literal notranslate"><span class="pre">CASE</span> <span class="pre">WHEN</span></code> statement. There are only narrow transformations, meaning that the data can stay within the partitions and no shuffle is needed and therefore should be more efficient than a join.</p>
<p>This can be confirmed by looking at the Spark UI:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spark_ui_url</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;spark-eejet47wnollgkuz.cdswmn-d01-01.ons.statistics.gov.uk&#39;
</pre></div>
</div>
</div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">spark_ui_url</span>
</pre></div>
</div>
<p><img alt="Spark UI for replacing joins with a narrow transformation, showing no exchanges" src="raw-notebooks/images/when_ui.png" /></p>
<p>This plan is far simpler than the other two we saw.</p>
<p>Although it may be tempting to use this method be careful. It is trickier to code and harder to read than a conventional join and also will not work if the source data changes, so if a new value appeared in <code class="docutils literal notranslate"><span class="pre">origin_of_call</span></code> (e.g. the RSPCA or the army, which may want a different <code class="docutils literal notranslate"><span class="pre">origin_type</span></code>) we would have to change the actual code rather than adding new lines to a reference file.</p>
<p>In production code, it is best practice to use unit tests. These are very important when making efficiency improvements, since it is important that any changes do not affect the functionality of the code. See the article on Unit Testing for more details.</p>
</div>
</div>
<div class="section" id="when-to-use-each-method">
<h2>When to use each method<a class="headerlink" href="#when-to-use-each-method" title="Permalink to this headline">¶</a></h2>
<p>We have seen examples of three ways of joining data:</p>
<ul class="simple">
<li><p>Sort Merge Join</p></li>
<li><p>Broadcast Join</p></li>
<li><p>Replacing joins with a narrow transformation</p></li>
</ul>
<p>When should each be used?</p>
<p>First of all, it is most important that your code works. Optimising your code prematurely can lead to errors, so it is often best to not concern yourself with the detail initially and let Spark make the decision.</p>
<p>Once your code is working, the main question to answer is <em>is the second DataFrame small enough to be broadcast effectively?</em> If so, then a broadcast join is the best option. If not, use a sort merge join.</p>
<p>Another question to answer is <em>should I turn the automatic broadcasting on or off</em>? Automatic broadcasting is useful if you’re unsure as Spark will decide for you. It is also good for future-proofing if your source data grows in size, since it will automatically change to a sort merge join once it goes over the threshold; often large datasets started out as a small ones! However, only DataFrames which Spark can calculate the size of will be automatically broadcast; if not, a sort merge join will be used, even if the second DataFrame is tiny. If you’re using automatic broadcasting, check the Spark UI or use <code class="docutils literal notranslate"><span class="pre">explain()</span></code> to verify the type of join.</p>
<p>Some users prefer to have complete control, by setting <code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code> to <code class="docutils literal notranslate"><span class="pre">-1</span></code> and using the broadcast hints (<code class="docutils literal notranslate"><span class="pre">F.broadcast()</span></code>/<code class="docutils literal notranslate"><span class="pre">sdf_broadcast</span></code>). Be careful not to broadcast a DataFrame which grows in size over time if you choose to do this.</p>
<p>You can change the value of <code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code>, which may be useful for those using either very small or very large Spark sessions.</p>
<p>The narrow transformation method was shown mainly to demonstrate that you can replace a join with a narrow transformation in certain circumstances. In practice, as such DataFrames will be tiny they can be broadcast anyway so it is not recommended. Only use this if your source data will never change, and be careful to extensively test and comment your code.</p>
<p>The analysis above assumes that the join keys in the DataFrames are roughly equally partitioned. If your DataFrame is skewed so that some partitions contain significantly more data than others, then the efficiency of the join could be affected. See the article on partitions for more detail. The solution here is to use a <em>salted join</em>.</p>
</div>
<div class="section" id="salted-joins">
<h2>Salted Joins<a class="headerlink" href="#salted-joins" title="Permalink to this headline">¶</a></h2>
<p>A sort merge join will move all the data with the same join keys to the same partition, which can lead to skew in the DataFrame and cause the join to process inefficiently, or not at all in some cases. This can be resolved with a <em>salted join</em>: splitting the join keys, so that the DataFrame is distributed into more equal partition sizes. See the article on salted joins for more information.</p>
</div>
<div class="section" id="further-resources">
<h2>Further Resources<a class="headerlink" href="#further-resources" title="Permalink to this headline">¶</a></h2>
<p>PySpark Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.join.html"><code class="docutils literal notranslate"><span class="pre">.join()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.explain.html"><code class="docutils literal notranslate"><span class="pre">.explain()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.broadcast.html"><code class="docutils literal notranslate"><span class="pre">F.broadcast()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.when.html"><code class="docutils literal notranslate"><span class="pre">F.when()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.otherwise.html"><code class="docutils literal notranslate"><span class="pre">F.otherwise()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.substr.html"><code class="docutils literal notranslate"><span class="pre">substr()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.isin.html"><code class="docutils literal notranslate"><span class="pre">.isin()</span></code></a></p></li>
</ul>
<p>sparklyr Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/join.tbl_spark.html"><code class="docutils literal notranslate"><span class="pre">left_join()</span></code></a></p></li>
<li><p><a class="reference external" href="https://dplyr.tidyverse.org/reference/explain.html"><code class="docutils literal notranslate"><span class="pre">explain()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/sdf_broadcast.html"><code class="docutils literal notranslate"><span class="pre">sdf_broadcast()</span></code></a></p></li>
<li><p><a class="reference external" href="https://dplyr.tidyverse.org/reference/case_when.html"><code class="docutils literal notranslate"><span class="pre">case_when()</span></code></a></p></li>
</ul>
<p>Spark documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/sql-performance-tuning.html">Performance tuning</a>: details of <code class="docutils literal notranslate"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/sql/index.html#substr"><code class="docutils literal notranslate"><span class="pre">substr</span></code></a></p></li>
</ul>
<p>Spark in ONS material:</p>
<ul class="simple">
<li><p>Shuffles</p></li>
<li><p>Spark Application and UI</p></li>
<li><p>Persisting</p></li>
<li><p>Partitions</p></li>
<li><p>Salted Joins</p></li>
<li><p>Spark configuration hierarchy</p></li>
<li><p>Unit testing in Spark</p></li>
</ul>
<p>Other links:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://databricks.com/glossary/what-are-transformations">DataBricks Transformations definition</a></p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./raw-notebooks/join_concepts"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Wil Roberts & Adrian Prince<br/>
    
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>