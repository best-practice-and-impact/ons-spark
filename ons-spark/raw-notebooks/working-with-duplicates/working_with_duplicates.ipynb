{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f2fffb-570c-4b9e-b4c3-607af41fd96b",
   "metadata": {},
   "source": [
    "# Working with Duplicates\n",
    "\n",
    "Duplicated data can cause many issues when it comes to running big data pipelines. There are several things to consider when working with duplicates in your data:\n",
    "1. Dealing with duplicates is something that should be done at the start of your pipeline. However, you will also need to keep in mind that transformations further on in the pipeline (e.g. joins) may also create duplicates and this will need to be checked. \n",
    "2. You need to take into account which variables you are looking for duplicates in: a true duplicate will have duplicated data in all variables. However, in reality, you will most likely find rows which have duplicated data (e.g. id numbers or identifiers) but have differeing data in their other variables. As such, you will need to determine how to deal with such data and whether to keep these entries or filter them based on other variable characteristics. \n",
    "\n",
    "There are several ways of dealing with duplicates in Spark. This section will cover two of the main ways: using Spark's in-built drop duplicates function and an alternative using a Window with a row number.\n",
    "\n",
    "The first thing we will do is start our Spark session and read in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b82c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting spark.hadoop.yarn.resourcemanager.principal to johanna.hall\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "          .appName('working_with_duplicates')\n",
    "          .getOrCreate())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795bdddd",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "library(sparklyr)\n",
    "library(dplyr)\n",
    "library(rlang)\n",
    "\n",
    "sc <- sparklyr::spark_connect(\n",
    "  master = \"yarn-client\",\n",
    "  app_name = \"working_with_duplicates\",\n",
    "  config = default_config)\n",
    "\n",
    "connection_is_open(sc)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c211a41a-5814-4b28-83be-f66f49e1814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#read in MOT dataset and select columns we will be working with\n",
    "\n",
    "mot_path = \"s3a://onscdp-dev-data01-5320d6ca/bat/dapcats/mot_test_results.csv\"\n",
    "\n",
    "mot = (spark.read.csv(mot_path, header=True, inferSchema=True)\n",
    "                 .select(['test_id', \n",
    "                         'vehicle_id', \n",
    "                         'test_date', \n",
    "                         'test_mileage', \n",
    "                         'postcode_area', \n",
    "                         'make', \n",
    "                         'colour', \n",
    "                         'test_result']))\n",
    "\n",
    "#change the date format to yyyy-MM-dd\n",
    "mot = mot.withColumn(\"test_date\", F.to_date(\"test_date\", \"yyyy-MM-dd\"))\n",
    "\n",
    "#remove rows with nulls\n",
    "mot = mot.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1692ec7",
   "metadata": {},
   "source": [
    "```r\n",
    "#read in the MOT dataset and select columns we want to work with\n",
    "mot_path = \"s3a://onscdp-dev-data01-5320d6ca/bat/dapcats/mot_test_results.csv\"\n",
    "\n",
    "mot <- sparklyr::spark_read_csv(sc,\n",
    "    mot_path, \n",
    "    source = \"csv\", \n",
    "    header = TRUE, \n",
    "    infer_schema = TRUE) %>% \n",
    "    sparklyr::select(\n",
    "      test_id,\n",
    "      vehicle_id, \n",
    "      test_date, \n",
    "      test_mileage, \n",
    "      postcode_area, \n",
    "      make, \n",
    "      colour,\n",
    "      test_result)\n",
    "\n",
    "#change the date format to yyyy-MM-dd\n",
    "mot <- mot %>%\n",
    "    dplyr::mutate(test_date = dplyr::sql(\"CAST(test_date AS DATE)\"))\n",
    "\n",
    "#remove rows with nulls\n",
    "mot <- na.omit(mot)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034911c-4603-4c4d-a144-979fffb21608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- test_id: integer (nullable = true)\n",
      " |-- vehicle_id: integer (nullable = true)\n",
      " |-- test_date: date (nullable = true)\n",
      " |-- test_mileage: integer (nullable = true)\n",
      " |-- postcode_area: string (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- colour: string (nullable = true)\n",
      " |-- test_result: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check the schema of the data\n",
    "mot.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a0529",
   "metadata": {},
   "source": [
    "```r\n",
    "#check schema of data\n",
    "sparklyr::sdf_schema(mot)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34f0a63-d826-4a4e-bce7-467747e37136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41892592"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the size of the data we are working with\n",
    "mot.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d0a90",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "#check the size of the data we are working with\n",
    "mot %>%\n",
    "    sparklyr::sdf_nrow()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805d44f-8a59-4d3b-b0cf-c13e135c8a44",
   "metadata": {},
   "source": [
    "Lets start by having a look at a subset of our data. We will be using the DVSA MOT dataset from 2023. We can see that vehicle ID 223981155 is duplicated 863 times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288fbc52-55f1-4523-bec5-8191c7f5ecb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223981155</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1214612397</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1478780109</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>371225013</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1497793597</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>401693765</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43095996</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1316457909</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1357224061</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vehicle_id  count\n",
       "0   223981155    863\n",
       "1  1214612397      9\n",
       "2  1478780109      7\n",
       "3   371225013      7\n",
       "4  1497793597      7\n",
       "5   401693765      7\n",
       "6    43095996      7\n",
       "7  1316457909      7\n",
       "8  1357224061      7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter to vehicles that have passed their MOT and groupby vehicle_id\n",
    "duplicate_count = (mot.filter(F.col('test_result')==\"P\")\n",
    "                .groupBy(\"vehicle_id\").agg(F.count(\"*\").alias(\"count\"))\n",
    "                .filter(F.col(\"count\") > 6)\n",
    "                .orderBy('count', ascending=False))\n",
    "\n",
    "#Show top 10 rows\n",
    "duplicate_count.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc328574",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "#Filter to vehicles that have passed their MOT and groupby vehicle_id\n",
    "duplicate_count <- mot %>%\n",
    "  dplyr::filter(test_result == \"P\") %>%\n",
    "  dplyr::group_by(vehicle_id) %>%\n",
    "  dplyr::summarise(count = dplyr::n(), .groups = 'drop') %>%\n",
    "  dplyr::arrange(dplyr::desc(count)) %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "#Show top 10 rows\n",
    "duplicate_count %>%\n",
    "  head(10) %>%\n",
    "  collect() %>%\n",
    "  print(width = Inf)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe54a3a5-b820-4980-b394-2ffa126c80c9",
   "metadata": {},
   "source": [
    "For demonstration purposes we will take a small sample of vehicle id 223981155. We will restrict results to those vehicles that have passed their MOT. We can then look how many of this vehicle id are in each postcode area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e3cd24-5201-4715-8da4-8137b885cb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|postcode_area|count|\n",
      "+-------------+-----+\n",
      "|           BS|   21|\n",
      "|           NP|   20|\n",
      "|           PE|    8|\n",
      "|           NN|    7|\n",
      "|           WN|    7|\n",
      "|           BB|    7|\n",
      "|           NW|    5|\n",
      "|           SE|    4|\n",
      "|           LU|    2|\n",
      "|           ML|    2|\n",
      "|            E|    1|\n",
      "|           CO|    1|\n",
      "|           TS|    1|\n",
      "|           CF|    1|\n",
      "|           CH|    1|\n",
      "|            N|    1|\n",
      "|           EH|    1|\n",
      "|           DH|    1|\n",
      "|           SR|    1|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sample_path = \"s3a://onscdp-dev-data01-5320d6ca/bat/dapcats/mot_duplicate_sample.parquet\"\n",
    "\n",
    "#Read in a 10% sample of vehicle id 223981155 for demo purposes\n",
    "sample = spark.read.parquet(sample_path)\n",
    "\n",
    "\n",
    "#Check count of this vehicle per postcode area\n",
    "(sample.groupBy('postcode_area').agg(F.count('*').alias('count'))\n",
    "    .orderBy('count', ascending=False)\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a33e89d",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "sample_path = \"s3a://onscdp-dev-data01-5320d6ca/bat/dapcats/mot_duplicate_sample.parquet\"\n",
    "\n",
    "#Read in a 10% sample of vehicle id 223981155 for demo purposes\n",
    "sample <- sparklyr::spark_read_parquet(sc,\n",
    "                                   sample_path,\n",
    "                                   source = \"parquet\")\n",
    "\n",
    "#Check count of this vehicle per postcode area\n",
    "sample %>%\n",
    "  dplyr::group_by(postcode_area) %>%\n",
    "  dplyr::summarise(count = dplyr::n(), .groups = 'drop') %>%\n",
    "  dplyr::arrange(dplyr::desc(count)) %>%\n",
    "  collect() %>%\n",
    "  print(width = Inf) \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c094fedd-133f-4c02-8db7-18af854d17de",
   "metadata": {},
   "source": [
    "## `.dropDuplicates()` or `sparklyr::sdf_drop_duplicates()`\n",
    "\n",
    "\n",
    "We can use the `.dropDuplicates()` or `sparklyr::sdf_drop_duplicates()` function on our sample, which in our case works fine as we are using it on the whole of the sample dataset. This means Spark will search for duplicates across all variables. We can see that there are multiple entries for various postcode areas, but they have different information for `test_id`, `test_date` and `test_mileage` despite having the same `vehicle_id` and `postcode_area`, so are not true duplicates and thus retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "247c8c08-a0b4-4239-a491-8776321c2cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------+-------------+----+------+-----------+\n",
      "|   test_id|vehicle_id| test_date|test_mileage|postcode_area|make|colour|test_result|\n",
      "+----------+----------+----------+------------+-------------+----+------+-----------+\n",
      "|1712482407| 223981155|2023-09-08|      315802|           BB|DVSA| BEIGE|          P|\n",
      "| 608299587| 223981155|2023-09-08|      129365|           BB|DVSA| BEIGE|          P|\n",
      "|1243548035| 223981155|2023-09-08|      118059|           BB|DVSA| BEIGE|          P|\n",
      "|1041508715| 223981155|2023-08-15|      111890|           BB|DVSA| BEIGE|          P|\n",
      "|1569660147| 223981155|2023-09-05|       68311|           BB|DVSA| BEIGE|          P|\n",
      "|1531481473| 223981155|2023-09-09|       37932|           BB|DVSA| BEIGE|          P|\n",
      "| 693596559| 223981155|2023-09-08|       30568|           BB|DVSA| BEIGE|          P|\n",
      "| 243918949| 223981155|2023-09-16|      218001|           BS|DVSA| BEIGE|          P|\n",
      "| 890662963| 223981155|2023-09-16|      197459|           BS|DVSA| BEIGE|          P|\n",
      "| 537036175| 223981155|2023-08-29|      188907|           BS|DVSA| BEIGE|          P|\n",
      "| 250905065| 223981155|2023-08-28|      186254|           BS|DVSA| BEIGE|          P|\n",
      "| 746058855| 223981155|2023-09-19|      185623|           BS|DVSA| BEIGE|          P|\n",
      "|1096998015| 223981155|2023-08-23|      180932|           BS|DVSA| BEIGE|          P|\n",
      "|1517807321| 223981155|2023-09-22|      156503|           BS|DVSA| BEIGE|          P|\n",
      "|1563278235| 223981155|2023-06-20|      155722|           BS|DVSA| BEIGE|          P|\n",
      "|1141589769| 223981155|2023-09-19|      155482|           BS|DVSA| BEIGE|          P|\n",
      "| 291027007| 223981155|2023-09-19|      149706|           BS|DVSA| BEIGE|          P|\n",
      "|1803896485| 223981155|2023-08-11|      143010|           BS|DVSA| BEIGE|          P|\n",
      "|1745334919| 223981155|2023-09-12|      133314|           BS|DVSA| BEIGE|          P|\n",
      "| 972921705| 223981155|2023-08-16|      127893|           BS|DVSA| BEIGE|          P|\n",
      "+----------+----------+----------+------------+-------------+----+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sample.dropDuplicates().sort(['postcode_area', F.desc('test_mileage')]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7e1ffd",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "#Drop duplicates based on all columns\n",
    "sample %>% \n",
    "  sparklyr::sdf_drop_duplicates() %>%\n",
    "  dplyr::arrange(postcode_area, desc(test_mileage)) %>%   \n",
    "  collect() %>%\n",
    "  print(width = Inf)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734e01d-3d9b-41de-9a96-99e473003373",
   "metadata": {},
   "source": [
    "One thing to be aware of when using the `.dropDuplicates()` or `sparklyr::sdf_drop_duplicates()` function is that it is non-deterministic which means it may not always produce the same results on different runs of the code, depending on which variables you are using it on and how your data is partitioned. This is especially pertinent when dropping duplicates on a subset of your data (e.g. specifying a variable, rather than using the function on all variables as was shown above). \n",
    "\n",
    "Let's say we want to keep only one entry from vehicle id 223981155 per postcode area. To do this, we can use `.dropDuplicates()` or `sparklyr::sdf_drop_duplicates()` on the postcode_area variable. We have multiple entries for various postcodes and because we are only providing a single variable to drop duplicates on, Spark will simply keep the first entry of that variable it finds (without considering the values in the other variables). \n",
    "\n",
    "The important thing to note with this is that the results of your code will change **depending on how your data is partitioned**. There is no inherent order to how Spark processes the partitions when using this method, hence the variable results (unless your data is always only stored on 1 partition, then the result will remain the same).\n",
    "\n",
    "The below provides an illustration of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0fb6229-1751-4301-90a8-6c858cd54ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the current partitioning of our data\n",
    "sample.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10a70aa",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "#Check current partition of the data\n",
    "sparklyr::sdf_num_partitions(sample) %>% print()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3abf855-2fe4-48ba-9b22-3294a63b5385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------+-------------+----+------+-----------+\n",
      "|   test_id|vehicle_id| test_date|test_mileage|postcode_area|make|colour|test_result|\n",
      "+----------+----------+----------+------------+-------------+----+------+-----------+\n",
      "|1712482407| 223981155|2023-09-08|      315802|           BB|DVSA| BEIGE|          P|\n",
      "| 979064019| 223981155|2023-09-08|       91546|           BS|DVSA| BEIGE|          P|\n",
      "| 952073263| 223981155|2023-07-25|       43980|           CF|DVSA| BEIGE|          P|\n",
      "|1595426675| 223981155|2023-09-02|      184784|           CH|DVSA| BEIGE|          P|\n",
      "| 194619757| 223981155|2023-08-31|      107114|           CO|DVSA| BEIGE|          P|\n",
      "| 363813511| 223981155|2023-07-24|       68944|           DH|DVSA| BEIGE|          P|\n",
      "| 818121815| 223981155|2023-05-31|      139581|            E|DVSA| BEIGE|          P|\n",
      "| 130590349| 223981155|2023-02-06|      125337|           EH|DVSA| BEIGE|          P|\n",
      "|1621487003| 223981155|2023-04-11|       96702|           LU|DVSA| BEIGE|          P|\n",
      "| 217703609| 223981155|2023-07-28|       32574|           ML|DVSA| BEIGE|          P|\n",
      "| 364306397| 223981155|2023-02-23|       71745|            N|DVSA| BEIGE|          P|\n",
      "| 648395111| 223981155|2023-08-03|      185442|           NN|DVSA| BEIGE|          P|\n",
      "| 182333359| 223981155|2023-09-07|      158000|           NP|DVSA| BEIGE|          P|\n",
      "| 855822481| 223981155|2023-07-20|      152541|           NW|DVSA| BEIGE|          P|\n",
      "| 488527389| 223981155|2023-04-12|      105257|           PE|DVSA| BEIGE|          P|\n",
      "| 585395909| 223981155|2023-03-15|       65240|           SE|DVSA| BEIGE|          P|\n",
      "|  74140977| 223981155|2023-01-14|      144703|           SR|DVSA| BEIGE|          P|\n",
      "|1493456623| 223981155|2023-10-05|       49493|           TS|DVSA| BEIGE|          P|\n",
      "| 378218713| 223981155|2023-04-14|      156723|           WN|DVSA| BEIGE|          P|\n",
      "+----------+----------+----------+------------+-------------+----+------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Drop duplicates on postcode area\n",
    "sample.dropDuplicates(['postcode_area']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8566441",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "#Drop duplicates based on postcode_area\n",
    "sample %>%\n",
    "  sparklyr::sdf_drop_duplicates(cols = \"postcode_area\") %>%\n",
    "  collect() %>%\n",
    "  print(width = Inf)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c89d1a10-504b-4a87-ab74-470e0bd2384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Repartition our data\n",
    "sample = sample.repartition(10)\n",
    "sample.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b0529",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "#Repartition the data\n",
    "sample <- sparklyr::sdf_repartition(sample, partitions = 10)\n",
    "sparklyr::sdf_num_partitions(sample) %>% print()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "582e7904-3e9e-47ec-8ccf-a23fbf28d5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=======================================>                 (7 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------+-------------+----+------+-----------+\n",
      "|   test_id|vehicle_id| test_date|test_mileage|postcode_area|make|colour|test_result|\n",
      "+----------+----------+----------+------------+-------------+----+------+-----------+\n",
      "| 693596559| 223981155|2023-09-08|       30568|           BB|DVSA| BEIGE|          P|\n",
      "|1745334919| 223981155|2023-09-12|      133314|           BS|DVSA| BEIGE|          P|\n",
      "| 952073263| 223981155|2023-07-25|       43980|           CF|DVSA| BEIGE|          P|\n",
      "|1595426675| 223981155|2023-09-02|      184784|           CH|DVSA| BEIGE|          P|\n",
      "| 194619757| 223981155|2023-08-31|      107114|           CO|DVSA| BEIGE|          P|\n",
      "| 363813511| 223981155|2023-07-24|       68944|           DH|DVSA| BEIGE|          P|\n",
      "| 818121815| 223981155|2023-05-31|      139581|            E|DVSA| BEIGE|          P|\n",
      "| 130590349| 223981155|2023-02-06|      125337|           EH|DVSA| BEIGE|          P|\n",
      "|1621487003| 223981155|2023-04-11|       96702|           LU|DVSA| BEIGE|          P|\n",
      "| 804896923| 223981155|2023-06-21|      189384|           ML|DVSA| BEIGE|          P|\n",
      "| 364306397| 223981155|2023-02-23|       71745|            N|DVSA| BEIGE|          P|\n",
      "|1628501733| 223981155|2023-07-13|       75452|           NN|DVSA| BEIGE|          P|\n",
      "|1710297771| 223981155|2023-08-16|      141404|           NP|DVSA| BEIGE|          P|\n",
      "|1356082105| 223981155|2023-06-13|      167670|           NW|DVSA| BEIGE|          P|\n",
      "|1968902105| 223981155|2023-04-14|      116994|           PE|DVSA| BEIGE|          P|\n",
      "|1177098561| 223981155|2023-03-15|      121700|           SE|DVSA| BEIGE|          P|\n",
      "|  74140977| 223981155|2023-01-14|      144703|           SR|DVSA| BEIGE|          P|\n",
      "|1493456623| 223981155|2023-10-05|       49493|           TS|DVSA| BEIGE|          P|\n",
      "|1507431521| 223981155|2023-03-08|      129272|           WN|DVSA| BEIGE|          P|\n",
      "+----------+----------+----------+------------+-------------+----+------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Rerun drop duplicates to see discrepancy\n",
    "sample.dropDuplicates(['postcode_area']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91edf280",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "#Rerun drop duplicates\n",
    "sample %>%\n",
    "  sparklyr::sdf_drop_duplicates(cols = \"postcode_area\") %>%\n",
    "  collect() %>%\n",
    "  print(width = Inf)\n",
    "  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c37de2-96b3-4ddb-93f3-414c81353ec7",
   "metadata": {},
   "source": [
    "## Window method\n",
    "\n",
    "If you are dropping duplicates on a particular variable and want to avoid the inherent non-deterministic nature of `.dropDuplicates()` or `sparklyr::drop_duplicates()`, an alternative method to use is a Window function with `F.row_number()`.\n",
    "\n",
    "Simply `.partitionBy()` (or `dplyr::group_by()` in sparklyr) the same column(s) you want to remove duplicates from and use `.orderBy()` (or `dplyr::arrange()` in sparklyr) to specify the rows you want. This will return the rank within the groups. Note that `F.row_number()` (`dplyr::row_number()` in sparklyr) will return unique values within each group.\n",
    "\n",
    "Let's say we want to retain the record with the highest test mileage in each postcode area. We can use `postcode_area` to partition the data, and then order it by `test_mileage`. We can then apply the `F.row_number()` function to the window to rank each of the entries in that postcode area based on their mileage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29fe39de-6131-44cd-9dca-91eaef7e53cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------+-------------+----+------+-----------+-----+\n",
      "|   test_id|vehicle_id| test_date|test_mileage|postcode_area|make|colour|test_result|row_n|\n",
      "+----------+----------+----------+------------+-------------+----+------+-----------+-----+\n",
      "|1712482407| 223981155|2023-09-08|      315802|           BB|DVSA| BEIGE|          P|    1|\n",
      "| 608299587| 223981155|2023-09-08|      129365|           BB|DVSA| BEIGE|          P|    2|\n",
      "|1243548035| 223981155|2023-09-08|      118059|           BB|DVSA| BEIGE|          P|    3|\n",
      "|1041508715| 223981155|2023-08-15|      111890|           BB|DVSA| BEIGE|          P|    4|\n",
      "|1569660147| 223981155|2023-09-05|       68311|           BB|DVSA| BEIGE|          P|    5|\n",
      "|1531481473| 223981155|2023-09-09|       37932|           BB|DVSA| BEIGE|          P|    6|\n",
      "| 693596559| 223981155|2023-09-08|       30568|           BB|DVSA| BEIGE|          P|    7|\n",
      "| 243918949| 223981155|2023-09-16|      218001|           BS|DVSA| BEIGE|          P|    1|\n",
      "| 890662963| 223981155|2023-09-16|      197459|           BS|DVSA| BEIGE|          P|    2|\n",
      "| 537036175| 223981155|2023-08-29|      188907|           BS|DVSA| BEIGE|          P|    3|\n",
      "| 250905065| 223981155|2023-08-28|      186254|           BS|DVSA| BEIGE|          P|    4|\n",
      "| 746058855| 223981155|2023-09-19|      185623|           BS|DVSA| BEIGE|          P|    5|\n",
      "|1096998015| 223981155|2023-08-23|      180932|           BS|DVSA| BEIGE|          P|    6|\n",
      "|1517807321| 223981155|2023-09-22|      156503|           BS|DVSA| BEIGE|          P|    7|\n",
      "|1563278235| 223981155|2023-06-20|      155722|           BS|DVSA| BEIGE|          P|    8|\n",
      "|1141589769| 223981155|2023-09-19|      155482|           BS|DVSA| BEIGE|          P|    9|\n",
      "| 291027007| 223981155|2023-09-19|      149706|           BS|DVSA| BEIGE|          P|   10|\n",
      "|1803896485| 223981155|2023-08-11|      143010|           BS|DVSA| BEIGE|          P|   11|\n",
      "|1745334919| 223981155|2023-09-12|      133314|           BS|DVSA| BEIGE|          P|   12|\n",
      "| 972921705| 223981155|2023-08-16|      127893|           BS|DVSA| BEIGE|          P|   13|\n",
      "+----------+----------+----------+------------+-------------+----+------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#create our window based on postcode_area, ordered by test_mileage.\n",
    "w = Window.partitionBy('postcode_area').orderBy(F.desc('test_mileage'))\n",
    "\n",
    "#rank the rows within each postcode_area based on mileage.\n",
    "windowed_duplicates = (sample.withColumn('row_n', F.row_number().over(w)))\n",
    "\n",
    "windowed_duplicates.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d4146",
   "metadata": {},
   "source": [
    "```r\n",
    "#create our window based on postcode_area, ordered by test_mileage.\n",
    "#rank the rows within each postcode_area based on mileage.\n",
    "windowed_duplicates <- sample %>%\n",
    "  dplyr::group_by(postcode_area) %>%\n",
    "  dplyr::arrange(desc(test_mileage), .by_group = TRUE) %>%\n",
    "  dplyr::mutate(row_n = dplyr::row_number()) %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "windowed_duplicates %>%\n",
    "  collect() %>%\n",
    "  print(width = Inf)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe08cad-c5ad-4959-a9fb-6722d770e7f1",
   "metadata": {},
   "source": [
    "We can then simply `.filter()` or `dplyr::filter()` the row number to get the first entry of that postcode area. This will retain the vehicle with the highest mileage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ffcdaf9-9ae9-4122-a563-f1ae8ebf5c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------+-------------+----+------+-----------+-----+\n",
      "|   test_id|vehicle_id| test_date|test_mileage|postcode_area|make|colour|test_result|row_n|\n",
      "+----------+----------+----------+------------+-------------+----+------+-----------+-----+\n",
      "|1712482407| 223981155|2023-09-08|      315802|           BB|DVSA| BEIGE|          P|    1|\n",
      "| 243918949| 223981155|2023-09-16|      218001|           BS|DVSA| BEIGE|          P|    1|\n",
      "| 952073263| 223981155|2023-07-25|       43980|           CF|DVSA| BEIGE|          P|    1|\n",
      "|1595426675| 223981155|2023-09-02|      184784|           CH|DVSA| BEIGE|          P|    1|\n",
      "| 194619757| 223981155|2023-08-31|      107114|           CO|DVSA| BEIGE|          P|    1|\n",
      "| 363813511| 223981155|2023-07-24|       68944|           DH|DVSA| BEIGE|          P|    1|\n",
      "| 818121815| 223981155|2023-05-31|      139581|            E|DVSA| BEIGE|          P|    1|\n",
      "| 130590349| 223981155|2023-02-06|      125337|           EH|DVSA| BEIGE|          P|    1|\n",
      "|1700053881| 223981155|2023-03-02|      103661|           LU|DVSA| BEIGE|          P|    1|\n",
      "| 804896923| 223981155|2023-06-21|      189384|           ML|DVSA| BEIGE|          P|    1|\n",
      "| 364306397| 223981155|2023-02-23|       71745|            N|DVSA| BEIGE|          P|    1|\n",
      "| 278592185| 223981155|2023-08-03|      220980|           NN|DVSA| BEIGE|          P|    1|\n",
      "| 649777577| 223981155|2023-08-14|      177213|           NP|DVSA| BEIGE|          P|    1|\n",
      "| 986714569| 223981155|2023-05-16|      201262|           NW|DVSA| BEIGE|          P|    1|\n",
      "| 126550303| 223981155|2023-03-01|      157423|           PE|DVSA| BEIGE|          P|    1|\n",
      "|1177098561| 223981155|2023-03-15|      121700|           SE|DVSA| BEIGE|          P|    1|\n",
      "|  74140977| 223981155|2023-01-14|      144703|           SR|DVSA| BEIGE|          P|    1|\n",
      "|1493456623| 223981155|2023-10-05|       49493|           TS|DVSA| BEIGE|          P|    1|\n",
      "| 378218713| 223981155|2023-04-14|      156723|           WN|DVSA| BEIGE|          P|    1|\n",
      "+----------+----------+----------+------------+-------------+----+------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#retain the first entry (highest mileage) in each postcode_area\n",
    "highest_mileage_duplicates = windowed_duplicates.filter(F.col('row_n')==1)\n",
    "\n",
    "highest_mileage_duplicates.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11d0cf",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "#retain the first entry (highest mileage) in each postcode_area\n",
    "highest_mileage_duplicates <- windowed_duplicates %>%\n",
    "  dplyr::filter(row_n == 1) %>%\n",
    "  dplyr::select(-row_n) %>%\n",
    "  dplyr::arrange(postcode_area)\n",
    "\n",
    "highest_mileage_duplicates %>%\n",
    "  collect() %>%\n",
    "  print(width = Inf)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7942a-1a66-468a-b083-722a1ab731dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
