{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Spark partitions data for wide transformations\n",
    "\n",
    "This notebook demonstrates how Spark partitions data in wide transformations such as `.groupBy()`, `.join()` and `Window.partitionBy()`. To test this we will create a skewed variable within a DataFrame to make it more obvious how Spark is partitioning the data. \n",
    "\n",
    "We will also see how a `.cache()` might affect the execution plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting set up\n",
    "Start with some imports and a Spark session. Note that the `spark.executor.memory` is set to `1GB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, Window \n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"wide-skew\")\n",
    "         .config(\"spark.executor.memory\", \"1g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create a DataFrame with a skewed variable, `skew_col`. Also add another column `rand_val`, which we will use later. We will use `spark.range()` and set the number of partitions to two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+\n",
      "| id|skew_col|rand_val|\n",
      "+---+--------+--------+\n",
      "|  0|       A|       7|\n",
      "|  1|       A|       9|\n",
      "|  2|       A|       9|\n",
      "|  3|       A|       9|\n",
      "|  4|       A|       4|\n",
      "+---+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row_ct = 10**7\n",
    "seed_no = 42\n",
    "\n",
    "skewed_df = spark.range(row_ct, numPartitions=2)\n",
    "\n",
    "skewed_df = (\n",
    "    skewed_df.withColumn(\"skew_col\", F.when(F.col(\"id\") < 100, \"A\")\n",
    "                               .when(F.col(\"id\") < 1000, \"B\")\n",
    "                               .when(F.col(\"id\") < 10000, \"C\")\n",
    "                               .when(F.col(\"id\") < 100000, \"D\")\n",
    "                               .otherwise(\"E\"))\n",
    "              .withColumn(\"rand_val\", F.rint(F.rand(seed_no)*10).cast(\"int\"))\n",
    ")\n",
    "\n",
    "skewed_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the `.join()` we'll need a second DataFrame. Note this has only 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = spark.createDataFrame([\n",
    "    [\"A\", 1],\n",
    "    [\"B\", 2],\n",
    "    [\"C\", 3],\n",
    "    [\"D\", 4],\n",
    "    [\"E\", 5]\n",
    "], [\"skew_col\", \"number_col\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to need the Spark UI, create a link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=http://spark-kkdb8tzmcgn7jdqf.cdswmn-d01-01.ons.statistics.gov.uk>Spark UI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, IPython\n",
    "url = \"spark-%s.%s\" % (os.environ[\"CDSW_ENGINE_ID\"], os.environ[\"CDSW_DOMAIN\"])\n",
    "IPython.display.HTML(\"<a href=http://%s>Spark UI</a>\" % url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some wide transformations\n",
    "\n",
    "The wide transformations are put into functions so we can call them repeatedly later. For each function the job description is set so we can find the correct jobs in the Spark UI. The functions return a sample of the DataFrame, which isn't important. The important thing here is to look at the task metrics and possibly the SQL DAG diagrams in the Spark UI.\n",
    "\n",
    "There is one function for a `.groupBy()`, another for a `.join()` and a third for a `Window.partitionBy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_join():\n",
    "    spark.sparkContext.setJobDescription(\"join\")\n",
    "    joined_df = skewed_df.join(small_df, on=\"skew_col\", how=\"left\")\n",
    "    return joined_df.show(3)\n",
    "\n",
    "def action_groupby_sum():\n",
    "    spark.sparkContext.setJobDescription(\"groupby_sum\")\n",
    "    return skewed_df.groupBy(\"skew_col\").agg(F.sum(\"rand_val\")).show(3)\n",
    "\n",
    "def action_window_sum():\n",
    "    spark.sparkContext.setJobDescription(\"Window\")\n",
    "    window_df = skewed_df.withColumn(\"id_window_sum\", F.sum(\"rand_val\").over(Window.partitionBy(\"skew_col\")))\n",
    "    return window_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+----------+\n",
      "|skew_col|     id|rand_val|number_col|\n",
      "+--------+-------+--------+----------+\n",
      "|       E| 100000|       6|         5|\n",
      "|       E|5438200|       7|         5|\n",
      "|       E| 100001|       6|         5|\n",
      "+--------+-------+--------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+-------------+\n",
      "|skew_col|sum(rand_val)|\n",
      "+--------+-------------+\n",
      "|       E|     49491417|\n",
      "|       B|         4639|\n",
      "|       D|       448943|\n",
      "+--------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-------+--------+--------+-------------+\n",
      "|     id|skew_col|rand_val|id_window_sum|\n",
      "+-------+--------+--------+-------------+\n",
      "|5000000|       E|       4|     49491417|\n",
      "| 438200|       E|       1|     49491417|\n",
      "|5000001|       E|       3|     49491417|\n",
      "+-------+--------+--------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action_join()\n",
    "action_groupby_sum()\n",
    "action_window_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some screenshots from the Spark UI showing how Spark partitioned the data and executed the tasks. Note that the images might look slightly different on multiple runs of this notbook. The processing times will also vary.\n",
    "\n",
    "### Join\n",
    "\n",
    "In the Task Timeline below we can clearly see there is a skew in the length of the tasks in this diagram, which translates to a skew in partition size. This is because Spark has partitioned the data on the `skew_col` before doing the `.join()`. Also note that the full partition could not fit on one executor, this is indicated by the precense of the Shuffle Spill (Memory) and Shuffle Spill (Disk) metrics.\n",
    "\n",
    "![skew_join](./images/skew_join.PNG)\n",
    "\n",
    "\n",
    "### Group by\n",
    "\n",
    "This time we see more evenly sized tasks in the Task Timeline. This means that Spark does not partition by the grouped variable to complete the `.groupBy()`. Instead the aggregation is applied within the original partitions and results are summed up at the end. Note there is no Shuffle Spill (Memory) and Shuffle Spill (Disk) metrics, meaning there was no need to spill data from executor memory to disk in this `.groupBy()`.\n",
    "\n",
    "We also see less green in the Task Timeline, this indicates that more time is spent on scheduling tasks or serialising data for shuffling, although we won't worry about that too much here. \n",
    "\n",
    "![skew_groupby](./images/skew_groupby.PNG)\n",
    "\n",
    "### Window\n",
    "\n",
    "Again we see a clear skew for the Window function. Also we see the spill is back.\n",
    "\n",
    "![skew_window](./images/skew_window.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another group by - count distinct\n",
    "The groupby was different, let's try a different groupby to see if Spark does the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+\n",
      "|skew_col|count(DISTINCT rand_val)|\n",
      "+--------+------------------------+\n",
      "|       E|                      11|\n",
      "|       B|                      11|\n",
      "|       D|                      11|\n",
      "+--------+------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def action_groupby_distinct():\n",
    "    spark.sparkContext.setJobDescription(\"groupby_countDistinct\")\n",
    "    return skewed_df.groupBy(\"skew_col\").agg(F.countDistinct(\"rand_val\")).show(3)\n",
    "\n",
    "action_groupby_distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semms like Spark does the same thing as the last groupBy() we tried- aggregate within the original partitions and sum the results for each grouped variable at the end. We haven't included a screenshot here to leave it to the reader to find the relevant diagram.\n",
    "\n",
    "### Window alternative- group by and join\n",
    "\n",
    "Let's look more closely at the Window function. We can achieve the same result by doing a `.groupBy()` first then `.join()` the aggregated data back onto the original DataFrame. In general, the groupby-join method is slower than a Window function because it involves two shuffles, one for the `.groupby()` and a second for the `.join()`, instead of just one shuffle for the `.Window.partitionBy()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+-------------+\n",
      "|skew_col|     id|rand_val|sum(rand_val)|\n",
      "+--------+-------+--------+-------------+\n",
      "|       E| 100000|       6|     49491417|\n",
      "|       E|5438200|       7|     49491417|\n",
      "|       E| 100001|       6|     49491417|\n",
      "+--------+-------+--------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def action_groupby_join():\n",
    "    spark.sparkContext.setJobDescription(\"groupby-join\")\n",
    "    sum_id = skewed_df.join(skewed_df.groupBy(\"skew_col\").agg(F.sum(\"rand_val\")),\n",
    "                        on=\"skew_col\",\n",
    "                        how=\"left\")\n",
    "    return sum_id.show(3)\n",
    "\n",
    "action_groupby_join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duration of these Spark jobs will vary with different runs of this notebook, and finding the times to compare isn't the easiest task either. The fairest comparison to make is to look at the job numbers for each method, then go to the SQL tab in the UI, and look at the duration for the corresponding SQL queries.\n",
    "\n",
    "After executing the `action_window()` and `action_groupby_join()` functions a couple of times I get some consistent results. The Window method takes 6 seconds and the groupby-join method takes 3 seconds. \n",
    "\n",
    "It looks like the groupby-join method is more efficient in this case. Why? \n",
    "\n",
    "There are a couple of things at play here. \n",
    "- Firstly, there is a large skew that slows down the Window function but has little effect on the groupby. \n",
    "- Secondly, the second DataFrame in the join is small, so the join is relatively quick. \n",
    "\n",
    "So the groupby-join method is quicker for this very specific case. In practice it is quite rare to get a skew this severe, and unusual to use a join for such a small DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does `.cache()` have any effect?\n",
    "\n",
    "As a final investigation, does caching both DataFrames have any effect on how Spark processes the data?\n",
    "\n",
    "The function below caches both DataFrames, then the various functions are run again to see how Spark processes the data differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_cache():\n",
    "    spark.sparkContext.setJobDescription(\"Cache\")\n",
    "    skewed_df.cache().count()\n",
    "    small_df.cache().count()\n",
    "    \n",
    "action_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+--------+----------+\n",
      "|skew_col| id|rand_val|number_col|\n",
      "+--------+---+--------+----------+\n",
      "|       A|  0|       7|         1|\n",
      "|       A|  1|       9|         1|\n",
      "|       A|  2|       9|         1|\n",
      "+--------+---+--------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+-------------+\n",
      "|skew_col|sum(rand_val)|\n",
      "+--------+-------------+\n",
      "|       E|     49491417|\n",
      "|       B|         4639|\n",
      "|       D|       448943|\n",
      "+--------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+------------------------+\n",
      "|skew_col|count(DISTINCT rand_val)|\n",
      "+--------+------------------------+\n",
      "|       E|                      11|\n",
      "|       B|                      11|\n",
      "|       D|                      11|\n",
      "+--------+------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-------+--------+--------+-------------+\n",
      "|     id|skew_col|rand_val|id_window_sum|\n",
      "+-------+--------+--------+-------------+\n",
      "|5000000|       E|       4|     49491417|\n",
      "| 438200|       E|       1|     49491417|\n",
      "|5000001|       E|       3|     49491417|\n",
      "+-------+--------+--------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+-------+--------+-------------+\n",
      "|skew_col|     id|rand_val|sum(rand_val)|\n",
      "+--------+-------+--------+-------------+\n",
      "|       E| 100000|       6|     49491417|\n",
      "|       E|5438200|       7|     49491417|\n",
      "|       E| 100001|       6|     49491417|\n",
      "+--------+-------+--------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action_join()\n",
    "action_groupby_sum()\n",
    "action_groupby_distinct()\n",
    "action_window_sum()\n",
    "action_groupby_join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that caching the DataFrames had little or no effect on both groupbys, the Window function or the groupby-join. Looking through the Spark UI, the only noticeable difference was to the `.join()`. The reason being is that after the caching the small DataFrame, `small_df`, Spark knew that it was a small DataFrame and therefore performed a broadcast join instead of the default sort-merge join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Join**\n",
    "\n",
    "- Without caching we get spill and a SortMergeJoin\n",
    "- With caching we don't get spill and a BroadcastHashJoin\n",
    "\n",
    "**Group by**\n",
    "\n",
    "- No spill\n",
    "- Not affected too badly by skew or caching\n",
    "\n",
    "**Window**\n",
    "\n",
    "- Obvious skew and spill\n",
    "- Cache has little effect\n",
    "\n",
    "**Groupby and join**\n",
    "\n",
    "- No skew or spill in groupby part\n",
    "- Skew and spill in the join part, but this could be avoided by forcing a broadcast join, i.e. `F.broadcast()` around the smaller DataFrame\n",
    "- This method was quicker than the Window function, but it unlikely to be quicker in most cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
