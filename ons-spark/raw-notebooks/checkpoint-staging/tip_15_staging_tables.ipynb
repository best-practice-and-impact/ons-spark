{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://officenationalstatistics.sharepoint.com/:i:/r/sites/itoDSTPMO/DAPCATS/04.%20Technical/02.%20Development_Test/images_for_gitlab/dap-cats-ds-logo.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip of the Week: Staging Tables\n",
    "\n",
    "Staging tables are an alternative way of checkpointing data in Spark, in which the data is written out as a named Hive table in a database, rather than to the checkpointing location.\n",
    "\n",
    "### A quick recap of persisting\n",
    "\n",
    "Persisting in Spark is where we store the data at an intermediate point of the code in memory or on disk. This is generally done with `.cache()` (to store the data in memory) or `.checkpoint()` (to write it to disk). If you are not familiar with the concept of persisting, please read the [Persisting in Spark notebook](http://np2rvlapxx507/DAP_CATS/Training/more-spark/blob/master/more_spark/notebooks/material/persist.ipynb) which explains these concepts in more detail.\n",
    "\n",
    "Importantly, if your code is short and non-complex then it is unlikely you will need any form of persisting in your code, but if you have long and complex code sensible persisting can help make it more efficient.\n",
    "\n",
    "### Staging tables: the concept\n",
    "\n",
    "You can write a staging table to HDFS with `df.write.mode(\"overwrite\").saveAsTable(table_name, format=\"parquet\")` or `df.write.insertInto(table_name, overwrite=True)`(of course, if using `.insertInto()` you will need to create the table first). You can then read the table back in with `spark.read.table()`. Like with checkpointing, this will break the lineage of the DataFrame, and therefore they can be useful in large, complex pipelines, or those that involve processes in a loop. As Spark is more efficient at reading in tables than CSV files, another use case is staging CSV files as tables at the start of your code before doing any complex calculations.\n",
    "\n",
    "Staging has some advantages over checkpointing:\n",
    "- The same table can be overwritten, meaning there is no need to clean up old checkpointed files\n",
    "- It is stored in a location that is easier to access, rather than the checkpointing folder, which can help with debugging and testing changes to the code\n",
    "- They can be re-used elsewhere\n",
    "- If `.insertInto()` is used, you can take advantage of the table schema, as an exception will be raised if the DataFrame and table schemas do not match\n",
    "- It is more efficient for Spark to read Hive tables than CSV files as the underlying format is Parquet, so if your data are delivered as CSV files you may want to stage them as Hive tables first. For more information see the [Storing as a Parquet tip](http://np2rvlapxx507/DAP_CATS/troubleshooting/tip-of-the-week/blob/master/tip_18_parquet.ipynb).\n",
    "\n",
    "There are also some disadvantages:\n",
    "- Takes longer to write the code\n",
    "- More difficult to maintain, especially if `.insertInto()` is used, as you will have to alter the table if the DataFrame structure changes\n",
    "- Ensure that you are not using them unnecessarily (the same is true with any method of persisting data)\n",
    "\n",
    "The examples here use PySpark, but the same principles apply to R users who are using sparklyr in DAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Our example will be very simple, and show how to read a CSV file, perform some basic data cleansing, then stage as a Hive table, and then read it back in as a DataFrame. \n",
    "\n",
    "Often staging tables are most useful in large, complex pipelines; for obvious reasons our example will instead be simple!\n",
    "\n",
    "First, import the relevant modules and create a Spark session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"staging-tables-tip\")\n",
    "    .config(\"spark.executor.memory\", \"1g\")\n",
    "    .config(\"spark.executor.cores\", 1)\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", 3)\n",
    "    .config(\"spark.sql.shuffle.partitions\", 12)\n",
    "    .config(\"spark.shuffle.service.enabled\", \"true\")\n",
    "    .config(\"spark.ui.showConsoleProgress\", \"false\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read in the CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/training/animal_rescue.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then do some preparation: drop and rename some columns, change the format, then sort.\n",
    "\n",
    "Note that if saving as a Hive table there are some stricter rules, including:\n",
    "- Some characters aren't allowed in column names, including `£`\n",
    "- The table won't load in the browser in HUE if you use date, but will accept a timestamp\n",
    "\n",
    "We then preview the DataFrame with `.toPandas()` (remember to use `.limit()` when looking at data in this way):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidentNumber</th>\n",
       "      <th>DateTimeOfCall</th>\n",
       "      <th>CalYear</th>\n",
       "      <th>FinYear</th>\n",
       "      <th>TypeOfIncident</th>\n",
       "      <th>EngineCount</th>\n",
       "      <th>JobHours</th>\n",
       "      <th>HourlyCost</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>Description</th>\n",
       "      <th>AnimalGroup</th>\n",
       "      <th>OriginOfCall</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>PropertyCategory</th>\n",
       "      <th>SpecialServiceTypeCategory</th>\n",
       "      <th>SpecialServiceType</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Borough</th>\n",
       "      <th>StnGroundName</th>\n",
       "      <th>PostcodeDistrict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000014-03092018M</td>\n",
       "      <td>2018-09-03</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018/19</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>333</td>\n",
       "      <td>999.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown - Heavy Livestock Animal</td>\n",
       "      <td>Other FRS</td>\n",
       "      <td>Animal harm outdoors</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Other animal assistance</td>\n",
       "      <td>Animal harm involving livestock</td>\n",
       "      <td>CARSHALTON SOUTH AND CLOCKHOUSE</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>Wallington</td>\n",
       "      <td>CR8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000099-01012017</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016/17</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>326</td>\n",
       "      <td>652.0</td>\n",
       "      <td>DOG WITH HEAD STUCK IN RAILINGS CALLED BY OWNER</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Person (mobile)</td>\n",
       "      <td>Railings</td>\n",
       "      <td>Outdoor Structure</td>\n",
       "      <td>Other animal assistance</td>\n",
       "      <td>Assist trapped domestic animal</td>\n",
       "      <td>BROMLEY TOWN</td>\n",
       "      <td>BROMLEY</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>BR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000260-01012017</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016/17</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>326</td>\n",
       "      <td>326.0</td>\n",
       "      <td>BIRD TRAPPED IN NETTING BY THE 02 SHOP AND NEA...</td>\n",
       "      <td>Bird</td>\n",
       "      <td>Person (land line)</td>\n",
       "      <td>Single shop</td>\n",
       "      <td>Non Residential</td>\n",
       "      <td>Animal rescue from height</td>\n",
       "      <td>Animal rescue from height - Bird</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>CROYDON</td>\n",
       "      <td>Croydon</td>\n",
       "      <td>CR0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000375-01012017</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016/17</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>326</td>\n",
       "      <td>652.0</td>\n",
       "      <td>DOG STUCK IN HULL OF DERELICT BOAT - WATER RES...</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Person (mobile)</td>\n",
       "      <td>Barge</td>\n",
       "      <td>Boat</td>\n",
       "      <td>Animal rescue from water</td>\n",
       "      <td>Animal rescue from water - Domestic pet</td>\n",
       "      <td>BRENTFORD</td>\n",
       "      <td>HOUNSLOW</td>\n",
       "      <td>Chiswick</td>\n",
       "      <td>TW8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000477-01012017</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016/17</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>326</td>\n",
       "      <td>326.0</td>\n",
       "      <td>DEER TRAPPED IN RAILINGS JUNCTION WITH DENNIS ...</td>\n",
       "      <td>Deer</td>\n",
       "      <td>Person (mobile)</td>\n",
       "      <td>Animal harm outdoors</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Other animal assistance</td>\n",
       "      <td>Animal assistance involving wild animal - Othe...</td>\n",
       "      <td>STANMORE PARK</td>\n",
       "      <td>HARROW</td>\n",
       "      <td>Stanmore</td>\n",
       "      <td>HA7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     IncidentNumber DateTimeOfCall CalYear  FinYear   TypeOfIncident  \\\n",
       "0  000014-03092018M     2018-09-03    2018  2018/19  Special Service   \n",
       "1   000099-01012017     2017-01-01    2017  2016/17  Special Service   \n",
       "2   000260-01012017     2017-01-01    2017  2016/17  Special Service   \n",
       "3   000375-01012017     2017-01-01    2017  2016/17  Special Service   \n",
       "4   000477-01012017     2017-01-01    2017  2016/17  Special Service   \n",
       "\n",
       "  EngineCount JobHours HourlyCost TotalCost  \\\n",
       "0         2.0      3.0        333     999.0   \n",
       "1         1.0      2.0        326     652.0   \n",
       "2         1.0      1.0        326     326.0   \n",
       "3         1.0      2.0        326     652.0   \n",
       "4         1.0      1.0        326     326.0   \n",
       "\n",
       "                                         Description  \\\n",
       "0                                               None   \n",
       "1    DOG WITH HEAD STUCK IN RAILINGS CALLED BY OWNER   \n",
       "2  BIRD TRAPPED IN NETTING BY THE 02 SHOP AND NEA...   \n",
       "3  DOG STUCK IN HULL OF DERELICT BOAT - WATER RES...   \n",
       "4  DEER TRAPPED IN RAILINGS JUNCTION WITH DENNIS ...   \n",
       "\n",
       "                        AnimalGroup        OriginOfCall          PropertyType  \\\n",
       "0  Unknown - Heavy Livestock Animal           Other FRS  Animal harm outdoors   \n",
       "1                               Dog     Person (mobile)              Railings   \n",
       "2                              Bird  Person (land line)          Single shop    \n",
       "3                               Dog     Person (mobile)                Barge    \n",
       "4                              Deer     Person (mobile)  Animal harm outdoors   \n",
       "\n",
       "    PropertyCategory SpecialServiceTypeCategory  \\\n",
       "0            Outdoor    Other animal assistance   \n",
       "1  Outdoor Structure    Other animal assistance   \n",
       "2    Non Residential  Animal rescue from height   \n",
       "3               Boat   Animal rescue from water   \n",
       "4            Outdoor    Other animal assistance   \n",
       "\n",
       "                                  SpecialServiceType  \\\n",
       "0                    Animal harm involving livestock   \n",
       "1                     Assist trapped domestic animal   \n",
       "2                   Animal rescue from height - Bird   \n",
       "3            Animal rescue from water - Domestic pet   \n",
       "4  Animal assistance involving wild animal - Othe...   \n",
       "\n",
       "                              Ward   Borough StnGroundName PostcodeDistrict  \n",
       "0  CARSHALTON SOUTH AND CLOCKHOUSE    SUTTON    Wallington              CR8  \n",
       "1                     BROMLEY TOWN   BROMLEY       Bromley              BR2  \n",
       "2                        Fairfield   CROYDON       Croydon              CR0  \n",
       "3                        BRENTFORD  HOUNSLOW      Chiswick              TW8  \n",
       "4                    STANMORE PARK    HARROW      Stanmore              HA7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (df.\n",
    "    drop(\n",
    "        \"WardCode\", \n",
    "        \"BoroughCode\", \n",
    "        \"Easting_m\", \n",
    "        \"Northing_m\", \n",
    "        \"Easting_rounded\", \n",
    "        \"Northing_rounded\")\n",
    "    .withColumnRenamed(\"PumpCount\", \"EngineCount\")\n",
    "    .withColumnRenamed(\"FinalDescription\", \"Description\")\n",
    "    .withColumnRenamed(\"HourlyNotionalCost(£)\", \"HourlyCost\")\n",
    "    .withColumnRenamed(\"IncidentNotionalCost(£)\", \"TotalCost\")\n",
    "    .withColumnRenamed(\"OriginofCall\", \"OriginOfCall\")\n",
    "    .withColumnRenamed(\"PumpHoursTotal\", \"JobHours\")\n",
    "    .withColumnRenamed(\"AnimalGroupParent\", \"AnimalGroup\")\n",
    "    .withColumn(\n",
    "        \"DateTimeOfCall\", F.to_timestamp(F.col(\"DateTimeOfCall\"), \"dd/MM/yyyy\"))\n",
    "    .orderBy(\"IncidentNumber\")\n",
    "    )\n",
    "\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the plan with `df.explain()`. This displays what precisely Spark will do once an action is called (*lazy evaluation*). This is a simple example but in long pipelines this plan can get complicated. Using a staging table can split this process, referred to as *cutting the lineage*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Sort [IncidentNumber#10 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(IncidentNumber#10 ASC NULLS FIRST, 12)\n",
      "   +- *(1) Project [IncidentNumber#10, cast(unix_timestamp(DateTimeOfCall#11, dd/MM/yyyy, Some(Etc/UTC)) as timestamp) AS DateTimeOfCall#229, CalYear#12, FinYear#13, TypeOfIncident#14, PumpCount#15 AS EngineCount#82, PumpHoursTotal#16 AS JobHours#187, HourlyNotionalCost(£)#17 AS HourlyCost#124, IncidentNotionalCost(£)#18 AS TotalCost#145, FinalDescription#19 AS Description#103, AnimalGroupParent#20 AS AnimalGroup#208, OriginofCall#21 AS OriginOfCall#166, PropertyType#22, PropertyCategory#23, SpecialServiceTypeCategory#24, SpecialServiceType#25, Ward#27, Borough#29, StnGroundName#30, PostcodeDistrict#31]\n",
      "      +- *(1) FileScan csv [IncidentNumber#10,DateTimeOfCall#11,CalYear#12,FinYear#13,TypeOfIncident#14,PumpCount#15,PumpHoursTotal#16,HourlyNotionalCost(£)#17,IncidentNotionalCost(£)#18,FinalDescription#19,AnimalGroupParent#20,OriginofCall#21,PropertyType#22,PropertyCategory#23,SpecialServiceTypeCategory#24,SpecialServiceType#25,Ward#27,Borough#29,StnGroundName#30,PostcodeDistrict#31] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://dnt01/training/animal_rescue.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<IncidentNumber:string,DateTimeOfCall:string,CalYear:string,FinYear:string,TypeOfIncident:s...\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save the DataFrame as table, using `mode(\"overwrite\")`, which overwrites the existing table if there is one. The first time you create a staging table this option will be redundant, but on subsequent runs on the code you will get an error without this as the table will already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getenv('HADOOP_USER_NAME') \n",
    "table_name = f\"train_tmp.staging_example_{username}\"\n",
    "\n",
    "df.write.mode(\"overwrite\").saveAsTable(table_name, format=\"parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the data in again and preview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidentNumber</th>\n",
       "      <th>DateTimeOfCall</th>\n",
       "      <th>CalYear</th>\n",
       "      <th>FinYear</th>\n",
       "      <th>TypeOfIncident</th>\n",
       "      <th>EngineCount</th>\n",
       "      <th>JobHours</th>\n",
       "      <th>HourlyCost</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>Description</th>\n",
       "      <th>AnimalGroup</th>\n",
       "      <th>OriginOfCall</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>PropertyCategory</th>\n",
       "      <th>SpecialServiceTypeCategory</th>\n",
       "      <th>SpecialServiceType</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Borough</th>\n",
       "      <th>StnGroundName</th>\n",
       "      <th>PostcodeDistrict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000014-03092018M</td>\n",
       "      <td>2018-09-03</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018/19</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>333</td>\n",
       "      <td>999.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown - Heavy Livestock Animal</td>\n",
       "      <td>Other FRS</td>\n",
       "      <td>Animal harm outdoors</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Other animal assistance</td>\n",
       "      <td>Animal harm involving livestock</td>\n",
       "      <td>CARSHALTON SOUTH AND CLOCKHOUSE</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>Wallington</td>\n",
       "      <td>CR8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000099-01012017</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016/17</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>326</td>\n",
       "      <td>652.0</td>\n",
       "      <td>DOG WITH HEAD STUCK IN RAILINGS CALLED BY OWNER</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Person (mobile)</td>\n",
       "      <td>Railings</td>\n",
       "      <td>Outdoor Structure</td>\n",
       "      <td>Other animal assistance</td>\n",
       "      <td>Assist trapped domestic animal</td>\n",
       "      <td>BROMLEY TOWN</td>\n",
       "      <td>BROMLEY</td>\n",
       "      <td>Bromley</td>\n",
       "      <td>BR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000260-01012017</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016/17</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>326</td>\n",
       "      <td>326.0</td>\n",
       "      <td>BIRD TRAPPED IN NETTING BY THE 02 SHOP AND NEA...</td>\n",
       "      <td>Bird</td>\n",
       "      <td>Person (land line)</td>\n",
       "      <td>Single shop</td>\n",
       "      <td>Non Residential</td>\n",
       "      <td>Animal rescue from height</td>\n",
       "      <td>Animal rescue from height - Bird</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>CROYDON</td>\n",
       "      <td>Croydon</td>\n",
       "      <td>CR0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000375-01012017</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016/17</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>326</td>\n",
       "      <td>652.0</td>\n",
       "      <td>DOG STUCK IN HULL OF DERELICT BOAT - WATER RES...</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Person (mobile)</td>\n",
       "      <td>Barge</td>\n",
       "      <td>Boat</td>\n",
       "      <td>Animal rescue from water</td>\n",
       "      <td>Animal rescue from water - Domestic pet</td>\n",
       "      <td>BRENTFORD</td>\n",
       "      <td>HOUNSLOW</td>\n",
       "      <td>Chiswick</td>\n",
       "      <td>TW8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000477-01012017</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016/17</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>326</td>\n",
       "      <td>326.0</td>\n",
       "      <td>DEER TRAPPED IN RAILINGS JUNCTION WITH DENNIS ...</td>\n",
       "      <td>Deer</td>\n",
       "      <td>Person (mobile)</td>\n",
       "      <td>Animal harm outdoors</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Other animal assistance</td>\n",
       "      <td>Animal assistance involving wild animal - Othe...</td>\n",
       "      <td>STANMORE PARK</td>\n",
       "      <td>HARROW</td>\n",
       "      <td>Stanmore</td>\n",
       "      <td>HA7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     IncidentNumber DateTimeOfCall CalYear  FinYear   TypeOfIncident  \\\n",
       "0  000014-03092018M     2018-09-03    2018  2018/19  Special Service   \n",
       "1   000099-01012017     2017-01-01    2017  2016/17  Special Service   \n",
       "2   000260-01012017     2017-01-01    2017  2016/17  Special Service   \n",
       "3   000375-01012017     2017-01-01    2017  2016/17  Special Service   \n",
       "4   000477-01012017     2017-01-01    2017  2016/17  Special Service   \n",
       "\n",
       "  EngineCount JobHours HourlyCost TotalCost  \\\n",
       "0         2.0      3.0        333     999.0   \n",
       "1         1.0      2.0        326     652.0   \n",
       "2         1.0      1.0        326     326.0   \n",
       "3         1.0      2.0        326     652.0   \n",
       "4         1.0      1.0        326     326.0   \n",
       "\n",
       "                                         Description  \\\n",
       "0                                               None   \n",
       "1    DOG WITH HEAD STUCK IN RAILINGS CALLED BY OWNER   \n",
       "2  BIRD TRAPPED IN NETTING BY THE 02 SHOP AND NEA...   \n",
       "3  DOG STUCK IN HULL OF DERELICT BOAT - WATER RES...   \n",
       "4  DEER TRAPPED IN RAILINGS JUNCTION WITH DENNIS ...   \n",
       "\n",
       "                        AnimalGroup        OriginOfCall          PropertyType  \\\n",
       "0  Unknown - Heavy Livestock Animal           Other FRS  Animal harm outdoors   \n",
       "1                               Dog     Person (mobile)              Railings   \n",
       "2                              Bird  Person (land line)          Single shop    \n",
       "3                               Dog     Person (mobile)                Barge    \n",
       "4                              Deer     Person (mobile)  Animal harm outdoors   \n",
       "\n",
       "    PropertyCategory SpecialServiceTypeCategory  \\\n",
       "0            Outdoor    Other animal assistance   \n",
       "1  Outdoor Structure    Other animal assistance   \n",
       "2    Non Residential  Animal rescue from height   \n",
       "3               Boat   Animal rescue from water   \n",
       "4            Outdoor    Other animal assistance   \n",
       "\n",
       "                                  SpecialServiceType  \\\n",
       "0                    Animal harm involving livestock   \n",
       "1                     Assist trapped domestic animal   \n",
       "2                   Animal rescue from height - Bird   \n",
       "3            Animal rescue from water - Domestic pet   \n",
       "4  Animal assistance involving wild animal - Othe...   \n",
       "\n",
       "                              Ward   Borough StnGroundName PostcodeDistrict  \n",
       "0  CARSHALTON SOUTH AND CLOCKHOUSE    SUTTON    Wallington              CR8  \n",
       "1                     BROMLEY TOWN   BROMLEY       Bromley              BR2  \n",
       "2                        Fairfield   CROYDON       Croydon              CR0  \n",
       "3                        BRENTFORD  HOUNSLOW      Chiswick              TW8  \n",
       "4                    STANMORE PARK    HARROW      Stanmore              HA7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.table(table_name)\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame has the same structure as previously, but when we look at the plan with `df.explain()` we can see that less is being done. This is an example of cutting the lineage and can be useful when you have complex plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) FileScan parquet train_tmp.staging_example_princa[IncidentNumber#310,DateTimeOfCall#311,CalYear#312,FinYear#313,TypeOfIncident#314,EngineCount#315,JobHours#316,HourlyCost#317,TotalCost#318,Description#319,AnimalGroup#320,OriginOfCall#321,PropertyType#322,PropertyCategory#323,SpecialServiceTypeCategory#324,SpecialServiceType#325,Ward#326,Borough#327,StnGroundName#328,PostcodeDistrict#329] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://dnt01/training/train_tmp/hive/staging_example_princa], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<IncidentNumber:string,DateTimeOfCall:timestamp,CalYear:string,FinYear:string,TypeOfInciden...\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `.insertInto()`\n",
    "\n",
    "Another method is to create an empty table and then use `.insertInto()`; here we will just use a small number of columns as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_table = f\"train_tmp.staging_small_{username}\"\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE {small_table} (\n",
    "        IncidentNumber STRING,\n",
    "        CalYear INT,\n",
    "        EngineCount INT,\n",
    "        AnimalGroup STRING\n",
    "    )\n",
    "    STORED AS PARQUET\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the columns will be inserted by position, not name, so it's a good idea to re-select the column order to match that of the table before inserting in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = spark.read.table(small_table).columns\n",
    "df.select(col_order).write.insertInto(small_table, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can then be read in as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+-----------+--------------------+\n",
      "|  IncidentNumber|CalYear|EngineCount|         AnimalGroup|\n",
      "+----------------+-------+-----------+--------------------+\n",
      "|000014-03092018M|   2018|          2|Unknown - Heavy L...|\n",
      "| 000099-01012017|   2017|          1|                 Dog|\n",
      "| 000260-01012017|   2017|          1|                Bird|\n",
      "| 000375-01012017|   2017|          1|                 Dog|\n",
      "| 000477-01012017|   2017|          1|                Deer|\n",
      "+----------------+-------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.table(small_table)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will drop the tables used in this example, which we can do with the `DROP` SQL statement. This is much easier than deleting a checkpointed file.\n",
    "\n",
    "Of course, with staging tables you generally want to keep the table, but just overwrite the data each time, so this step often won't be needed.\n",
    "\n",
    "Always be very careful when using `DROP` as this will delete the table without warning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DROP TABLE {table_name}\")\n",
    "spark.sql(f\"DROP TABLE {small_table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Resources\n",
    "\n",
    "Notebooks:\n",
    "- [Persisting in Spark](http://np2rvlapxx507/DAP_CATS/Training/more-spark/blob/master/more_spark/notebooks/material/persist.ipynb)\n",
    "- [Storing as a Parquet](http://np2rvlapxx507/DAP_CATS/troubleshooting/tip-of-the-week/blob/master/tip_18_parquet.ipynb)\n",
    "\n",
    "Functions:\n",
    "- [df.write.insertInto()](https://spark.apache.org/docs/2.4.0/api/python/pyspark.sql.html#pyspark.sql.DataFrameWriter.insertInto)\n",
    "- [df.write.saveAsTable()](https://spark.apache.org/docs/2.4.0/api/python/pyspark.sql.html#pyspark.sql.DataFrameWriter.saveAsTable)\n",
    "- [spark.read.csv()](https://spark.apache.org/docs/2.4.0/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.csv)\n",
    "- [spark.read.table()](https://spark.apache.org/docs/2.4.0/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.table)\n",
    "\n",
    "Other material:\n",
    "- <a href=\"https://en.wikipedia.org/wiki/Staging_(data)\">Staging (data) article on Wikipedia</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
