{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60544fb2",
   "metadata": {},
   "source": [
    "## Synthetic Data Generation in Python: Faker and Mimesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a83f7fc",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "\n",
    "This is a guide on generating synthetic data in Python. Synthetic data is artificially created information that closely resembles real-world data, but contains no actual personal or sensitive information. It is invaluable for:\n",
    "\n",
    "- Testing and validating data pipelines and machine learning models\n",
    "- Protecting privacy and confidentiality\n",
    "- Simulating rare or edge-case scenarios\n",
    "- Enabling reproducible research and open data sharing\n",
    "\n",
    "In this notebook, we demonstrate how to generate synthetic data using two leading Python libraries: [Faker](https://faker.readthedocs.io/en/master/) and [Mimesis](https://mimesis.name/). For each example, we show parallel code for both libraries, highlighting their similarities and differences. We also cover best practices, advanced use cases, and how to scale up data generation with PySpark for big data applications.\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- Generate realistic synthetic data for a variety of domains\n",
    "- Choose between Faker and Mimesis based on your needs\n",
    "- Understand how to ensure reproducibility and locale-specific data\n",
    "- Scale up data generation for large datasets\n",
    "- Apply best practices for synthetic data projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ad950",
   "metadata": {},
   "source": [
    "### 2. Install and Setup\n",
    "\n",
    "First, install the required libraries and check their versions to ensure compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce05233",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faker mimesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc58fc",
   "metadata": {},
   "source": [
    "````{tabs}\n",
    "```{code-tab} py Faker\n",
    "!pip install faker\n",
    "```\n",
    "\n",
    "```{code-tab} py Mimesis\n",
    "!pip install mimesis\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d26638",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "````{tabs}\n",
    "```{code-tab} py Faker\n",
    "import faker\n",
    "import pkg_resources\n",
    "print(\"Faker version:\", pkg_resources.get_distribution(\"Faker\").version) \n",
    "```\n",
    "\n",
    "```{code-tab} py Mimesis\n",
    "import mimesis\n",
    "print(\"Mimesis version:\", mimesis.__version__)\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabs}\n",
    "```{code-tab} plaintext Faker Output\n",
    "Faker version: 37.4.0\n",
    "```\n",
    "\n",
    "```{code-tab} plaintext Mimesis Output\n",
    "Mimesis version: 18.0.0\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91fcdb",
   "metadata": {},
   "source": [
    "### 3. Setting a Random Seed\n",
    "\n",
    "Setting a random seed ensures reproducibility, so you get the same synthetic data each time you run the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cae8d1",
   "metadata": {},
   "source": [
    "````{tabs}\n",
    "```{code-tab} py Faker\n",
    "from faker import Faker\n",
    "\n",
    "# Set up Faker\n",
    "fake_uk = Faker('en_GB')\n",
    "fake_uk.seed_instance(42)\n",
    "```\n",
    "```{code-tab} py Mimesis\n",
    "from mimesis import Generic\n",
    "from mimesis import random as mimesis_random\n",
    "\n",
    "# Set up Mimesis\n",
    "mimesis_random.global_seed = 42\n",
    "generic = Generic(locale='en_GB', seed=42)\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365fb8de",
   "metadata": {},
   "source": [
    "### 4. Providers and Locales in Faker and Mimesis\n",
    "\n",
    "Both Faker and Mimesis use the concept of **providers** (modules or classes that generate specific types of data) and **locales** (to match country or language conventions). Below, we show how to list available providers and generate data for different locales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ca5fc",
   "metadata": {},
   "source": [
    "#### 4.1 Providers\n",
    "\n",
    "You can explore the full list of available providers and their methods in the [official Faker documentation](https://faker.readthedocs.io/en/master/providers.html) and [official Mimesis documentation](https://mimesis.name/v12.1.1/providers.html), which offer detailed information and usage examples for each one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a3e755",
   "metadata": {},
   "source": [
    "````{tabs}\n",
    "```{code-tab} py Faker\n",
    "print(\"Faker Providers:\")\n",
    "for provider in fake_uk.providers:\n",
    "    print(\"-\", provider)\n",
    "```\n",
    "```{code-tab} py Mimesis\n",
    "print(\"Mimesis Providers:\")\n",
    "for attribute in dir(generic):\n",
    "    if not attribute.startswith('_'):\n",
    "        print(\"-\", attribute)\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabs}\n",
    "```{code-tab} plaintext Faker Output\n",
    "Faker Providers:\n",
    "- <faker.providers.user_agent.Provider object at 0x00000199DED9E740>\n",
    "- <faker.providers.ssn.en_GB.Provider object at 0x00000199DED9F670>\n",
    "- <faker.providers.sbn.Provider object at 0x00000199DED9C610>\n",
    "- <faker.providers.python.Provider object at 0x00000199DED9C1F0>\n",
    "- <faker.providers.profile.Provider object at 0x00000199DED9E470>\n",
    "- <faker.providers.phone_number.en_GB.Provider object at 0x00000199DED9FD60>\n",
    "- <faker.providers.person.en_GB.Provider object at 0x00000199DED9C070>\n",
    "- <faker.providers.passport.en_US.Provider object at 0x00000199DED9CAC0>\n",
    "- <faker.providers.misc.en_US.Provider object at 0x00000199DED9FDF0>\n",
    "- <faker.providers.lorem.la.Provider object at 0x00000199DED9FE80>\n",
    "- <faker.providers.job.en_US.Provider object at 0x00000199DED9C820>\n",
    "- <faker.providers.isbn.en_US.Provider object at 0x00000199DED9C880>\n",
    "- <faker.providers.internet.en_GB.Provider object at 0x00000199DED9C9A0>\n",
    "- <faker.providers.geo.en_US.Provider object at 0x00000199DED9C8B0>\n",
    "- <faker.providers.file.Provider object at 0x00000199DED9F7F0>\n",
    "- <faker.providers.emoji.Provider object at 0x00000199DED9F8B0>\n",
    "- <faker.providers.doi.Provider object at 0x00000199DED9F910>\n",
    "- <faker.providers.date_time.en_US.Provider object at 0x00000199DED9FA00>\n",
    "- <faker.providers.currency.en_US.Provider object at 0x00000199DED9DB10>\n",
    "- <faker.providers.credit_card.en_US.Provider object at 0x00000199DED9E5C0>\n",
    "- <faker.providers.company.en_US.Provider object at 0x00000199DED9E6B0>\n",
    "- <faker.providers.color.en_US.Provider object at 0x00000199DED9DCC0>\n",
    "- <faker.providers.barcode.en_US.Provider object at 0x00000199DED9EB00>\n",
    "- <faker.providers.bank.en_GB.Provider object at 0x00000199DED9DBD0>\n",
    "- <faker.providers.automotive.en_GB.Provider object at 0x00000199DEDC9AE0>\n",
    "- <faker.providers.address.en_GB.Provider object at 0x00000199DD272AD0>\n",
    "```\n",
    "```{code-tab} plaintext Mimesis Output\n",
    "Mimesis Providers:\n",
    "- address\n",
    "- binaryfile\n",
    "- choice\n",
    "- code\n",
    "- cryptographic\n",
    "- datetime\n",
    "- development\n",
    "- file\n",
    "- finance\n",
    "- food\n",
    "- hardware\n",
    "- internet\n",
    "- numeric\n",
    "- path\n",
    "- payment\n",
    "- person\n",
    "- science\n",
    "- text\n",
    "- transport\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0bb665",
   "metadata": {},
   "source": [
    "#### 4.2 Locales\n",
    "\n",
    "Locales allow you to generate data that matches the conventions and formats of different countries and regions. This is useful for internationalisation and region-specific testing.\n",
    "\n",
    "\n",
    "To demonstrate how locales influence data generation, let us create a simple example that generates person and address data for various regions.  Note that both libraries also support language-specific data generation; for example, outputs for Arabic and Japanese locales are written in the respective languages. For a full list of supported locales, please refer to the [official Faker documentation](https://fakerjs.dev/guide/localization.html#available-locales) and [official Mimesis documentation](https://mimesis.name/v12.1.1/locales.html).\n",
    "\n",
    "\n",
    "**Generate data for multiple locales**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8c772d",
   "metadata": {},
   "source": [
    "````{tabs}\n",
    "```{code-tab} py Faker\n",
    "print(\"\\nFaker Examples for Multiple Locales:\")\n",
    "locales = ['en_GB', 'en_US', 'ja_JP', 'fr_FR', 'ar']\n",
    "for loc in locales:\n",
    "    fake = Faker(loc)\n",
    "    fake.seed_instance(42)\n",
    "    print(f\"\\n{loc.upper()} Example:\")\n",
    "    print(\"Name:\", fake.name())\n",
    "    print(\"Email:\", fake.email())\n",
    "    print(\"Job:\", fake.job())\n",
    "```\n",
    "\n",
    "```{code-tab} py Mimesis\n",
    "from mimesis import Person\n",
    "print(\"\\nMimesis Examples for Multiple Locales:\")\n",
    "locales = [Locale.EN_GB, Locale.EN, Locale.JA, Locale.FR, Locale.AR_EG]\n",
    "for loc in locales:\n",
    "    person = Person(locale=loc, seed=42)\n",
    "    print(f\"\\n{loc.value.upper()} Example:\")\n",
    "    print(\"Full Name:\", person.full_name())\n",
    "    print(\"Email:\", person.email())\n",
    "    print(\"Job:\", person.occupation())\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabs}\n",
    "```{code-tab} plaintext Faker Output\n",
    "Faker Examples for Multiple Locales:\n",
    "\n",
    "EN_GB Example:\n",
    "Name: William Jennings\n",
    "Email: duncan32@example.net\n",
    "Job: Civil engineer, consulting\n",
    "\n",
    "EN_US Example:\n",
    "Name: Allison Hill\n",
    "Email: donaldgarcia@example.net\n",
    "Job: Sports administrator\n",
    "\n",
    "JA_JP Example:\n",
    "Name: 佐藤 淳\n",
    "Email: tomoyatakahashi@example.org\n",
    "Job: 測量士\n",
    "\n",
    "FR_FR Example:\n",
    "Name: Alexandre Traore\n",
    "Email: patrick32@example.net\n",
    "Job: boucher\n",
    "\n",
    "AR Example:\n",
    "Name: جلاء بنو العريج\n",
    "Email: dyaalhaby@example.net\n",
    "Job: رجل مباحث\n",
    "```\n",
    "```{code-tab} plaintext Mimesis Output\n",
    "Mimesis Examples for Multiple Locales:\n",
    "EN-GB Example:\n",
    "Full Name: Anthony Reilly\n",
    "Email: holds1871@live.com\n",
    "Job: Choreographer\n",
    "\n",
    "EN Example:\n",
    "Full Name: Anthony Reilly\n",
    "Email: holds1871@live.com\n",
    "Job: Choreographer\n",
    "\n",
    "JA Example:\n",
    "Full Name: 石松 田場\n",
    "Email: gilbert1852@yahoo.com\n",
    "Job: 巫女\n",
    "\n",
    "FR Example:\n",
    "Full Name: Alexy Rigal\n",
    "Email: holds1871@live.com\n",
    "Job: Responsable SAV (Service après-vente)\n",
    "\n",
    "AR-EG Example:\n",
    "Full Name: أيمن عبد الماجد باشا\n",
    "Email: gilbert1852@yahoo.com\n",
    "Job: تقني تدفئة وتكييف\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd3130",
   "metadata": {},
   "source": [
    "#### 4.3 Generate User Profiles with Multiple Providers\n",
    "\n",
    "Combining multiple providers allows you to create rich, realistic user profiles for testing and simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e6a5a6",
   "metadata": {},
   "source": [
    "````{tabs}\n",
    "```{code-tab} py Faker\n",
    "profile = {\n",
    "    \"Name\": fake_uk.name(),\n",
    "    \"Address\": fake_uk.address().replace(\"\\n\", \", \"),\n",
    "    \"Email\": fake_uk.email(),\n",
    "    \"Job\": fake_uk.job(),\n",
    "    \"Phone\": fake_uk.phone_number(),\n",
    "    \"Company\": fake_uk.company(),\n",
    "    \"Date of Birth\": fake_uk.date_of_birth(minimum_age=18, maximum_age=90)\n",
    "}\n",
    "print(\"Faker User Profile:\")\n",
    "for k, v in profile.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "```\n",
    "\n",
    "```{code-tab} py Mimesis\n",
    "from mimesis import Address, Finance, Datetime\n",
    "\n",
    "person = Person(locale=Locale.EN_GB, seed=42)\n",
    "address = Address(locale=Locale.EN_GB, seed=42)\n",
    "finance = Finance(locale=Locale.EN_GB, seed=42)\n",
    "datetime = Datetime(locale=Locale.EN_GB, seed=42)\n",
    "profile_mimesis = {\n",
    "    \"Name\": person.full_name(),\n",
    "    \"Address\": address.address(),\n",
    "    \"Email\": person.email(),\n",
    "    \"Job\": person.occupation(),\n",
    "    \"Phone\": person.telephone(),\n",
    "    \"Company\": finance.company(),\n",
    "    \"Date of Birth\": datetime.formatted_date(fmt='%Y-%m-%d', start=1970, end=2005)\n",
    "}\n",
    "print(\"Mimesis User Profile:\")\n",
    "for k, v in profile_mimesis.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabs}\n",
    "```{code-tab} plaintext Faker Output\n",
    "Faker User Profile:\n",
    "Name: William Jennings\n",
    "Address: 2 Sian streets, New Maryton, E3 8ZA\n",
    "Email: francescaharrison@example.com\n",
    "Job: English as a second language teacher\n",
    "Phone: +44151 496 0940\n",
    "Company: Harrison LLC\n",
    "Date of Birth: 1972-04-21\n",
    "```\n",
    "```{code-tab} plaintext Mimesis Output\n",
    "Mimesis User Profile:\n",
    "Name: Anthony Reilly\n",
    "Address: 1310 Blaney Avenue\n",
    "Email: holds1871@live.com\n",
    "Job: Choreographer\n",
    "Phone: 01002 65774\n",
    "Company: Centrica\n",
    "Date of Birth: 1977-01-24\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cba0da",
   "metadata": {},
   "source": [
    "#### 4.4 Generating Text using Faker and Mimesis\n",
    "\n",
    "Generating synthetic text is useful for testing NLP pipelines, populating free-text fields, or simulating survey responses. Here, we show how to generate random sentences, words, paragraphs, and quotes using both Faker and Mimesis, side by side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817d68a",
   "metadata": {},
   "source": [
    "````{tabs}\n",
    "```{code-tab} py Faker\n",
    "fake = Faker()\n",
    "\n",
    "print('Sentence:', fake.sentence())\n",
    "print('Paragraph:', fake.paragraph())\n",
    "print('Text:', fake.text(max_nb_chars=100))\n",
    "print('Word:', fake.word())\n",
    "print('Quote:', fake.catch_phrase())\n",
    "```\n",
    "```{code-tab} py Mimesis\n",
    "from mimesis import Text\n",
    "\n",
    "text = Text()\n",
    "\n",
    "print('Sentence:', text.sentence())\n",
    "print('Paragraph:', text.text(quantity=1))\n",
    "print('Text:', text.text(quantity=2))\n",
    "print('Word:', text.word())\n",
    "print('Quote:', text.quote())\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabs}\n",
    "```{code-tab} plaintext Faker Output\n",
    "Sentence: Other hotel financial want nation.\n",
    "Paragraph: Kitchen together begin town draw story capital piece. Full which agency democratic election cold although because.\n",
    "Text: I president whatever very necessary seat color. Official behind yeah claim focus.\n",
    "Word: team\n",
    "Quote: Compatible modular adapter\n",
    "```\n",
    "```{code-tab} plaintext Mimesis Output\n",
    "Sentence: Messages can be sent to and received from ports, but these messages must obey the so-called \"port protocol.\"\n",
    "Paragraph: Haskell is a standardized, general-purpose purely functional programming language, with non-strict semantics and strong static typing.\n",
    "Text: Erlang is known for its designs that are well suited for systems. The sequential subset of Erlang supports eager evaluation, single assignment, and dynamic typing.\n",
    "Word: recipes\n",
    "Quote: I'm gonna make him an offer he can't refuse.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0cf60b",
   "metadata": {},
   "source": [
    "### 5. Generating Data at Scale with PySpark\n",
    "\n",
    "For large datasets, you can use Faker or Mimesis to generate data and load it into a Spark DataFrame. Below are parallel examples for both libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc718fc0",
   "metadata": {},
   "source": [
    "````{tabs}\n",
    "```{code-tab} py Faker\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"SyntheticDataExample\").getOrCreate()\n",
    "\n",
    "n_rows = 1000\n",
    "\n",
    "\n",
    "fake_uk = Faker('en_GB')\n",
    "fake_uk.seed_instance(42)\n",
    "\n",
    "faker_data = [(fake_uk.name(), fake_uk.address().replace(\"\\n\", \", \"), fake_uk.email()) for _ in range(n_rows)] \n",
    "columns = [\"Name\", \"Address\", \"Email\"] \n",
    "\n",
    "# Check if in virtual environment\n",
    "is_in_venv = os.getenv('VIRTUAL_ENV') is not None\n",
    "\n",
    "if not is_in_venv:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: spark.createDataFrame\")\n",
    "    df_spark = spark.createDataFrame(faker_data, schema=columns)\n",
    "else:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: Pandas DataFrame -> CSV -> Spark DataFrame\")\n",
    "    import pandas as pd\n",
    "    df_pd = pd.DataFrame(faker_data, columns=columns)\n",
    "\n",
    "    file_path = \"personal_data_temp.csv\"\n",
    "    df_pd.to_csv(file_path, index=False)\n",
    "    df_spark = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "df_spark.show(5)\n",
    "spark.stop()\n",
    "```\n",
    "```{code-tab} py Mimesis\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"MimesisDataGeneration\").getOrCreate()\n",
    "\n",
    "# Check if in virtual environment\n",
    "is_in_venv = os.getenv('VIRTUAL_ENV') is not None\n",
    "\n",
    "person = Person(locale=Locale.EN_GB, seed=42)\n",
    "finance = Finance(locale=Locale.EN_GB, seed=42)\n",
    "\n",
    "n_rows = 1000\n",
    "\n",
    "mimesis_data = {\n",
    "    \"First Name\": [person.first_name() for _ in range(n_rows)],\n",
    "    \"Last Name\": [person.last_name() for _ in range(n_rows)],\n",
    "    \"Full Name\": [person.full_name() for _ in range(n_rows)],\n",
    "    \"Gender\": [person.gender() for _ in range(n_rows)],\n",
    "    \"Age\": [person.random.randint(16, 88) for _ in range(n_rows)],\n",
    "    \"Email\": [person.email() for _ in range(n_rows)],\n",
    "    \"Phone Number\": [person.phone_number() for _ in range(n_rows)],\n",
    "    \"Nationality\": [person.nationality() for _ in range(n_rows)],\n",
    "    \"Occupation\": [person.occupation() for _ in range(n_rows)],\n",
    "    \"Bank Name\": [finance.bank() for _ in range(n_rows)],\n",
    "    \"Company Name\": [finance.company() for _ in range(n_rows)],\n",
    "    \"Company Type\": [finance.company_type() for _ in range(n_rows)],\n",
    "    \"Cryptocurrency ISO Code\": [finance.cryptocurrency_iso_code() for _ in range(n_rows)],\n",
    "    \"Cryptocurrency Symbol\": [finance.cryptocurrency_symbol() for _ in range(n_rows)],\n",
    "    \"Currency ISO Code\": [finance.currency_iso_code() for _ in range(n_rows)],\n",
    "    \"Currency Symbol\": [finance.currency_symbol() for _ in range(n_rows)],\n",
    "    \"Random Price\": [finance.price() for _ in range(n_rows)],\n",
    "    \"Price in BTC\": [finance.price_in_btc() for _ in range(n_rows)],\n",
    "    \"Stock Exchange Name\": [finance.stock_exchange() for _ in range(n_rows)],\n",
    "    \"Stock Name\": [finance.stock_name() for _ in range(n_rows)],\n",
    "    \"Stock Ticker\": [finance.stock_ticker() for _ in range(n_rows)]\n",
    "}\n",
    "\n",
    "if not is_in_venv:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: spark.createDataFrame\")\n",
    "    df_mimesis_spark = spark.createDataFrame(\n",
    "        [(v) for v in zip(*mimesis_data.values())],\n",
    "        schema=list(mimesis_data.keys())  \n",
    "    )\n",
    "else:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: Pandas DataFrame -> CSV -> Spark DataFrame\")\n",
    "    df_mimesis_pd = pd.DataFrame(mimesis_data)\n",
    "\n",
    "    file_path = \"mimesis_data_temp.csv\"\n",
    "    df_mimesis_pd.to_csv(file_path, index=False)\n",
    "    df_mimesis_spark = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "     \n",
    "df_mimesis_spark.show(5)\n",
    "spark.stop()\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabs}\n",
    "```{code-tab} plaintext Faker Output\n",
    "is_in_venv: False | Spark DataFrame to be created from: spark.createDataFrame\n",
    "                                                                                \n",
    "+--------------------+--------------------+--------------------+\n",
    "|                Name|             Address|               Email|\n",
    "+--------------------+--------------------+--------------------+\n",
    "|    William Jennings|2 Sian streets, N...|francescaharrison...|\n",
    "|     Rosemary Wright|654 Robin track, ...|simpsongemma@exam...|\n",
    "|         Sean Norton|103 Robinson walk...|  rita19@example.net|\n",
    "|       Brenda Briggs|Studio 4, Lydia i...|iwilkins@example.org|\n",
    "|Leonard Powell-Mo...|Flat 32G, Green c...|andrea01@example.net|\n",
    "+--------------------+--------------------+--------------------+\n",
    "only showing top 5 rows\n",
    "```\n",
    "```{code-tab} plaintext Mimesis Output\n",
    "is_in_venv: False | Spark DataFrame to be created from: spark.createDataFrame\n",
    "                                                                                \n",
    "+----------------+------+---+--------------------+-------------+-----------+--------------+--------------------+\n",
    "|       Full Name|Gender|Age|               Email| Phone Number|Nationality|    Occupation|           Bank Name|\n",
    "+----------------+------+---+--------------------+-------------+-----------+--------------+--------------------+\n",
    "|  Anthony Reilly|  Male| 45| saw1917@outlook.com|023 5108 9063|  Ethiopian|        Brewer|National Counties...|\n",
    "|       Kaley Day| Other| 86|plan1855@protonma...|0893 286 9998|    Belgian| Horse Trainer|The Royal Bank of...|\n",
    "|Cleveland Osborn| Other| 23|finland2058@duck.com|0111 971 3359| Guatemalan|        Driver|Royal Bank of Sco...|\n",
    "|     Zack Holder|Female| 65|differ1890@proton...| 017582 12621| Ecuadorian|        Tailor|Paragon Banking G...|\n",
    "|     Arden Brady| Other| 82| aud2057@example.com|  0800 204605|      Greek|Bakery Manager|     Triodos Bank UK|\n",
    "+----------------+------+---+--------------------+-------------+-----------+--------------+--------------------+\n",
    "only showing top 5 rows\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7402bd85",
   "metadata": {},
   "source": [
    "### 6. Generating Fake Population Data\n",
    "\n",
    "Generating synthetic population data is essential for simulating census datasets, survey microdata, or anonymised samples. In this section, we demonstrate how to create tabular, population-like data with custom categories, such as sex, ethnicity, marital status, and employment status, while also simulating missing values, using the Mimesis library. The same approach and logic can be applied with the Faker library.\n",
    "\n",
    "Note: To generate a name consistent with a specific gender, use the `.person().first_name()` and `.person().last_name()` methods separately, specifying the gender for the first name with the `Gender.MALE` or `Gender.FEMALE` enum from Mimesis. This ensures that gender-related fields (such as first name and title) are logically consistent within each synthetic record."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ccb860",
   "metadata": {},
   "source": [
    "````{tabs}\n",
    "```{code-tab} py Faker\n",
    "from faker import Faker\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "fake = Faker('en_GB')\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "n_rows = 1000\n",
    "shared_address_rows = 10\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('ID', StringType(), True),\n",
    "    StructField('SOURCE_FILE', StringType(), True),\n",
    "    StructField('TIME_STAMP', StringType(), True),\n",
    "    StructField('Local_Authority', StringType(), True),\n",
    "    StructField('Postcode', StringType(), True),\n",
    "    StructField('Address_Line_1', StringType(), True),\n",
    "    StructField('Address_Line_2', StringType(), True),\n",
    "    StructField('Address_Line_3', StringType(), True),\n",
    "    StructField('Address_Line_4', StringType(), True),\n",
    "    StructField('Address_Line_5', StringType(), True),\n",
    "    StructField('Address_Line_6', StringType(), True),\n",
    "    StructField('Last_Name', StringType(), True),\n",
    "    StructField('First_Name', StringType(), True),\n",
    "    StructField('Sex', StringType(), True),\n",
    "    StructField('Title', StringType(), True),\n",
    "    StructField('Marital_Status', StringType(), True),\n",
    "    StructField('DOB', StringType(), True),\n",
    "    StructField('Ethnicity', StringType(), True),\n",
    "    StructField('Education_Level', StringType(), True),\n",
    "    StructField('Nationality', StringType(), True),\n",
    "    StructField('Income', IntegerType(), True),\n",
    "    StructField('Employment_Status', StringType(), True),\n",
    "    StructField('Academic_Degree', StringType(), True),\n",
    "    StructField('guid', StringType(), True)\n",
    "])\n",
    "\n",
    "categories = {\n",
    "    'sex': ['Male', 'Female'],\n",
    "    'marital_status': {\n",
    "        'Male': ['Single', 'Married', 'Divorced', 'Widowed'],\n",
    "        'Female': ['Single', 'Married', 'Divorced', 'Widowed']\n",
    "    },\n",
    "    'education_level': [\n",
    "        'No Qualifications', 'GCSEs', 'A-Levels', 'Apprenticeship',\n",
    "        \"Bachelor's Degree\", \"Master's Degree\", 'PhD'\n",
    "    ],\n",
    "    'ethnicity': ['White', 'Black', 'Asian', 'Mixed', 'Other'],\n",
    "    'employment_status': ['Employed', 'Unemployed', 'Student', 'Retired'],\n",
    "    'academic_degree': [\n",
    "        \"None\", \"Bachelor's Degree\", \"Master's Degree\", \"PhD\", \"Diploma\", \"Certificate\"\n",
    "    ],\n",
    "    'nationality': [\n",
    "        \"British\", \"Irish\", \"Polish\", \"Indian\", \"Pakistani\", \"Nigerian\", \"Chinese\", \"Other\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def maybe_missing(val, p=0.1):\n",
    "    return val if random.random() > p else None\n",
    "\n",
    "def random_timestamp():\n",
    "    return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "shared_address = {\n",
    "    'Local_Authority': fake.county(),\n",
    "    'Postcode': fake.postcode(),\n",
    "    'Address_Line_1': str(random.randint(1, 200)),\n",
    "    'Address_Line_2': fake.street_name(),\n",
    "    'Address_Line_3': None,\n",
    "    'Address_Line_4': fake.city(),\n",
    "    'Address_Line_5': fake.country(),\n",
    "    'Address_Line_6': 'United Kingdom',\n",
    "}\n",
    "\n",
    "columns = [\n",
    "    'ID', 'SOURCE_FILE', 'TIME_STAMP', 'Local_Authority', 'Postcode', 'Address_Line_1',\n",
    "    'Address_Line_2', 'Address_Line_3', 'Address_Line_4', 'Address_Line_5', 'Address_Line_6',\n",
    "    'Last_Name', 'First_Name', 'Sex', 'Title', 'Marital_Status', 'DOB', 'Ethnicity', 'Education_Level',\n",
    "    'Nationality', 'Income', 'Employment_Status', 'Academic_Degree', 'guid'\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for i in range(n_rows):\n",
    "    sex = random.choice(categories['sex'])\n",
    "    first_name = fake.first_name_male() if sex == 'Male' else fake.first_name_female()\n",
    "    title = random.choice(['Mr', 'Dr', 'Prof']) if sex == 'Male' else random.choice(['Ms', 'Mrs', 'Miss', 'Dr', 'Prof'])\n",
    "    last_name = fake.last_name()\n",
    "    marital_status = random.choice(categories['marital_status'][sex])\n",
    "    if i >= n_rows - shared_address_rows:\n",
    "        address = shared_address\n",
    "    else:\n",
    "        address = {\n",
    "            'Local_Authority': fake.county(),\n",
    "            'Postcode': fake.postcode(),\n",
    "            'Address_Line_1': str(random.randint(1, 200)),\n",
    "            'Address_Line_2': fake.street_name(),\n",
    "            'Address_Line_3': None,\n",
    "            'Address_Line_4': fake.city(),\n",
    "            'Address_Line_5': fake.country(),\n",
    "            'Address_Line_6': 'United Kingdom',\n",
    "        }\n",
    "    age = random.randint(18, 99)\n",
    "    dob = (datetime.date.today() - datetime.timedelta(days=age*365 + random.randint(0, 364)))\n",
    "    income_val = maybe_missing(random.randint(25000, 75000))\n",
    "    income_val = int(income_val) if income_val is not None else None\n",
    "    row = {\n",
    "        'ID': str(i+1).zfill(len(str(n_rows))),\n",
    "        'SOURCE_FILE': f\"{fake.user_name()}.csv\",\n",
    "        'TIME_STAMP': random_timestamp(),\n",
    "        **address,\n",
    "        'Last_Name': last_name,\n",
    "        'First_Name': first_name,\n",
    "        'Sex': sex,\n",
    "        'Title': title,\n",
    "        'Marital_Status': marital_status,\n",
    "        'DOB': dob.strftime('%d-%m-%Y'),\n",
    "        'Ethnicity': maybe_missing(random.choice(categories['ethnicity'])),\n",
    "        'Education_Level': maybe_missing(random.choice(categories['education_level'])),\n",
    "        'Nationality': random.choice(categories['nationality']),\n",
    "        'Income': income_val,\n",
    "        'Employment_Status': maybe_missing(random.choice(categories['employment_status'])),\n",
    "        'Academic_Degree': maybe_missing(random.choice(categories['academic_degree'])),\n",
    "        'guid': fake.uuid4()\n",
    "    }\n",
    "    # Ensure all keys are present\n",
    "    for col in columns:\n",
    "        if col not in row:\n",
    "            row[col] = None\n",
    "    rows.append(row)\n",
    "\n",
    "spark = SparkSession.builder.appName(\"FakerData\").getOrCreate()\n",
    "is_in_venv = os.getenv('VIRTUAL_ENV') is not None\n",
    "\n",
    "if is_in_venv:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: CSV file\")\n",
    "    file_path = \"population_data_temp_faker.csv\"\n",
    "    import csv\n",
    "    with open(file_path, \"w\", newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "    population_df = spark.read.csv(file_path, header=True, schema=schema)\n",
    "else:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: spark.createDataFrame\")\n",
    "    population_df = spark.createDataFrame(rows, schema=schema)\n",
    "\n",
    "# To display the first 9 columns and 5 rows\n",
    "population_df.select(population_df.columns[:9]).show(5)\n",
    "\n",
    "# Or if you want to show specific columns\n",
    "cols_to_show = [\"ID\", \"First_Name\", \"Last_Name\", \"Title\", \"Sex\", \"DOB\", \"Ethnicity\", \"Address_Line_1\", \"Address_Line_2\", \"Postcode\"]\n",
    "population_df.select(cols_to_show).show(5)\n",
    "spark.stop()\n",
    "```\n",
    "```{code-tab} py Mimesis\n",
    "from mimesis import Generic\n",
    "from mimesis.locales import Locale\n",
    "from mimesis.enums import Gender, TitleType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "generic = Generic(locale=Locale.EN_GB, seed=42)\n",
    "\n",
    "n_rows = 1000\n",
    "shared_address_rows = 10\n",
    "\n",
    "categories = {\n",
    "    'sex': ['Male', 'Female'],\n",
    "    'marital_status': {\n",
    "        'Male': ['Single', 'Married', 'Divorced', 'Widowed'],\n",
    "        'Female': ['Single', 'Married', 'Divorced', 'Widowed']\n",
    "    },\n",
    "    'education_level': [\n",
    "        'No Qualifications',\n",
    "        'GCSEs',\n",
    "        'A-Levels',\n",
    "        'Apprenticeship',\n",
    "        \"Bachelor's Degree\",\n",
    "        \"Master's Degree\",\n",
    "        'PhD'\n",
    "    ],\n",
    "    'ethnicity': ['White', 'Black', 'Asian', 'Mixed', 'Other'],\n",
    "    'employment_status': ['Employed', 'Unemployed', 'Student', 'Retired']\n",
    "}\n",
    "\n",
    "def maybe_missing(val, p=0.1):\n",
    "    return val if random.random() > p else None\n",
    "\n",
    "def random_timestamp():\n",
    "    return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Shared address for a group\n",
    "shared_address = {\n",
    "    'Local_Authority': generic.address.region(),\n",
    "    'Postcode': generic.address.postal_code(),\n",
    "    'Address_Line_1': str(generic.person.random.randint(1, 200)),\n",
    "    'Address_Line_2': generic.address.street_name(),\n",
    "    'Address_Line_3': np.nan,\n",
    "    'Address_Line_4': generic.address.city(),\n",
    "    'Address_Line_5': generic.address.country(),\n",
    "    'Address_Line_6': 'United Kingdom',\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'Local_Authority': [],\n",
    "    'Postcode': [],\n",
    "    'Address_Line_1': [],\n",
    "    'Address_Line_2': [],\n",
    "    'Address_Line_3': [],\n",
    "    'Address_Line_4': [],\n",
    "    'Address_Line_5': [],\n",
    "    'Address_Line_6': [],\n",
    "    'Last_Name': [],\n",
    "    'First_Name': [],\n",
    "    'Sex': [],\n",
    "    'Title': [],\n",
    "    'Marital_Status': [],\n",
    "    'guid': [],\n",
    "    'SOURCE_FILE': [],\n",
    "    'DOB': [],\n",
    "    'Ethnicity': [],\n",
    "    'Education_Level': [],\n",
    "    'TIME_STAMP': [],\n",
    "    'Nationality': [],\n",
    "    'Income': [],\n",
    "    'Employment_Status': [],\n",
    "    'Academic_Degree': []\n",
    "}\n",
    "\n",
    "for i in range(n_rows):\n",
    "    # Assign sex\n",
    "    sex = random.choice(categories['sex'])\n",
    "    gender_enum = Gender.MALE if sex == 'Male' else Gender.FEMALE\n",
    "    # First name and title consistent with sex\n",
    "    first_name = generic.person.first_name(gender=gender_enum)\n",
    "    title = generic.person.title(gender=gender_enum, title_type=TitleType.TYPICAL)\n",
    "    # Marital status consistent with sex\n",
    "    marital_status = random.choice(categories['marital_status'][sex])\n",
    "    # Shared address for last shared_address_rows\n",
    "    if i >= n_rows - shared_address_rows:\n",
    "        for k in shared_address:\n",
    "            data[k].append(shared_address[k])\n",
    "    else:\n",
    "        data['Local_Authority'].append(generic.address.region())\n",
    "        data['Postcode'].append(generic.address.postal_code())\n",
    "        data['Address_Line_1'].append(str(generic.person.random.randint(1, 200)))\n",
    "        data['Address_Line_2'].append(generic.address.street_name())\n",
    "        data['Address_Line_3'].append(np.nan)\n",
    "        data['Address_Line_4'].append(generic.address.city())\n",
    "        data['Address_Line_5'].append(generic.address.country())\n",
    "        data['Address_Line_6'].append('United Kingdom')\n",
    "    # Names and other fields\n",
    "    last_name = generic.person.last_name()\n",
    "    data['Last_Name'].append(last_name)\n",
    "    data['First_Name'].append(first_name)\n",
    "    data['Sex'].append(sex)\n",
    "    data['Title'].append(title)\n",
    "    data['Marital_Status'].append(marital_status)\n",
    "    data['guid'].append(generic.person.password())\n",
    "    data['SOURCE_FILE'].append(f\"{generic.person.username(mask='l_l')}.csv\")\n",
    "    # Date of Birth: Randomly generate between ages 18-99\n",
    "    dob_year = generic.person.random.randint(1925, 2007)\n",
    "    dob_month = generic.person.random.randint(1, 12)\n",
    "    dob_day = generic.person.random.randint(1, 28)\n",
    "    data['DOB'].append(f\"{dob_day:02d}-{dob_month:02d}-{dob_year}\")\n",
    "    data['Ethnicity'].append(maybe_missing(random.choice(categories['ethnicity'])))\n",
    "    data['Education_Level'].append(maybe_missing(random.choice(categories['education_level'])))\n",
    "    data['TIME_STAMP'].append(random_timestamp())\n",
    "    data['Nationality'].append(generic.person.nationality())\n",
    "    data['Income'].append(maybe_missing(generic.random.randint(25000, 75000)))\n",
    "    data['Employment_Status'].append(maybe_missing(generic.random.choice(categories['employment_status'])))\n",
    "    data['Academic_Degree'].append(maybe_missing(generic.person.academic_degree()))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Add ID column starting from 1\n",
    "df['ID'] = [str(i).zfill(len(str(n_rows))) for i in np.arange(1, n_rows + 1)]\n",
    "# Reorder columns\n",
    "df = df[[\n",
    "    'ID', 'SOURCE_FILE', 'TIME_STAMP', 'Local_Authority', 'Postcode', 'Address_Line_1',\n",
    "    'Address_Line_2', 'Address_Line_3', 'Address_Line_4', 'Address_Line_5', 'Address_Line_6',\n",
    "    'Last_Name', 'First_Name', 'Sex', 'Title', 'Marital_Status', 'DOB', 'Ethnicity', 'Education_Level',\n",
    "    'Nationality', 'Income', 'Employment_Status', 'Academic_Degree', 'guid'\n",
    "]]\n",
    "df.head(12)\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MimesisData\").getOrCreate()\n",
    "\n",
    "# Check if in virtual environment\n",
    "is_in_venv = os.getenv('VIRTUAL_ENV') is not None\n",
    "\n",
    "if is_in_venv:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: Pandas DataFrame -> CSV -> Spark DataFrame\")\n",
    "    file_path = \"population_data_temp.csv\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "    population_df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "else:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: spark.createDataFrame\")\n",
    "    pd.DataFrame.iteritems = pd.DataFrame.items\n",
    "    population_df = spark.createDataFrame(df)\n",
    "    \n",
    "# To display the first 9 columns and 5 rows\n",
    "population_df.select(population_df.columns[:9]).show(5)\n",
    "\n",
    "# Or if you want to show specific columns\n",
    "cols_to_show = [\"ID\", \"First_Name\", \"Last_Name\", \"Title\", \"Sex\", \"DOB\", \"Ethnicity\", \"Address_Line_1\", \"Address_Line_2\", \"Postcode\"]\n",
    "population_df.select(cols_to_show).show(5)\n",
    "spark.stop()\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabs}\n",
    "```{code-tab} plaintext Faker Output\n",
    "is_in_venv: False | Spark DataFrame to be created from: spark.createDataFrame\n",
    "                                                                                \n",
    "+----+----------------+-------------------+---------------+--------+--------------+---------------+--------------+-----------------+\n",
    "|  ID|     SOURCE_FILE|         TIME_STAMP|Local_Authority|Postcode|Address_Line_1| Address_Line_2|Address_Line_3|   Address_Line_4|\n",
    "+----+----------------+-------------------+---------------+--------+--------------+---------------+--------------+-----------------+\n",
    "|0001|  evansleigh.csv|2025-07-01 14:05:16|   Glasgow City| S37 0GS|            63|    White forge|          null|      Timothyland|\n",
    "|0002|palmersandra.csv|2025-07-01 14:05:16|  Pembrokeshire|  M9 9HD|            57|    Irene forks|          null|        Jasonbury|\n",
    "|0003|  wilsonryan.csv|2025-07-01 14:05:16|       Stirling| SN1 8JG|            89|     Lamb route|          null|      Lake Victor|\n",
    "|0004|      ievans.csv|2025-07-01 14:05:16|       Highland|HD3X 6TF|            60|Davidson summit|          null|     Fionachester|\n",
    "|0005|     jemma51.csv|2025-07-01 14:05:16|     Lancashire|CW6W 6RZ|            98|     Hill plaza|          null|Lake Geoffreyside|\n",
    "+----+----------------+-------------------+---------------+--------+--------------+---------------+--------------+-----------------+\n",
    "only showing top 5 rows\n",
    "\n",
    "+----+----------+---------+-----+------+----------+---------+--------------+---------------+--------+\n",
    "|  ID|First_Name|Last_Name|Title|   Sex|       DOB|Ethnicity|Address_Line_1| Address_Line_2|Postcode|\n",
    "+----+----------+---------+-----+------+----------+---------+--------------+---------------+--------+\n",
    "|0001|    Howard|   Foster|   Mr|  Male|03-05-1979|     null|            63|    White forge| S37 0GS|\n",
    "|0002|   Bernard|Wilkinson| Prof|  Male|22-09-1949|    White|            57|    Irene forks|  M9 9HD|\n",
    "|0003|    Sheila|    Evans|   Ms|Female|12-03-1930|    Other|            89|     Lamb route| SN1 8JG|\n",
    "|0004|      Ryan|    Kelly|   Dr|  Male|27-12-1994|    Asian|            60|Davidson summit|HD3X 6TF|\n",
    "|0005|     Peter|   Taylor|   Mr|  Male|21-08-1972|    Asian|            98|     Hill plaza|CW6W 6RZ|\n",
    "+----+----------+---------+-----+------+----------+---------+--------------+---------------+--------+\n",
    "only showing top 5 rows\n",
    "\n",
    "```\n",
    "```{code-tab} plaintext Mimesis Output\n",
    "is_in_venv: False | Spark DataFrame to be created from: spark.createDataFrame\n",
    "                                                                                \n",
    "+----+--------------------+-------------------+----------------+--------+--------------+--------------+--------------+--------------+\n",
    "|  ID|         SOURCE_FILE|         TIME_STAMP| Local_Authority|Postcode|Address_Line_1|Address_Line_2|Address_Line_3|Address_Line_4|\n",
    "+----+--------------------+-------------------+----------------+--------+--------------+--------------+--------------+--------------+\n",
    "|0001|guitars_appeared.csv|2025-07-01 13:57:58|   County Armagh|FN0F 6OF|           190|   Invergourie|           NaN|         Luton|\n",
    "|0002|motors_chronicle.csv|2025-07-01 13:57:58|            Avon|TE4H 2TC|            57|  Druminiskill|           NaN|     Charlbury|\n",
    "|0003|  buffalo_grande.csv|2025-07-01 13:57:58|         Norfolk|PU7N 9JO|           187|     Killylane|           NaN|       Redhill|\n",
    "|0004|    treating_dsl.csv|2025-07-01 13:57:58|           Essex|SB2H 0GC|           117|  Craigatempin|           NaN|   Wednesfield|\n",
    "|0005|mariah_substantia...|2025-07-01 13:57:58|Northamptonshire|EJ6S 6BQ|           176|     Granshagh|           NaN|     Kirkcaldy|\n",
    "+----+--------------------+-------------------+----------------+--------+--------------+--------------+--------------+--------------+\n",
    "only showing top 5 rows\n",
    "\n",
    "+----+----------+---------+-----+------+----------+---------+--------------+--------------+--------+\n",
    "|  ID|First_Name|Last_Name|Title|   Sex|       DOB|Ethnicity|Address_Line_1|Address_Line_2|Postcode|\n",
    "+----+----------+---------+-----+------+----------+---------+--------------+--------------+--------+\n",
    "|0001| Cornelius| Ferguson|  Mr.|  Male|23-04-1996|    Mixed|           190|   Invergourie|FN0F 6OF|\n",
    "|0002|       Tom|     Hunt|  Sir|  Male|12-02-1973|     null|            57|  Druminiskill|TE4H 2TC|\n",
    "|0003|   Kenisha|    James| Mrs.|Female|28-02-1962|    White|           187|     Killylane|PU7N 9JO|\n",
    "|0004|    Manuel|   Mosley|  Sir|  Male|09-07-1984|    Mixed|           117|  Craigatempin|SB2H 0GC|\n",
    "|0005|    Tyrone|      Gay|  Mr.|  Male|15-11-1975|    Black|           176|     Granshagh|EJ6S 6BQ|\n",
    "+----+----------+---------+-----+------+----------+---------+--------------+--------------+--------+\n",
    "only showing top 5 rows\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce56c3fa",
   "metadata": {},
   "source": [
    "### 7. Best Practices\n",
    "\n",
    "* Set a random seed for reproducibility.\n",
    "* Choose the appropriate locale for your use case.\n",
    "* Combine multiple providers for richer data.\n",
    "* For large datasets, use PySpark or batch processing.\n",
    "* Refer to the Faker documentation and Mimesis documentation for more features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2fead2",
   "metadata": {},
   "source": [
    "### 8. Conclusion\n",
    "Synthetic data generation is a powerful tool for testing, privacy protection, and simulation. Both Faker and Mimesis offer extensive capabilities for generating realistic, diverse data in Python. By using parallel examples, you can choose the library that best fits your needs and easily adapt your code for different scenarios.\n",
    "\n",
    "We have demonstrated:\n",
    "- The core concepts of providers and locales.\n",
    "- How to generate a wide range of data types, including text, user profiles, and population data.\n",
    "- How to scale up data generation using PySpark.\n",
    "- Best practices for reproducibility and data realism.\n",
    "\n",
    "Feel free to expand on these examples and adapt them to your own projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66f0576",
   "metadata": {},
   "source": [
    "### References and further reading\n",
    "* [Faker Documentation (Python)](https://faker.readthedocs.io/en/master/)\n",
    "* [Mimesis API](https://mimesis.name/v12.1.1/api.html)\n",
    "* [Medium Blog on Mimesis](https://medium.com/@tubelwj/mimesis-a-python-library-for-generating-test-sample-data-7809d894cbd9)\n",
    "* [Getting Started with Mimesis: A Modern Approach to Synthetic Data Generation](https://www.statology.org/getting-started-mimesis-modern-approach-synthetic-data-generation/)\n",
    "* [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/index.html)\n",
    "* [Synthpop: Synthetic Data in R](../ancillary-topics/synthpop_with_r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
