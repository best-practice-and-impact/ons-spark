{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faker: Synthetic Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction to Faker\n",
    "\n",
    "`Faker` is a Python package that generates fake data such as names, addresses, emails, dates, credit card numbers, and more. It is similar to [`Mimesis`](../ancillary-topics/mimesis.html)\n",
    "\n",
    "**Key Features:** Randomised generation, locale support, wide range of data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Install required libraries\n",
    "To start, we will need the `Faker` library to generate the dummy data. Additionally, we will use PySpark for working with Spark DataFrames in Python.\n",
    "\n",
    "For Python, use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://njobud:****@onsart-01.ons.statistics.gov.uk/artifactory/api/pypi/yr-python/simple\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'onsart-01.ons.statistics.gov.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting Faker\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'onsart-01.ons.statistics.gov.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  Downloading https://onsart-01.ons.statistics.gov.uk/artifactory/api/pypi/yr-python/packages/packages/96/18/f70c67c9d3a71f1749faa027dad3cd626c728df5682458091d73c69ed9a9/Faker-35.2.2-py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /runtime-addons/cmladdon-2.0.47-b365/opt/cmladdons/python/site-packages (from Faker) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions in /runtime-addons/cmladdon-2.0.47-b365/opt/cmladdons/python/site-packages (from Faker) (4.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /runtime-addons/cmladdon-2.0.47-b365/opt/cmladdons/python/site-packages (from python-dateutil>=2.4->Faker) (1.17.0)\n",
      "Installing collected packages: Faker\n",
      "Successfully installed Faker-35.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further details to assist on the setup, please visit the [official documentation](https://faker.readthedocs.io/en/master/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the version of the `Faker` package installed in your environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faker_version: 35.2.2\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "faker_version = pkg_resources.get_distribution(\"Faker\").version\n",
    "print(f\"faker_version: {faker_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up a global random seed for reproducibility**\n",
    "\n",
    "You can set a global seed for all data providers and use it without explicitly passing it to each provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "fake = Faker()\n",
    "fake.seed_instance(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate a first fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Allison Hill\n",
      "Email: donaldgarcia@example.net\n",
      "Address: 600 Jeffery Parkways, New Jamesside, MT 29394\n",
      "Phone: 394.802.6542x351\n",
      "Birthday: 1941-05-13\n"
     ]
    }
   ],
   "source": [
    "# Generate sample personal data\n",
    "print(\"Name:\", fake.name())\n",
    "print(\"Email:\", fake.email())\n",
    "print(\"Address:\", (fake.address()).replace(\"\\n\", \", \")) # the address method has new line characters (\\n), hence, replace with \", \" to have all in one line\n",
    "print(\"Phone:\", fake.phone_number())\n",
    "print(\"Birthday:\", fake.date_of_birth(minimum_age=18, maximum_age=90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. International data generation\n",
    "\n",
    "\n",
    "Faker has a great feature that allows it to generate data tailored to specific locales. Here's how you can create data that reflects various locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US: 737 Christopher Springs Suite 170, South Lisa, NM 20713\n",
      "UK: Studio 8, Thomas ports, Coopertown, M56 9QR\n",
      "France: 5, rue Alves, 54783 Fournier\n",
      "Japan: 静岡県袖ケ浦市麹町4丁目7番20号\n"
     ]
    }
   ],
   "source": [
    "# Create localised Faker instances\n",
    "fake_us = Faker('en_US')\n",
    "fake_uk = Faker('en_GB')\n",
    "fake_fr = Faker('fr_FR')\n",
    "fake_jp = Faker('ja_JP')\n",
    "\n",
    "print(\"US:\", fake_us.address().replace(\"\\n\", \", \"))\n",
    "print(\"UK:\", fake_uk.address().replace(\"\\n\", \", \"))\n",
    "print(\"France:\", fake_fr.address().replace(\"\\n\", \", \"))\n",
    "print(\"Japan:\", fake_jp.address().replace(\"\\n\", \", \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the differences in address formats:\n",
    "\n",
    "* US addresses include state abbreviations and ZIP codes.  \n",
    "* UK addresses use British postal codes.  \n",
    "* France addresses follow European conventions.  \n",
    "* Japan addresses are formatted with the correct characters and local conventions.\n",
    "\n",
    "\n",
    "For an up-to-date list of supported locales, you can check the [official documentation](https://fakerjs.dev/guide/localization.html#available-locales)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Faker’s provider architecture\n",
    "\n",
    "\n",
    "Faker utilises a modular system of \"providers,\" where each provider is responsible for generating a specific type of data. Let's take a closer look at how providers work and the types available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Faker Providers:\n",
      "- <faker.providers.user_agent.Provider object at 0x7f8357bb7c40>\n",
      "- <faker.providers.ssn.en_GB.Provider object at 0x7f8357bb7be0>\n",
      "- <faker.providers.sbn.Provider object at 0x7f8357bb7b80>\n",
      "- <faker.providers.python.Provider object at 0x7f8357bb7b20>\n",
      "- <faker.providers.profile.Provider object at 0x7f8357bb7ac0>\n",
      "- <faker.providers.phone_number.en_GB.Provider object at 0x7f8357bb7a60>\n",
      "- <faker.providers.person.en_GB.Provider object at 0x7f8357bb7940>\n",
      "- <faker.providers.passport.en_US.Provider object at 0x7f8357bb79a0>\n",
      "- <faker.providers.misc.en_US.Provider object at 0x7f8357bb7880>\n",
      "- <faker.providers.lorem.la.Provider object at 0x7f8357bb77f0>\n",
      "- <faker.providers.job.en_US.Provider object at 0x7f8357bb78b0>\n",
      "- <faker.providers.isbn.en_US.Provider object at 0x7f8357bb76d0>\n",
      "- <faker.providers.internet.en_GB.Provider object at 0x7f8357bb77c0>\n",
      "- <faker.providers.geo.en_US.Provider object at 0x7f8357bb7760>\n",
      "- <faker.providers.file.Provider object at 0x7f8357bb7730>\n",
      "- <faker.providers.emoji.Provider object at 0x7f8357bb7610>\n",
      "- <faker.providers.date_time.en_US.Provider object at 0x7f836c1b0bb0>\n",
      "- <faker.providers.currency.en_US.Provider object at 0x7f836c1b0e20>\n",
      "- <faker.providers.credit_card.en_US.Provider object at 0x7f836c1b0e80>\n",
      "- <faker.providers.company.en_US.Provider object at 0x7f836c1b0e50>\n",
      "- <faker.providers.color.en_US.Provider object at 0x7f836c1a3dc0>\n",
      "- <faker.providers.barcode.en_US.Provider object at 0x7f836c1e4d00>\n",
      "- <faker.providers.bank.en_GB.Provider object at 0x7f836c1a32e0>\n",
      "- <faker.providers.automotive.en_GB.Provider object at 0x7f836c1a3a30>\n",
      "- <faker.providers.address.en_GB.Provider object at 0x7f836c1a3af0>\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "\n",
    "fake = Faker('en_GB')\n",
    "\n",
    "print(\"Available Faker Providers:\")\n",
    "for provider in fake.providers:\n",
    "    print(f\"- {provider}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the list corresponds to a specific provider, such as:\n",
    "\n",
    "- **User Agent Provider:** Generates browser and device identification strings.  \n",
    "- **SSN Provider:** Creates valid-format social security numbers (US-specific).  \n",
    "- **SBN Provider:** Generates 9-digit Standard Book Numbers (used in older systems prior to 1974).  \n",
    "\n",
    "In addition to these, Faker includes other commonly used providers for generating various types of data:\n",
    "\n",
    "- **Person Provider:** Generates names, birthdates, and personal details.  \n",
    "- **Address Provider:** Produces realistic street addresses and postal codes.\n",
    "- **Internet Provider:** Generates email addresses, domain names, and URLs.\n",
    "\n",
    "You can explore the full list of available providers and their methods in the official documentation, which offers detailed information and usage examples for each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Best practices for using Faker\n",
    "\n",
    "When working with Faker, keep the following best practices in mind:\n",
    "\n",
    "- Select locale-specific providers when generating data tailored to a particular region.\n",
    "- Combine different providers to generate more realistic and interconnected data.\n",
    "- Organise your fake data generation to align with the requirements of your application.\n",
    "- Explore the official documentation to learn about additional provider features and options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Building a typical dataset\n",
    "\n",
    "\n",
    "Now, let's explore how to combine multiple providers to generate rich and interconnected data for more complex structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>email</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>postcode</th>\n",
       "      <th>job</th>\n",
       "      <th>company</th>\n",
       "      <th>username</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William Jennings</td>\n",
       "      <td>35</td>\n",
       "      <td>francisdavidson@example.org</td>\n",
       "      <td>600 Charlie fort</td>\n",
       "      <td>New Joeside</td>\n",
       "      <td>DT79 0GS</td>\n",
       "      <td>Librarian, public</td>\n",
       "      <td>Bryan-Andrews</td>\n",
       "      <td>timothy16</td>\n",
       "      <td>http://butler-gough.info/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benjamin Simpson</td>\n",
       "      <td>42</td>\n",
       "      <td>fisherteresa@example.net</td>\n",
       "      <td>Studio 31 Irene forks</td>\n",
       "      <td>Jasonbury</td>\n",
       "      <td>S4 5GQ</td>\n",
       "      <td>Marine scientist</td>\n",
       "      <td>Davies Ltd</td>\n",
       "      <td>johnronald</td>\n",
       "      <td>http://www.lamb-scott.co.uk/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ricky Lloyd-Duncan</td>\n",
       "      <td>67</td>\n",
       "      <td>wilsonryan@example.com</td>\n",
       "      <td>Flat 13K Kelly parks</td>\n",
       "      <td>Youngmouth</td>\n",
       "      <td>M23 9SY</td>\n",
       "      <td>Oceanographer</td>\n",
       "      <td>Lloyd-Turner</td>\n",
       "      <td>dgreen</td>\n",
       "      <td>http://www.walsh.biz/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr Jasmine Smith</td>\n",
       "      <td>53</td>\n",
       "      <td>daviesgeoffrey@example.net</td>\n",
       "      <td>Studio 51s Steele alley</td>\n",
       "      <td>Donnaburgh</td>\n",
       "      <td>E4W 2QG</td>\n",
       "      <td>Solicitor, Scotland</td>\n",
       "      <td>Bell, Anderson and Jones</td>\n",
       "      <td>murraymohammad</td>\n",
       "      <td>http://www.shaw.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norman Sharp-Stewart</td>\n",
       "      <td>52</td>\n",
       "      <td>scottknowles@example.net</td>\n",
       "      <td>89 Arnold plains</td>\n",
       "      <td>Lake Graeme</td>\n",
       "      <td>SG57 1JJ</td>\n",
       "      <td>Bonds trader</td>\n",
       "      <td>Brown-Naylor</td>\n",
       "      <td>thomashammond</td>\n",
       "      <td>http://www.howe.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  age                        email  \\\n",
       "0      William Jennings   35  francisdavidson@example.org   \n",
       "1      Benjamin Simpson   42     fisherteresa@example.net   \n",
       "2    Ricky Lloyd-Duncan   67       wilsonryan@example.com   \n",
       "3      Dr Jasmine Smith   53   daviesgeoffrey@example.net   \n",
       "4  Norman Sharp-Stewart   52     scottknowles@example.net   \n",
       "\n",
       "                    street         city  postcode                  job  \\\n",
       "0         600 Charlie fort  New Joeside  DT79 0GS    Librarian, public   \n",
       "1    Studio 31 Irene forks    Jasonbury    S4 5GQ     Marine scientist   \n",
       "2     Flat 13K Kelly parks   Youngmouth   M23 9SY        Oceanographer   \n",
       "3  Studio 51s Steele alley   Donnaburgh   E4W 2QG  Solicitor, Scotland   \n",
       "4         89 Arnold plains  Lake Graeme  SG57 1JJ         Bonds trader   \n",
       "\n",
       "                    company        username                       website  \n",
       "0             Bryan-Andrews       timothy16     http://butler-gough.info/  \n",
       "1                Davies Ltd      johnronald  http://www.lamb-scott.co.uk/  \n",
       "2              Lloyd-Turner          dgreen         http://www.walsh.biz/  \n",
       "3  Bell, Anderson and Jones  murraymohammad          http://www.shaw.com/  \n",
       "4              Brown-Naylor   thomashammond          http://www.howe.com/  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "fake = Faker('en_GB')\n",
    "fake.seed_instance(42)\n",
    "\n",
    "n_rows = 100\n",
    "\n",
    "\n",
    "def generate_user_profile():\n",
    "    \"\"\" Function to generate a user profile \"\"\"\n",
    "    return {\n",
    "        'name': fake.name(),\n",
    "        'age': fake.random_int(min=18, max=80),\n",
    "        'email': fake.email(),\n",
    "        \n",
    "        'street': fake.street_address().replace(\"\\n\", \" \"),\n",
    "        'city': fake.city(),\n",
    "        'postcode': fake.postcode(),\n",
    "        \n",
    "        'job': fake.job(),\n",
    "        'company': fake.company(),\n",
    "        \n",
    "        'username': fake.user_name(),\n",
    "        'website': fake.url()\n",
    "    }\n",
    " \n",
    "profiles = [generate_user_profile() for _ in range(n_rows)]\n",
    " \n",
    "df = pd.DataFrame(profiles)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Using synthetic data with big data frameworks\n",
    "\n",
    "#### 8.1. Using synthetic data with PySpark\n",
    "\n",
    "Demonstrate how to create synthetic data in PySpark and use it within Spark DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                Name|             Address|               Email|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|    William Jennings|2 Sian streets, N...|francescaharrison...|\n",
      "|     Rosemary Wright|654 Robin track, ...|simpsongemma@exam...|\n",
      "|         Sean Norton|103 Robinson walk...|  rita19@example.net|\n",
      "|       Brenda Briggs|Studio 4, Lydia i...|iwilkins@example.org|\n",
      "|Leonard Powell-Mo...|Flat 32G, Green c...|andrea01@example.net|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Initialise Spark session\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"Synthetic Data Example\").getOrCreate()\n",
    "\n",
    "\n",
    "# Create synthetic data with Faker\n",
    "fake = Faker('en_GB')\n",
    "fake.seed_instance(42)\n",
    "\n",
    "n_rows = 100\n",
    "data = [(fake.name(), fake.address(), fake.email()) for _ in range(n_rows)]\n",
    "\n",
    "df_pandas = pd.DataFrame(data, columns=[\"Name\", \"Address\", \"Email\"])\n",
    "\n",
    "# Replace newline characters with commas in the 'Address' column using chaining\n",
    "df_pandas['Address'] = df_pandas['Address'].str.replace(\"\\n\", \", \")\n",
    "\n",
    "#I'm having problems when using spark.createDataFrame with virtual environment, hence, I have to create a csv file and read it\n",
    "df_pandas.to_csv('temp_01.csv', index=False)\n",
    "\n",
    "df_spark = spark.read.csv('temp_01.csv', header=True, inferSchema=True)\n",
    "\n",
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application to Big Data:**\n",
    "\n",
    "This example can be extended to generate large datasets (millions of records) that can be processed in parallel using PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2. Generate synthetic data with more features\n",
    "\n",
    "We will generate synthetic data with the following additional features:\n",
    "1. Mode of Transportation (Car, Public Transport, Walking, etc.)  \n",
    "2. Highest Education (High School, Bachelor's, Master's, PhD, etc.)  \n",
    "3. Marital Status (Single, Married, Divorced, Widowed)  \n",
    "4. Favorite High Street Supermarket (Tesco, Sainsbury's, Asda, etc.)  \n",
    "5. Pet Ownership (Yes, No - with type of pet if Yes)  \n",
    "\n",
    "We will also simulate some missing data in the dataset, which is commonly encountered in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>City</th>\n",
       "      <th>Email</th>\n",
       "      <th>Mode_of_Transport</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Supermarket</th>\n",
       "      <th>Pet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William Jennings</td>\n",
       "      <td>2 Sian streets, New Maryton, E3 8ZA</td>\n",
       "      <td>L8G 7YL</td>\n",
       "      <td>Port Samchester</td>\n",
       "      <td>ricky23@example.com</td>\n",
       "      <td>Car</td>\n",
       "      <td>None</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr Josh Pritchard</td>\n",
       "      <td>Studio 16, Lynn hill, Melissaborough, BR0X 4DJ</td>\n",
       "      <td>S4 5GQ</td>\n",
       "      <td>Rhysview</td>\n",
       "      <td>johnronald@example.net</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>High School</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Morrisons</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leigh Randall</td>\n",
       "      <td>0 Alexander circles, New Guy, W67 4FJ</td>\n",
       "      <td>NW8M 9RQ</td>\n",
       "      <td>East Natasha</td>\n",
       "      <td>dgreen@example.org</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lorraine Palmer</td>\n",
       "      <td>Studio 01, Read junctions, West Tracyburgh, AB...</td>\n",
       "      <td>MK9H 5GX</td>\n",
       "      <td>New Brandonfort</td>\n",
       "      <td>griffithslinda@example.com</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Married</td>\n",
       "      <td>Waitrose</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>June Sharp</td>\n",
       "      <td>782 Hill rest, Arnoldside, SM3Y 6QT</td>\n",
       "      <td>W1D 1PA</td>\n",
       "      <td>New Gerald</td>\n",
       "      <td>hammondjulia@example.org</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Single</td>\n",
       "      <td>Asda</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                                            Address  \\\n",
       "0   William Jennings                2 Sian streets, New Maryton, E3 8ZA   \n",
       "1  Dr Josh Pritchard     Studio 16, Lynn hill, Melissaborough, BR0X 4DJ   \n",
       "2      Leigh Randall              0 Alexander circles, New Guy, W67 4FJ   \n",
       "3    Lorraine Palmer  Studio 01, Read junctions, West Tracyburgh, AB...   \n",
       "4         June Sharp                782 Hill rest, Arnoldside, SM3Y 6QT   \n",
       "\n",
       "   Postcode             City                       Email Mode_of_Transport  \\\n",
       "0   L8G 7YL  Port Samchester         ricky23@example.com               Car   \n",
       "1    S4 5GQ         Rhysview      johnronald@example.net  Public Transport   \n",
       "2  NW8M 9RQ     East Natasha          dgreen@example.org  Public Transport   \n",
       "3  MK9H 5GX  New Brandonfort  griffithslinda@example.com  Public Transport   \n",
       "4   W1D 1PA       New Gerald    hammondjulia@example.org  Public Transport   \n",
       "\n",
       "     Education Marital_Status Supermarket   Pet  \n",
       "0         None        Widowed       Tesco   Cat  \n",
       "1  High School        Widowed   Morrisons   Cat  \n",
       "2          PhD        Married        None  None  \n",
       "3      Primary        Married    Waitrose  None  \n",
       "4      Primary         Single        Asda   Dog  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "from faker.generator import random\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "fake = Faker('en_GB')\n",
    "fake.seed_instance(42)\n",
    "\n",
    "n_samples = 1000   \n",
    "\n",
    "# Create lists of categories for features not captured in the Faker library\n",
    "mode_of_transport = ['Car', 'Public Transport', 'Walking', 'Cycling', 'Taxi']\n",
    "education_levels = ['Primary', 'High School', 'Vocational', 'Bachelor\\'s', 'Master\\'s', 'PhD']\n",
    "marital_status = ['Single', 'Married', 'Divorced', 'Widowed']\n",
    "supermarkets = ['Tesco', 'Sainsbury\\'s', 'Asda', 'Morrisons', 'Waitrose']\n",
    "pets = ['Dog', 'Cat', 'None']\n",
    "\n",
    "# Generate synthetic data with the new features\n",
    "data = []\n",
    "for _ in range(n_samples):\n",
    "    name = fake.name()\n",
    "    address = fake.address()\n",
    "    postcode = fake.postcode()\n",
    "    city = fake.city()\n",
    "    email = fake.email()\n",
    "    transport = fake.random_element(mode_of_transport)\n",
    "    education = fake.random_element(education_levels)\n",
    "    marital = fake.random_element(marital_status)\n",
    "    supermarket = fake.random_element(supermarkets)\n",
    "    pet = fake.random_element(pets)\n",
    "    \n",
    "    # Simulating missing data by randomly omitting some features\n",
    "    if random.random() < 0.1:  # 10% chance to have missing data for 'Mode of Transport'\n",
    "        transport = None\n",
    "    if random.random() < 0.1:  # 10% chance to have missing data for 'Education'\n",
    "        education = None\n",
    "    if random.random() < 0.1:  # 10% chance to have missing data for 'Marital Status'\n",
    "        marital = None\n",
    "    if random.random() < 0.1:  # 10% chance to have missing data for 'Supermarket'\n",
    "        supermarket = None\n",
    "    if random.random() < 0.1:  # 10% chance to have missing data for 'Pet'\n",
    "        pet = None\n",
    "\n",
    "    data.append([name, address, postcode, city, email, transport, education, marital, supermarket, pet])\n",
    "\n",
    "\n",
    "columns = ['Name', 'Address', 'Postcode', 'City', 'Email', 'Mode_of_Transport', 'Education', 'Marital_Status', 'Supermarket', 'Pet']\n",
    "synthetic_df = pd.DataFrame(data, columns=columns)\n",
    "synthetic_df['Address'] = synthetic_df['Address'].str.replace(\"\\n\", \", \")\n",
    "\n",
    "\n",
    "synthetic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integrate with PySpark for Big Data Workflow**\n",
    "\n",
    "Now that we have a robust dataset with additional features and some missing data, let's see how to integrate this with PySpark, which is commonly used in big data workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------+---------------+--------------------+-----------------+-----------+--------------+-----------+----+\n",
      "|             Name|             Address|Postcode|           City|               Email|Mode_of_Transport|  Education|Marital_Status|Supermarket| Pet|\n",
      "+-----------------+--------------------+--------+---------------+--------------------+-----------------+-----------+--------------+-----------+----+\n",
      "| William Jennings|2 Sian streets, N...| L8G 7YL|Port Samchester| ricky23@example.com|              Car|       null|       Widowed|      Tesco| Cat|\n",
      "|Dr Josh Pritchard|Studio 16, Lynn h...|  S4 5GQ|       Rhysview|johnronald@exampl...| Public Transport|High School|       Widowed|  Morrisons| Cat|\n",
      "|    Leigh Randall|0 Alexander circl...|NW8M 9RQ|   East Natasha|  dgreen@example.org| Public Transport|        PhD|       Married|       null|None|\n",
      "|  Lorraine Palmer|Studio 01, Read j...|MK9H 5GX|New Brandonfort|griffithslinda@ex...| Public Transport|    Primary|       Married|   Waitrose|null|\n",
      "|       June Sharp|782 Hill rest, Ar...| W1D 1PA|     New Gerald|hammondjulia@exam...| Public Transport|    Primary|        Single|       Asda| Dog|\n",
      "+-----------------+--------------------+--------+---------------+--------------------+-----------------+-----------+--------------+-----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"SyntheticDataForBigData\").getOrCreate()\n",
    "\n",
    "# Convert the synthetic DataFrame to a Spark DataFrame\n",
    "# Currently, using the createDataFrame on a virtual environment raising error. So, I will convert to a csv file and read the file using spark\n",
    "# spark_df = spark.createDataFrame(synthetic_df)\n",
    "synthetic_df.to_csv('temp.csv', index=False)\n",
    "\n",
    "spark_df = spark.read.csv('temp.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Show the Spark DataFrame\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Generating synthetic data is a crucial tool for testing algorithms, saving resources, and maintaining privacy. Faker offers various providers to generate synthetic data on Python and big data frameworks like `PySpark`  can help handle large datasets efficiently.\n",
    "\n",
    "\n",
    "### References and further reading\n",
    "* [Faker Documentation (Python)](https://faker.readthedocs.io/en/master/)\n",
    "* [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/index.html)\n",
    "* [Synthpop: Syntheic Data in `R`](../ancillary-topics/synthpop_with_r)\n",
    "* [Mimesis: Synthetic Data in Python](../ancillary-topics/mimesis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
