{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generating Synthetic/Dummy Data Using Faker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction to Faker\n",
    "\n",
    "`Faker` is a Python package that generates fake data such as names, addresses, emails, dates, credit card numbers, and more.\n",
    "\n",
    "**Key Features:** Randomised generation, locale support, wide range of data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Install required libraries\n",
    "To start, we will need the `Faker` library to generate the dummy data. Additionally, we will use PySpark for working with Spark DataFrames in Python.\n",
    "\n",
    "For Python, use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://njobud:****@onsart-01/artifactory/api/pypi/yr-python/simple\n",
      "Requirement already satisfied: Faker in d:\\github\\forks\\ons-spark\\.venv\\lib\\site-packages (37.1.0)\n",
      "Requirement already satisfied: tzdata in d:\\github\\forks\\ons-spark\\.venv\\lib\\site-packages (from Faker) (2025.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://njobud:****@onsart-01/artifactory/api/pypi/yr-python/simple\n",
      "Requirement already satisfied: setuptools in d:\\github\\forks\\ons-spark\\.venv\\lib\\site-packages (78.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install Faker\n",
    "!pip install setuptools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further details to assist on the setup, please visit the [official documentation](https://faker.readthedocs.io/en/master/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the version of the `Faker` package installed in your environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faker_version: 37.1.0\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "faker_version = pkg_resources.get_distribution(\"Faker\").version\n",
    "print(f\"faker_version: {faker_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up a global random seed for reproducibility**\n",
    "\n",
    "You can set a global seed for all data providers and use it without explicitly passing it to each provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "fake = Faker()\n",
    "fake.seed_instance(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate a first fake dData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Allison Hill\n",
      "Email: donaldgarcia@example.net\n",
      "Address: 600 Jeffery Parkways, New Jamesside, MT 29394\n",
      "Phone: 394.802.6542x351\n",
      "Birthday: 1947-06-02\n"
     ]
    }
   ],
   "source": [
    "# Generate sample personal data\n",
    "print(\"Name:\", fake.name())\n",
    "print(\"Email:\", fake.email())\n",
    "print(\"Address:\", (fake.address()).replace(\"\\n\", \", \")) # the address method has new line characters (\\n), hence, replace with \", \" to have all in one line\n",
    "print(\"Phone:\", fake.phone_number())\n",
    "print(\"Birthday:\", fake.date_of_birth(minimum_age=18, maximum_age=90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. International data generation\n",
    "\n",
    "\n",
    "Faker has a great feature that allows it to generate data tailored to specific locales. Here's how you can create data that reflects various locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US: 6828 Rachel Mountain Suite 480, Port Bryanshire, MD 52233\n",
      "UK: 071 Hollie vista, Garethside, TA4 2ND\n",
      "France: 75, rue Claudine Buisson, 20591 Allarddan\n",
      "Japan: 山梨県小平市蟇沼19丁目9番2号 シティ入谷630\n"
     ]
    }
   ],
   "source": [
    "# Create localised Faker instances\n",
    "fake_us = Faker('en_US')\n",
    "fake_uk = Faker('en_GB')\n",
    "fake_fr = Faker('fr_FR')\n",
    "fake_jp = Faker('ja_JP')\n",
    "\n",
    "print(\"US:\", fake_us.address().replace(\"\\n\", \", \"))\n",
    "print(\"UK:\", fake_uk.address().replace(\"\\n\", \", \"))\n",
    "print(\"France:\", fake_fr.address().replace(\"\\n\", \", \"))\n",
    "print(\"Japan:\", fake_jp.address().replace(\"\\n\", \", \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the differences in address formats:\n",
    "\n",
    "* US addresses include state abbreviations and ZIP codes.  \n",
    "* UK addresses use British postal codes.  \n",
    "* France addresses follow European conventions.  \n",
    "* Japan addresses are formatted with the correct characters and local conventions.\n",
    "\n",
    "\n",
    "For an up-to-date list of supported locales, you can check the [official documentation](https://fakerjs.dev/guide/localization.html#available-locales)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Faker’s provider architecture\n",
    "\n",
    "\n",
    "Faker utilises a modular system of \"providers,\" where each provider is responsible for generating a specific type of data. Let's take a closer look at how providers work and the types available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Faker Providers:\n",
      "- <faker.providers.user_agent.Provider object at 0x000002B7A21F4D40>\n",
      "- <faker.providers.ssn.en_GB.Provider object at 0x000002B7A21F4BF0>\n",
      "- <faker.providers.sbn.Provider object at 0x000002B7A21F45F0>\n",
      "- <faker.providers.python.Provider object at 0x000002B7A21F4650>\n",
      "- <faker.providers.profile.Provider object at 0x000002B7A21F5A00>\n",
      "- <faker.providers.phone_number.en_GB.Provider object at 0x000002B7A21F45C0>\n",
      "- <faker.providers.person.en_GB.Provider object at 0x000002B7A21F4530>\n",
      "- <faker.providers.passport.en_US.Provider object at 0x000002B7A2124B00>\n",
      "- <faker.providers.misc.en_US.Provider object at 0x000002B7A21AC320>\n",
      "- <faker.providers.lorem.la.Provider object at 0x000002B7A21F4560>\n",
      "- <faker.providers.job.en_US.Provider object at 0x000002B7A21F44A0>\n",
      "- <faker.providers.isbn.en_US.Provider object at 0x000002B7A21F44D0>\n",
      "- <faker.providers.internet.en_GB.Provider object at 0x000002B7A21F4410>\n",
      "- <faker.providers.geo.en_US.Provider object at 0x000002B7A21F4470>\n",
      "- <faker.providers.file.Provider object at 0x000002B7A21F5760>\n",
      "- <faker.providers.emoji.Provider object at 0x000002B7A217DC70>\n",
      "- <faker.providers.doi.Provider object at 0x000002B7A21F43E0>\n",
      "- <faker.providers.date_time.en_US.Provider object at 0x000002B7A21F4710>\n",
      "- <faker.providers.currency.en_US.Provider object at 0x000002B7A21F4440>\n",
      "- <faker.providers.credit_card.en_US.Provider object at 0x000002B7A21F4500>\n",
      "- <faker.providers.company.en_US.Provider object at 0x000002B7A21A2090>\n",
      "- <faker.providers.color.en_US.Provider object at 0x000002B7A21A2030>\n",
      "- <faker.providers.barcode.en_US.Provider object at 0x000002B7A2124AA0>\n",
      "- <faker.providers.bank.en_GB.Provider object at 0x000002B7A21A2060>\n",
      "- <faker.providers.automotive.en_GB.Provider object at 0x000002B7A21A20C0>\n",
      "- <faker.providers.address.en_GB.Provider object at 0x000002B7A138D4C0>\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "\n",
    "fake = Faker('en_GB')\n",
    "\n",
    "print(\"Available Faker Providers:\")\n",
    "for provider in fake.providers:\n",
    "    print(f\"- {provider}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the list corresponds to a specific provider, such as:\n",
    "\n",
    "- **User Agent Provider:** Generates browser and device identification strings.  \n",
    "- **SSN Provider:** Creates valid-format social security numbers (US-specific).  \n",
    "- **SBN Provider:** Generates 9-digit Standard Book Numbers (used in older systems prior to 1974).  \n",
    "\n",
    "In addition to these, Faker includes other commonly used providers for generating various types of data:\n",
    "\n",
    "- **Person Provider:** Generates names, birthdates, and personal details.  \n",
    "- **Address Provider:** Produces realistic street addresses and postal codes.\n",
    "- **Internet Provider:** Generates email addresses, domain names, and URLs.\n",
    "\n",
    "You can explore the full list of available providers and their methods in the official documentation, which offers detailed information and usage examples for each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Best practices for using Faker\n",
    "\n",
    "When working with Faker, keep the following best practices in mind:\n",
    "\n",
    "- Select locale-specific providers when generating data tailored to a particular region.\n",
    "- Combine different providers to generate more realistic and interconnected data.\n",
    "- Organise your fake data generation to align with the requirements of your application.\n",
    "- Explore the official documentation to learn about additional provider features and options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Building a typical dataset\n",
    "\n",
    "\n",
    "Now, let's explore how to combine multiple providers to generate rich and interconnected data for more complex structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>email</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>postcode</th>\n",
       "      <th>job</th>\n",
       "      <th>company</th>\n",
       "      <th>username</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William Jennings</td>\n",
       "      <td>35</td>\n",
       "      <td>francisdavidson@example.org</td>\n",
       "      <td>600 Charlie fort</td>\n",
       "      <td>New Joeside</td>\n",
       "      <td>DT79 0GS</td>\n",
       "      <td>Librarian, public</td>\n",
       "      <td>Bryan-Andrews</td>\n",
       "      <td>timothy16</td>\n",
       "      <td>http://butler-gough.info/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benjamin Simpson</td>\n",
       "      <td>42</td>\n",
       "      <td>fisherteresa@example.net</td>\n",
       "      <td>Studio 31 Irene forks</td>\n",
       "      <td>Jasonbury</td>\n",
       "      <td>S4 5GQ</td>\n",
       "      <td>Marine scientist</td>\n",
       "      <td>Davies Ltd</td>\n",
       "      <td>johnronald</td>\n",
       "      <td>http://www.lamb-scott.co.uk/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ricky Lloyd-Duncan</td>\n",
       "      <td>67</td>\n",
       "      <td>wilsonryan@example.com</td>\n",
       "      <td>Flat 13K Kelly parks</td>\n",
       "      <td>Youngmouth</td>\n",
       "      <td>M23 9SY</td>\n",
       "      <td>Oceanographer</td>\n",
       "      <td>Lloyd-Turner</td>\n",
       "      <td>dgreen</td>\n",
       "      <td>http://www.walsh.biz/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr Jasmine Smith</td>\n",
       "      <td>53</td>\n",
       "      <td>daviesgeoffrey@example.net</td>\n",
       "      <td>Studio 51s Steele alley</td>\n",
       "      <td>Donnaburgh</td>\n",
       "      <td>E4W 2QG</td>\n",
       "      <td>Solicitor, Scotland</td>\n",
       "      <td>Bell, Anderson and Jones</td>\n",
       "      <td>murraymohammad</td>\n",
       "      <td>http://www.shaw.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norman Sharp-Stewart</td>\n",
       "      <td>52</td>\n",
       "      <td>scottknowles@example.net</td>\n",
       "      <td>89 Arnold plains</td>\n",
       "      <td>Lake Graeme</td>\n",
       "      <td>SG57 1JJ</td>\n",
       "      <td>Bonds trader</td>\n",
       "      <td>Brown-Naylor</td>\n",
       "      <td>thomashammond</td>\n",
       "      <td>http://www.howe.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  age                        email  \\\n",
       "0      William Jennings   35  francisdavidson@example.org   \n",
       "1      Benjamin Simpson   42     fisherteresa@example.net   \n",
       "2    Ricky Lloyd-Duncan   67       wilsonryan@example.com   \n",
       "3      Dr Jasmine Smith   53   daviesgeoffrey@example.net   \n",
       "4  Norman Sharp-Stewart   52     scottknowles@example.net   \n",
       "\n",
       "                    street         city  postcode                  job  \\\n",
       "0         600 Charlie fort  New Joeside  DT79 0GS    Librarian, public   \n",
       "1    Studio 31 Irene forks    Jasonbury    S4 5GQ     Marine scientist   \n",
       "2     Flat 13K Kelly parks   Youngmouth   M23 9SY        Oceanographer   \n",
       "3  Studio 51s Steele alley   Donnaburgh   E4W 2QG  Solicitor, Scotland   \n",
       "4         89 Arnold plains  Lake Graeme  SG57 1JJ         Bonds trader   \n",
       "\n",
       "                    company        username                       website  \n",
       "0             Bryan-Andrews       timothy16     http://butler-gough.info/  \n",
       "1                Davies Ltd      johnronald  http://www.lamb-scott.co.uk/  \n",
       "2              Lloyd-Turner          dgreen         http://www.walsh.biz/  \n",
       "3  Bell, Anderson and Jones  murraymohammad          http://www.shaw.com/  \n",
       "4              Brown-Naylor   thomashammond          http://www.howe.com/  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "fake = Faker('en_GB')\n",
    "fake.seed_instance(42)\n",
    "\n",
    "n_rows = 100\n",
    "\n",
    "\n",
    "def generate_user_profile():\n",
    "    \"\"\" Function to generate a user profile \"\"\"\n",
    "    return {\n",
    "        # Personal details\n",
    "        'name': fake.name(),\n",
    "        'age': fake.random_int(min=18, max=80),\n",
    "        'email': fake.email(),\n",
    "        \n",
    "        # Location details\n",
    "        'street': fake.street_address().replace(\"\\n\", \" \"),\n",
    "        'city': fake.city(),\n",
    "        'postcode': fake.postcode(),\n",
    "        \n",
    "        # Professional information\n",
    "        'job': fake.job(),\n",
    "        'company': fake.company(),\n",
    "        \n",
    "        # Other details\n",
    "        'username': fake.user_name(),\n",
    "        'website': fake.url()\n",
    "    }\n",
    " \n",
    "profiles = [generate_user_profile() for _ in range(n_rows)]\n",
    " \n",
    "df = pd.DataFrame(profiles)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Using synthetic data with big data frameworks\n",
    "\n",
    "#### 8.1. Using synthetic data with PySpark\n",
    "\n",
    "Demonstrate how to create synthetic data in PySpark and use it within Spark DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                Name|             Address|               Email|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|    William Jennings|2 Sian streets, N...|francescaharrison...|\n",
      "|     Rosemary Wright|654 Robin track, ...|simpsongemma@exam...|\n",
      "|         Sean Norton|103 Robinson walk...|  rita19@example.net|\n",
      "|       Brenda Briggs|Studio 4, Lydia i...|iwilkins@example.org|\n",
      "|Leonard Powell-Mo...|Flat 32G, Green c...|andrea01@example.net|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"Synthetic Data Example\").getOrCreate()\n",
    "\n",
    "\n",
    "# Create synthetic data with Faker\n",
    "fake = Faker('en_GB')\n",
    "fake.seed_instance(42)\n",
    "\n",
    "n_rows = 100\n",
    "data = [(fake.name(), fake.address(), fake.email()) for _ in range(n_rows)]\n",
    "\n",
    "df_pandas = pd.DataFrame(data, columns=[\"Name\", \"Address\", \"Email\"])\n",
    "\n",
    "# Replace newline characters with commas in the 'Address' column using chaining\n",
    "df_pandas['Address'] = df_pandas['Address'].str.replace(\"\\n\", \", \")\n",
    "\n",
    "#I'm having problems when using spark.createDataFrame with virtual environment, hence, I have to create a csv file and read it\n",
    "df_pandas.to_csv('temp.csv', index=False)\n",
    "\n",
    "df_spark = spark.read.csv('temp.csv', header=True, inferSchema=True)\n",
    "\n",
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application to big data:**\n",
    "\n",
    "This example can be extended to generate large datasets (millions of records) that can be processed in parallel using PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2. Generate synthetic data with more features\n",
    "\n",
    "We will generate synthetic data with the following additional features:\n",
    "1. Mode of Transportation (Car, Public Transport, Walking, etc.)  \n",
    "2. Highest Education (High School, Bachelor's, Master's, PhD, etc.)  \n",
    "3. Marital Status (Single, Married, Divorced, Widowed)  \n",
    "4. Favorite High Street Supermarket (Tesco, Sainsbury's, Asda, etc.)  \n",
    "5. Pet Ownership (Yes, No - with type of pet if Yes)  \n",
    "\n",
    "We will also simulate some missing data in the dataset, which is commonly encountered in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>City</th>\n",
       "      <th>Email</th>\n",
       "      <th>Mode_of_Transport</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Supermarket</th>\n",
       "      <th>Pet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William Jennings</td>\n",
       "      <td>2 Sian streets, New Maryton, E3 8ZA</td>\n",
       "      <td>L8G 7YL</td>\n",
       "      <td>Port Samchester</td>\n",
       "      <td>ricky23@example.com</td>\n",
       "      <td>Car</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr Josh Pritchard</td>\n",
       "      <td>Studio 16, Lynn hill, Melissaborough, BR0X 4DJ</td>\n",
       "      <td>S4 5GQ</td>\n",
       "      <td>Rhysview</td>\n",
       "      <td>johnronald@example.net</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>High School</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Morrisons</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leigh Randall</td>\n",
       "      <td>0 Alexander circles, New Guy, W67 4FJ</td>\n",
       "      <td>NW8M 9RQ</td>\n",
       "      <td>East Natasha</td>\n",
       "      <td>dgreen@example.org</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>Morrisons</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lorraine Palmer</td>\n",
       "      <td>Studio 01, Read junctions, West Tracyburgh, AB...</td>\n",
       "      <td>MK9H 5GX</td>\n",
       "      <td>New Brandonfort</td>\n",
       "      <td>griffithslinda@example.com</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>None</td>\n",
       "      <td>Married</td>\n",
       "      <td>Waitrose</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>June Sharp</td>\n",
       "      <td>782 Hill rest, Arnoldside, SM3Y 6QT</td>\n",
       "      <td>W1D 1PA</td>\n",
       "      <td>New Gerald</td>\n",
       "      <td>hammondjulia@example.org</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Single</td>\n",
       "      <td>Asda</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                                            Address  \\\n",
       "0   William Jennings                2 Sian streets, New Maryton, E3 8ZA   \n",
       "1  Dr Josh Pritchard     Studio 16, Lynn hill, Melissaborough, BR0X 4DJ   \n",
       "2      Leigh Randall              0 Alexander circles, New Guy, W67 4FJ   \n",
       "3    Lorraine Palmer  Studio 01, Read junctions, West Tracyburgh, AB...   \n",
       "4         June Sharp                782 Hill rest, Arnoldside, SM3Y 6QT   \n",
       "\n",
       "   Postcode             City                       Email Mode_of_Transport  \\\n",
       "0   L8G 7YL  Port Samchester         ricky23@example.com               Car   \n",
       "1    S4 5GQ         Rhysview      johnronald@example.net  Public Transport   \n",
       "2  NW8M 9RQ     East Natasha          dgreen@example.org  Public Transport   \n",
       "3  MK9H 5GX  New Brandonfort  griffithslinda@example.com  Public Transport   \n",
       "4   W1D 1PA       New Gerald    hammondjulia@example.org  Public Transport   \n",
       "\n",
       "     Education Marital_Status Supermarket   Pet  \n",
       "0      Primary        Widowed       Tesco   Cat  \n",
       "1  High School        Widowed   Morrisons   Cat  \n",
       "2          PhD        Married   Morrisons  None  \n",
       "3         None        Married    Waitrose   Dog  \n",
       "4      Primary         Single        Asda   Dog  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "from faker.generator import random\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "fake = Faker('en_GB')\n",
    "fake.seed_instance(42)\n",
    "\n",
    " \n",
    "n_samples = 1000   \n",
    "\n",
    "# Create lists of categories for features not captured in the Faker library\n",
    "mode_of_transport = ['Car', 'Public Transport', 'Walking', 'Cycling', 'Taxi']\n",
    "education_levels = ['Primary', 'High School', 'Vocational', 'Bachelor\\'s', 'Master\\'s', 'PhD']\n",
    "marital_status = ['Single', 'Married', 'Divorced', 'Widowed']\n",
    "supermarkets = ['Tesco', 'Sainsbury\\'s', 'Asda', 'Morrisons', 'Waitrose']\n",
    "pets = ['Dog', 'Cat', 'None']\n",
    "\n",
    "# Generate synthetic data with the new features\n",
    "data = []\n",
    "for _ in range(n_samples):\n",
    "    name = fake.name()\n",
    "    address = fake.address()\n",
    "    postcode = fake.postcode()\n",
    "    city = fake.city()\n",
    "    email = fake.email()\n",
    "    transport = fake.random_element(mode_of_transport)\n",
    "    education = fake.random_element(education_levels)\n",
    "    marital = fake.random_element(marital_status)\n",
    "    supermarket = fake.random_element(supermarkets)\n",
    "    pet = fake.random_element(pets)\n",
    "    \n",
    "    # Simulating missing data by randomly omitting some features\n",
    "    if random.random() < 0.1:  # 10% chance to have missing data for 'Mode of Transport'\n",
    "        transport = None\n",
    "    if random.random() < 0.1:  # 10% chance to have missing data for 'Education'\n",
    "        education = None\n",
    "    if random.random() < 0.1:  # 10% chance to have missing data for 'Marital Status'\n",
    "        marital = None\n",
    "    if random.random() < 0.1:  # 10% chance to have missing data for 'Supermarket'\n",
    "        supermarket = None\n",
    "    if random.random() < 0.1:  # 10% chance to have missing data for 'Pet'\n",
    "        pet = None\n",
    "\n",
    "    data.append([name, address, postcode, city, email, transport, education, marital, supermarket, pet])\n",
    "\n",
    "\n",
    "columns = ['Name', 'Address', 'Postcode', 'City', 'Email', 'Mode_of_Transport', 'Education', 'Marital_Status', 'Supermarket', 'Pet']\n",
    "synthetic_df = pd.DataFrame(data, columns=columns)\n",
    "synthetic_df['Address'] = synthetic_df['Address'].str.replace(\"\\n\", \", \")\n",
    "\n",
    "\n",
    "synthetic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integrate with PySpark for big data workflow**\n",
    "\n",
    "Now that we have a robust dataset with additional features and some missing data, let's see how to integrate this with PySpark, which is commonly used in big data workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------+---------------+--------------------+-----------------+-----------+--------------+-----------+----+\n",
      "|             Name|             Address|Postcode|           City|               Email|Mode_of_Transport|  Education|Marital_Status|Supermarket| Pet|\n",
      "+-----------------+--------------------+--------+---------------+--------------------+-----------------+-----------+--------------+-----------+----+\n",
      "| William Jennings|2 Sian streets, N...| L8G 7YL|Port Samchester| ricky23@example.com|              Car|    Primary|       Widowed|      Tesco| Cat|\n",
      "|Dr Josh Pritchard|Studio 16, Lynn h...|  S4 5GQ|       Rhysview|johnronald@exampl...| Public Transport|High School|       Widowed|  Morrisons| Cat|\n",
      "|    Leigh Randall|0 Alexander circl...|NW8M 9RQ|   East Natasha|  dgreen@example.org| Public Transport|        PhD|       Married|  Morrisons|None|\n",
      "|  Lorraine Palmer|Studio 01, Read j...|MK9H 5GX|New Brandonfort|griffithslinda@ex...| Public Transport|       NULL|       Married|   Waitrose| Dog|\n",
      "|       June Sharp|782 Hill rest, Ar...| W1D 1PA|     New Gerald|hammondjulia@exam...| Public Transport|    Primary|        Single|       Asda| Dog|\n",
      "+-----------------+--------------------+--------+---------------+--------------------+-----------------+-----------+--------------+-----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"SyntheticDataForBigData\").getOrCreate()\n",
    "\n",
    "# Convert the synthetic DataFrame to a Spark DataFrame\n",
    "# Currently, using the createDataFrame on a virtual environment raising error. So, I will convert to a csv file and read the file using spark\n",
    "# spark_df = spark.createDataFrame(synthetic_df)\n",
    "synthetic_df.to_csv('temp.csv', index=False)\n",
    "\n",
    "spark_df = spark.read.csv('temp.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Show the Spark DataFrame\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Generating synthetic data is a crucial tool for testing algorithms, saving resources, and maintaining privacy. Faker offers various providers to generate synthetic data on Python and big data frameworks like `PySpark`  can help handle large datasets efficiently.\n",
    "\n",
    "\n",
    "### References and Further Reading\n",
    "* Faker Documentation (Python)\n",
    "* PySpark Documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
