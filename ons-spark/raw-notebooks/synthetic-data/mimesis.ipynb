{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mimesis: Synthetic Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction to Mimesis\n",
    "\n",
    "Synthetic data is artificially generated information that mimics real-world data. It is commonly used for testing, model validation, training machine learning models, and protecting sensitive information, as it allows users to work with realistic datasets without exposing actual personal or confidential data.\n",
    "\n",
    "Mimesis is a Python library used to generate fake, random, or synthetic data for various purposes as listed above. It allows users to generate a wide range of data types, including personal information, addresses, financial data, dates, and more. It is similar to [`Faker`](../ancillary-topics/faker.html), an alternative Python package used for generating synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Install and initialise Mimesis\n",
    "To start, we will need the `mimesis` library to generate the dummy data. Later on, we will use PySpark for working with Spark DataFrames in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Mimesis and check the installed version\n",
    "%pip install mimesis\n",
    "import mimesis\n",
    "print(mimesis.__version__)\n",
    "from mimesis import Generic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up a global random seed**\n",
    "\n",
    "You can set a global seed for all data providers and use it without explicitly passing it to each provider. Setting this seed allows us to generate the exact same synthetic data as will be shown in our examples. This is especially helpful when we are debugging or creating tests that require consistent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimesis import random\n",
    "\n",
    "random.global_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How Mimesis works\n",
    "\n",
    "\n",
    "Mimesis, inspired by the ancient Greek concept of `\"mimesis\"` (which means to imitate or replicate), is designed to create realistic synthetic data rather than just random values. Its goal is to generate contextually appropriate data that mimics real-world information. This is achieved through a structured provider system and built-in support for different locales, ensuring that the generated data is both varied and meaningful.\n",
    "\n",
    "Let us walk through how to generate basic synthetic data using a seeded instance of Mimesis. We will then generate and display basic personal and financial information. Note that the `Loacale` and `Provider` which are integral part how mimesis work are introduced here but will  explained in the next sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How Mimesis works\n",
    "\n",
    "Mimesis is a Python library for generating realistic synthetic data that mimics real-world information. It uses a system of providers and locale support to create varied, contextually appropriate data for testing and development.\n",
    "\n",
    "\n",
    "**What are providers and locales?**   \n",
    "A `provider` in Mimesis is a class that generates a specific type of data, such as names, addresses, or dates. A `locale` specifies the regional or language settings that influence the format and style of the generated data (for example, UK vs. US address formats).\n",
    "\n",
    "\n",
    "\n",
    "Below, we walk through how to generate basic synthetic data using a seeded instance of Mimesis. This example demonstrates how to create and display basic personal and financial information. The concepts of *Provider* and *Locale* are introduced here and will be explained in more detail in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Anthony Reilly\n",
      "Email: holds1871@live.com\n",
      "Address: 1310 Blaney Avenue\n",
      "Job: Choreographer\n",
      "Company: Centrica\n"
     ]
    }
   ],
   "source": [
    "# The following example demonstrates how to generate basic personal and financial data using the UK locale (en_GB) and a fixed seed for reproducibility.\n",
    "from mimesis import Person, Address, Finance\n",
    "from mimesis.locales import Locale\n",
    "\n",
    "person = Person(locale=Locale.EN_GB, seed=42)\n",
    "address = Address(locale=Locale.EN_GB, seed=42)\n",
    "finance = Finance(locale=Locale.EN_GB, seed=42)\n",
    "\n",
    "print(\"Name:\", person.full_name())\n",
    "print(\"Email:\", person.email())\n",
    "print(\"Address:\", address.address())\n",
    "print(\"Job:\", person.occupation())\n",
    "print(\"Company:\", finance.company())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs produced by Mimesis appear realistic and reflect real-world naming and formatting conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Mimesis provider system\n",
    "\n",
    "One of the key strengths of Mimesis is its well-structured provider system. At its core is the **Generic provider**, which acts as a central hub, giving you access to all the specialised data generators available in Mimesis. Let us begin by exploring the range of providers that you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providers available through Generic:\n",
      "address\n",
      "binaryfile\n",
      "choice\n",
      "code\n",
      "cryptographic\n",
      "datetime\n",
      "development\n",
      "file\n",
      "finance\n",
      "food\n",
      "hardware\n",
      "internet\n",
      "numeric\n",
      "path\n",
      "payment\n",
      "person\n",
      "science\n",
      "text\n",
      "transport\n"
     ]
    }
   ],
   "source": [
    "from mimesis import Generic\n",
    "from mimesis.locales import Locale\n",
    "\n",
    "generic = Generic(locale=Locale.EN_GB, seed=42)\n",
    "\n",
    "print(\"Providers available through Generic:\")\n",
    "for attribute in dir(generic):\n",
    "    if not attribute.startswith('_'):  # Here, we skip internal attributes\n",
    "        print(attribute)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Locale support for international applications\n",
    "\n",
    "A key feature of Mimesis is its ability to handle different locales. When generating test data for global applications, it is essential that the data reflects not only different languages but also the cultural and formatting norms of various regions. Mimesis achieves this through its robust locale system.\n",
    "\n",
    "Now, let us see how Mimesis adjusts its data generation based on different locale settings. For a full list of supported locales, please refer to the [official Mimesis documentation](https://mimesis.name/v12.1.1/locales.html).\n",
    "\n",
    "\n",
    "To demonstrate how locales influence data generation, let us create a simple example that generates person and address data for various regions. We will use a fixed seed to ensure consistent results. Note that Mimesis also supports language-specific data generation; for example, outputs for AR-EG and JA locales are written in the respective languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EN-GB Examples:\n",
      "Full Name: Anthony Reilly\n",
      "Phone: 055 2768 0402\n",
      "Email: appeared1901@example.org\n",
      "Job: Veterinary Surgeon\n",
      "\n",
      "EN Examples:\n",
      "Full Name: Anthony Reilly\n",
      "Phone: +1-309-276-8040\n",
      "Email: guitars1813@yahoo.com\n",
      "Job: Yacht Master\n",
      "\n",
      "JA Examples:\n",
      "Full Name: 石松 田場\n",
      "Phone: +81 117 5500 2657\n",
      "Email: readers2029@example.org\n",
      "Job: レコーディング・エンジニア\n",
      "\n",
      "FR Examples:\n",
      "Full Name: Alexy Rigal\n",
      "Phone: 0427680402\n",
      "Email: appeared1901@example.org\n",
      "Job: Responsable de la promotion des ventes\n",
      "\n",
      "AR-EG Examples:\n",
      "Full Name: أيمن عبد الماجد باشا\n",
      "Phone: 0611755002\n",
      "Email: water2079@duck.com\n",
      "Job: مهندس تنظيف\n"
     ]
    }
   ],
   "source": [
    "from mimesis import Person\n",
    "from mimesis.locales import Locale\n",
    "\n",
    "examples = {}\n",
    "\n",
    "# List of diverse locales to generate data for\n",
    "locales = [Locale.EN_GB, Locale.EN, Locale.JA, Locale.FR, Locale.AR_EG]\n",
    "\n",
    " \n",
    "for locale in locales:\n",
    "    person = Person(locale=locale, seed=42)\n",
    "    examples[locale] = {\n",
    "        \"Full Name\": person.full_name(),\n",
    "        \"Phone\": person.telephone(),\n",
    "        \"Email\": person.email(),\n",
    "        \"Job\": person.occupation()\n",
    "    }\n",
    "\n",
    "for locale, data in examples.items():\n",
    "    print(f\"\\n{locale.value.upper()} Examples:\")\n",
    "    for key, value in data.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Common Mimesis providers\n",
    "\n",
    "Mimesis offers a wide range of providers for generating different types of data. Some of the most commonly used providers include:\n",
    "\n",
    "- **Person**: Generates names, genders, emails, phone numbers, and other personal information.\n",
    "- **Address**: Produces realistic street addresses, cities, postcodes, and regions.\n",
    "- **Finance**: Generates financial data such as bank names, company names, currency codes, and prices.\n",
    "- **Datetime**: Produces random dates, times, and timestamps.\n",
    "- **Text**: Generates random sentences, words, and quotes.\n",
    "\n",
    "There are many additional providers available in Mimesis for generating data such as transport, science, food, and more. For a full list and detailed breakdowns, please refer to the [official Mimesis documentation](https://mimesis.name/v12.1.1/providers.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class: mimesis.Text**\n",
    "\n",
    "The `mimesis.Text` class generates random text data, such as sentences, words, quotes, levels, answers, and so on.\n",
    "\n",
    "**Key methods in `mimesis.Text`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. Random Sentence\n",
      "Random Sentence: Messages can be sent to and received from ports, but these messages must obey the so-called \"port protocol.\"\n",
      "\n",
      "### 2. Random Word\n",
      "Random Word: checkout\n",
      "\n",
      "### 3. Random Text\n",
      "Random Text (multiple sentences):\n",
      "Haskell features a type system with type inference and lazy evaluation. They are written as strings of consecutive alphanumeric characters, the first character being lowercase. She spent her earliest years reading classic literature, and writing poetry. Make me a sandwich. He looked inquisitively at his keyboard and wrote another sentence.\n",
      "\n",
      "### 4. Random Quote\n",
      "Random Quote: Those who refuse to learn from history are condemned to repeat it.\n",
      "\n",
      "### 5. An Answer\n",
      "Random Answer:\n",
      "Yes\n",
      "\n",
      "### 6. Random Level\n",
      "Random Level:\n",
      "high\n",
      "\n",
      "### 6. Random Paragraph\n",
      "Random Long Paragraph:\n",
      "Do you come here often? I don't even care. Haskell features a type system with type inference and lazy evaluation. Haskell is a standardized, general-purpose purely functional programming language, with non-strict semantics and strong static typing. Tuples are containers for a fixed number of Erlang data types. Ports are used to communicate with the external world. The syntax {D1,D2,...,Dn} denotes a tuple whose arguments are D1, D2, ... Dn. He looked inquisitively at his keyboard and wrote another sentence. Messages can be sent to and received from ports, but these messages must obey the so-called \"port protocol.\" Its main implementation is the Glasgow Haskell Compiler. Messages can be sent to and received from ports, but these messages must obey the so-called \"port protocol.\" Messages can be sent to and received from ports, but these messages must obey the so-called \"port protocol.\" Messages can be sent to and received from ports, but these messages must obey the so-called \"port protocol.\" Tuples are containers for a fixed number of Erlang data types. I don't even care. Erlang is a general-purpose, concurrent, functional programming language. Ports are used to communicate with the external world. Type classes first appeared in the Haskell programming language. Initially composing light-hearted and irreverent works, he also wrote serious, sombre and religious pieces beginning in the 1930s. The arguments can be primitive data types or compound data types. In 1989 the building was heavily damaged by fire, but it has since been restored. The Galactic Empire is nearing completion of the Death Star, a space station with the power to destroy entire planets. Its main implementation is the Glasgow Haskell Compiler. Erlang is a general-purpose, concurrent, functional programming language. I don't even care. Haskell features a type system with type inference and lazy evaluation. They are written as strings of consecutive alphanumeric characters, the first character being lowercase. Initially composing light-hearted and irreverent works, he also wrote serious, sombre and religious pieces beginning in the 1930s. Haskell is a standardized, general-purpose purely functional programming language, with non-strict semantics and strong static typing. In 1989 the building was heavily damaged by fire, but it has since been restored. Do you come here often? Tuples are containers for a fixed number of Erlang data types. Ports are used to communicate with the external world. In 1989 the building was heavily damaged by fire, but it has since been restored. Atoms can contain any character if they are enclosed within single quotes and an escape convention exists which allows any character to be used within an atom. Haskell is a standardized, general-purpose purely functional programming language, with non-strict semantics and strong static typing. The syntax {D1,D2,...,Dn} denotes a tuple whose arguments are D1, D2, ... Dn. The Galactic Empire is nearing completion of the Death Star, a space station with the power to destroy entire planets. Type classes first appeared in the Haskell programming language. Its main implementation is the Glasgow Haskell Compiler. Its main implementation is the Glasgow Haskell Compiler. Atoms can contain any character if they are enclosed within single quotes and an escape convention exists which allows any character to be used within an atom. Atoms are used within a program to denote distinguished values. He looked inquisitively at his keyboard and wrote another sentence. The arguments can be primitive data types or compound data types. They are written as strings of consecutive alphanumeric characters, the first character being lowercase. Its main implementation is the Glasgow Haskell Compiler. Initially composing light-hearted and irreverent works, he also wrote serious, sombre and religious pieces beginning in the 1930s. The syntax {D1,D2,...,Dn} denotes a tuple whose arguments are D1, D2, ... Dn. Erlang is known for its designs that are well suited for systems.\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary classes from Mimesis\n",
    "from mimesis import Generic\n",
    "from mimesis.locales import Locale\n",
    "\n",
    "# Initialize the Generic provider with UK locale and a fixed seed for reproducibility\n",
    "generic = Generic(locale=Locale.EN_GB, seed='OK')\n",
    "\n",
    "# --- Section 1: Random Sentence ---\n",
    "print(\"### 1. Random Sentence\")\n",
    "\n",
    "# Generate a random sentence\n",
    "random_sentence = generic.text.sentence()\n",
    "print(f\"Random Sentence: {random_sentence}\")\n",
    "\n",
    "# --- Section 2: Random Word ---\n",
    "print(\"\\n### 2. Random Word\")\n",
    "\n",
    "# Generate a random word\n",
    "random_word = generic.text.word()\n",
    "print(f\"Random Word: {random_word}\")\n",
    "\n",
    "# --- Section 3: Random Text (Multiple Sentences) ---\n",
    "print(\"\\n### 3. Random Text\")\n",
    "\n",
    "# Generate random text consisting of multiple sentences\n",
    "random_text = generic.text.text()\n",
    "print(f\"Random Text (multiple sentences):\\n{random_text}\")\n",
    "\n",
    "# --- Section 4: Random Quote ---\n",
    "print(\"\\n### 4. Random Quote\")\n",
    "\n",
    "# Generate a random quote (could be used for example datasets in surveys or quotes sections)\n",
    "random_quote = generic.text.quote()\n",
    "print(f\"Random Quote: {random_quote}\")\n",
    "\n",
    "# --- Section 5: Random Answer  ---\n",
    "print(\"\\n### 5. An Answer\")\n",
    "\n",
    "# Generates a random answer in the current language\n",
    "random_answer = generic.text.answer()\n",
    "print(f\"Random Answer:\\n{random_answer}\")\n",
    "\n",
    "# --- Section 6: Random Level ---\n",
    "print(\"\\n### 6. Random Level\")\n",
    "\n",
    "# Generates a word that indicates a level of something\n",
    "random_level = generic.text.level()\n",
    "print(f\"Random Level:\\n{random_level}\")\n",
    "\n",
    "# --- Section 7: Random Long Paragraphs ---\n",
    "print(\"\\n### 6. Random Paragraph\")\n",
    "\n",
    "# Generates a long paragraph from sentences. Specify the length of the list of sentences\n",
    "random_sentences = [generic.text.text() for _ in range(10)]\n",
    "long_paragraph = \" \".join(random_sentences)\n",
    "print(f\"Random Long Paragraph:\\n{long_paragraph}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Generating fake datasets wit Spark\n",
    "\n",
    "In this section, we will use PySpark along with Mimesis to generate synthetic person, finance, and population data, utilising Spark DataFrames instead of Pandas DataFrames. However, you can use Pandas DataFrames if that better suits your needs. PySpark allows you to scale the data generation process and handle larger datasets in a distributed manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Generating fake person data\n",
    "\n",
    "Here, the code uses the Mimesis library to generate synthetic personal data, such as names, genders, ages, emails, phone numbers, nationalities, and occupations. By initialising the Person object with the English (GB) locale with a seed for reproducibility, the code generates `n` number of rows (`n_rows`) of data, with each row containing randomly generated values for various personal attributes. The generated data is then passed on to a Spark dataframe for maniplation.\n",
    "\n",
    "If you encounter problem creating a Spark DataFrame using `spark.createDataFrame()` while runing in a virtual enviroment (venv). The code below will handle the issue.\n",
    "\n",
    "* If you're not in a virtual environment, the code directly uses `spark.createDataFrame()` to create the Spark DataFrame.  \n",
    "* If you're in a virtual environment, the data is first generated, then saved to a CSV file, and finally read into a Spark DataFrame using `spark.read.csv()`. \n",
    "\n",
    "To determine if you're in a virtual environment, the code checks whether the `VIRTUAL_ENV` environment variable is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from mimesis import Person, Locale\n",
    "from mimesis import Generic\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"MimesisDataGeneration\").getOrCreate()\n",
    "\n",
    "# Check if in virtual environment\n",
    "is_in_venv = os.getenv('VIRTUAL_ENV') is not None\n",
    "\n",
    "person = Person(locale=Locale.EN_GB, seed=42)\n",
    "\n",
    "n_rows = 10\n",
    "personal_data = {\n",
    "    \"First Name\": [person.first_name() for _ in range(n_rows)],\n",
    "    \"Last Name\": [person.last_name() for _ in range(n_rows)],\n",
    "    \"Full Name\": [person.full_name() for _ in range(n_rows)],\n",
    "    \"Gender\": [person.gender() for _ in range(n_rows)],\n",
    "    \"Age\": [person.random.randint(16, 88) for _ in range(n_rows)],\n",
    "    \"Email\": [person.email() for _ in range(n_rows)],\n",
    "    \"Phone Number\": [person.phone_number() for _ in range(n_rows)],\n",
    "    \"Nationality\": [person.nationality() for _ in range(n_rows)],\n",
    "    \"Occupation\": [person.occupation() for _ in range(n_rows)],\n",
    "}\n",
    "\n",
    "if not is_in_venv:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: spark.createDataFrame\")\n",
    "    personal_df = spark.createDataFrame(\n",
    "        [(v) for v in zip(*personal_data.values())],  \n",
    "        schema=list(personal_data.keys())  \n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: Pandas DataFrame -> CSV -> Spark DataFrame\")\n",
    "    personal_df_pd = pd.DataFrame(personal_data)\n",
    "\n",
    "    file_path = \"personal_data.csv\"\n",
    "    personal_df_pd.to_csv(file_path, index=False)\n",
    "    personal_df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "     \n",
    "personal_df.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you encounter an error when creating a Spark DataFrame in a virtual environment, use the workaround provided (generate data, save as CSV, and read with `spark.read.csv()`). This is the same issue and solution as described in the Faker notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Generating fake finance data\n",
    "\n",
    "In this section, the code generates synthetic finance-related data using the Mimesis library's `Finance` class. The data includes bank names, company names and types, cryptocurrency data (ISO codes and symbols), currency data, stock exchange names, stock tickers, and random prices. This is done for n_rows rows, with the data organised in a Spark DataFrame. The locale is set to English (GB) to generate finance-related data that follows British conventions, with a seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_in_venv: True | Spark DataFrame to be created from: Pandas DataFrame -> CSV -> Spark DataFrame\n",
      "+--------------------+--------------+--------------------+-----------------------+---------------------+-----------------+---------------+------------+------------+-------------------+--------------------+------------+\n",
      "|           Bank Name|  Company Name|        Company Type|Cryptocurrency ISO Code|Cryptocurrency Symbol|Currency ISO Code|Currency Symbol|Random Price|Price in BTC|Stock Exchange Name|          Stock Name|Stock Ticker|\n",
      "+--------------------+--------------+--------------------+-----------------------+---------------------+-----------------+---------------+------------+------------+-------------------+--------------------+------------+\n",
      "|National Counties...|      Glencore|Private company l...|                    VTC|                    Ξ|              GBP|              £|     1284.03|    0.291637|           Euronext|            PTC Inc.|         VMM|\n",
      "|The Royal Bank of...|Derwent London|Limited Liability...|                    XBC|                    Ξ|              GBP|              £|      817.86|   0.0897551|           Euronext|Boston Omaha Corp...|         TEN|\n",
      "|Royal Bank of Sco...|       Hunting|        Incorporated|                    DOT|                    Ξ|              GBP|              £|      719.96|   1.6363438|               HKEX|World Acceptance ...|       PACQU|\n",
      "|Paragon Banking G...|           Dcc|         Corporation|                    BTC|                    Ξ|              GBP|              £|      683.87|   0.3993704|                SSE| Waitr Holdings Inc.|       OFSSZ|\n",
      "|     Triodos Bank UK|        Booker|         Corporation|                    XRP|                    Ξ|              GBP|              £|      568.18|   0.7476416|             NASDAQ|Eaton Vance Calif...|        SRAX|\n",
      "| The Bank of Ireland|      Bgeo Grp|Private company l...|                   WBTC|                    Ł|              GBP|              £|     1005.14|   1.5154676|                SSE|      InspireMD Inc.|        PTLA|\n",
      "| OneSavings Bank plc|        Dunelm|        Incorporated|                    BNB|                    Ξ|              GBP|              £|      915.93|   1.7055283|                SSE|PennantPark Float...|       RUSHA|\n",
      "|          Tesco Bank|   Jpmor.amer.|Limited Liability...|                   DASH|                    Ł|              GBP|              £|     1037.04|   0.2247435|           Euronext|Piedmont Office R...|         NGS|\n",
      "|Penrith Building ...|   Wetherspoon| Limited Partnership|                    XBT|                    Ł|              GBP|              £|      591.95|    0.109076|             NASDAQ|VirnetX Holding Corp|        ZAGG|\n",
      "|Felixstowe & Walt...|    Tullow Oil|Limited Liability...|                    IOT|                    ₿|              GBP|              £|       721.2|   1.8978818|               NYSE|International Gam...|        PETZ|\n",
      "+--------------------+--------------+--------------------+-----------------------+---------------------+-----------------+---------------+------------+------------+-------------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mimesis import Finance, Locale\n",
    "\n",
    "is_in_venv = os.getenv('VIRTUAL_ENV') is not None\n",
    "\n",
    "finance = Finance(locale=Locale.EN_GB, seed=42)\n",
    "\n",
    "n_rows = 1000\n",
    "\n",
    "financial_data = {\n",
    "    \"Bank Name\": [finance.bank() for _ in range(n_rows)],\n",
    "    \"Company Name\": [finance.company() for _ in range(n_rows)],\n",
    "    \"Company Type\": [finance.company_type() for _ in range(n_rows)],\n",
    "    \"Cryptocurrency ISO Code\": [finance.cryptocurrency_iso_code() for _ in range(n_rows)],\n",
    "    \"Cryptocurrency Symbol\": [finance.cryptocurrency_symbol() for _ in range(n_rows)],\n",
    "    \"Currency ISO Code\": [finance.currency_iso_code() for _ in range(n_rows)],\n",
    "    \"Currency Symbol\": [finance.currency_symbol() for _ in range(n_rows)],\n",
    "    \"Random Price\": [finance.price() for _ in range(n_rows)],\n",
    "    \"Price in BTC\": [finance.price_in_btc() for _ in range(n_rows)],\n",
    "    \"Stock Exchange Name\": [finance.stock_exchange() for _ in range(n_rows)],\n",
    "    \"Stock Name\": [finance.stock_name() for _ in range(n_rows)],\n",
    "    \"Stock Ticker\": [finance.stock_ticker() for _ in range(n_rows)]\n",
    "}\n",
    "\n",
    "if not is_in_venv:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: spark.createDataFrame\")\n",
    "    finance_df = spark.createDataFrame(\n",
    "        [(v) for v in zip(*financial_data.values())],  \n",
    "        schema=list(financial_data.keys())  \n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: Pandas DataFrame -> CSV -> Spark DataFrame\")\n",
    "    finance_df_pd = pd.DataFrame(financial_data)\n",
    "    finance_df_pd.to_csv(\"finance_data.csv\", index=False)\n",
    "    finance_df = spark.read.csv(\"finance_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "finance_df.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Generating fake population data\n",
    "\n",
    "We use Mimesis's `Generic`, `Address`, and `Person` providers to generate fake population data (e.g., address, postcode, names, etc.).  \n",
    "We define the function `generate_elector_data()` to create fake data for several fields like local authority, postcode, DOB, etc.  \n",
    "It also include special handling to create continuity in address lines for a subset of rows and adds extra columns for address continuity.  \n",
    "\n",
    "* **Schema Consistency**: We define the schema upfront with StructType\n",
    "* **Data Generation**: The `generate_elector_data()` function is used to generate the data\n",
    "* **Address Continuity**: For a subset of rows, the code ensures continuity in address lines to simulate real-world scenarios where multiple entries might share the same address.\n",
    "* **Handling Virtual Environment**: The function `in_virtualenv()` checks if the `VIRTUAL_ENV` environment variable is set\n",
    "    * Without Virtual Environment: We directly use PySpark’s `spark.createDataFrame()` to generate the DataFrame.\n",
    "    * With Virtual Environment: We generate the data using mimesis, convert it to a pandas DataFrame, save it as a CSV, and then read it using `spark.read.csv()` with the predefined schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_in_venv: True | Spark DataFrame to be created from: Pandas DataFrame -> CSV -> Spark DataFrame\n",
      "+---+--------------------+-------------------+--------------------+--------+--------------+--------------+--------------+--------------+--------------------+--------------+--------------+--------------+--------------+----------+-----------+----------+------+----------+-----------+\n",
      "| ID|         SOURCE_FILE|         TIME_STAMP|     Local_Authority|Postcode|Address_Line_1|Address_Line_2|Address_Line_3|Address_Line_4|      Address_Line_5|Address_Line_6|Address_Line_7|Address_Line_8|Address_Line_9| Last_Name|Middlenames|First_Name| Title|       DOB|       guid|\n",
      "+---+--------------------+-------------------+--------------------+--------+--------------+--------------+--------------+--------------+--------------------+--------------+--------------+--------------+--------------+----------+-----------+----------+------+----------+-----------+\n",
      "|  1| appeared_fetish.csv|2025-04-04 13:43:51|  County Londonderry|AH2T 6XC|           184|        Egeria|      Barrhead|        Barnet|               Benin|          NULL|          NULL|          NULL|          NULL|   Mullins|    Anthony|     Kaley|   Mr.|08-07-1994|\"(\"\"@iNcuV\"|\n",
      "|  2|security_councils...|2025-04-04 13:43:51|            Grampian|GP5S 7KL|            97|    Craigatoke|     Aldeburgh|Ellesmere Port|            Portugal|          NULL|          NULL|          NULL|          NULL|      Hunt|      Aleen|   Neville|  Miss|10-09-1935|   o`Fij<4.|\n",
      "|  3|intended_elementa...|2025-04-04 13:43:51|     South Glamorgan|IE9I 0CW|           137|      Keadybeg|     Liverpool|   Berkhamsted|          San Marino|          NULL|          NULL|          NULL|          NULL| Singleton|     Harold|    Benito|   Sir|15-03-1956|   }=>JQ;pH|\n",
      "|  4|secretary_instant...|2025-04-04 13:43:51|             Suffolk|NZ3O 8QW|            36|        Hornby|     Guildford| Brightlingsea|               Aruba|          NULL|          NULL|          NULL|          NULL|    Harmon|       Jaye|   Britany|   Mr.|18-12-1956|   .Lg\\1&tU|\n",
      "|  5|photographs_toys.csv|2025-04-04 13:43:51|               Gwent|UZ8W 3LV|            65|        Canary|     Rostrevor|     Prestatyn|    Congo - Kinshasa|          NULL|          NULL|          NULL|          NULL|     Lyons|    Roberto|    Melvin|   Mr.|22-01-1995|   Viek6-Nf|\n",
      "|  6| lightning_fever.csv|2025-04-04 13:43:51|Highlands and Isl...|SR0Q 5GM|            40|    Corraquill|          Hove|   Northampton|              Sweden|          NULL|          NULL|          NULL|          NULL|     Pratt|      Terry|   Margart|   Sir|18-03-1972|   OQ`?yVq\\|\n",
      "|  7|   bucks_couples.csv|2025-04-04 13:43:51|           Cleveland|FA3G 2YW|            33|         Dalys|      Hinckley|     Lichfield|             Hungary|          NULL|          NULL|          NULL|          NULL|Williamson|     Kareem|   Angeles|   Sir|06-09-1985|   ?;Cf?`iT|\n",
      "|  8|     buried_gray.csv|2025-04-04 13:43:51|             Suffolk|DD7O 7LP|            18|    Drumagrove|          Hove|        Didcot|     Macau SAR China|          NULL|          NULL|          NULL|          NULL|  Espinoza|   Jacqulyn|       Jon|  Miss|03-06-1929|   PWlvF3vu|\n",
      "|  9|  recruiting_she.csv|2025-04-04 13:43:51|      West Glamorgan|CB1Q 7KB|           187|    Drumleacht|       Wigtown|         Largs|      Western Sahara|          NULL|          NULL|          NULL|          NULL|     Leach|      Jaime|    Jamika|Master|21-11-1931|   ^1S,.rjO|\n",
      "| 10|venice_beginning.csv|2025-04-04 13:43:51|        Bedfordshire|RC8T 7IH|           167|       Calmore|Wellingborough|   Abertillery|        Vatican City|          NULL|          NULL|          NULL|          NULL|      Neal|      Brain| Margareta|   Mr.|03-01-1994|   sYnrR?h.|\n",
      "| 11|vitamins_dispute.csv|2025-04-04 13:43:51|       Hertfordshire|ZT5C 6VN|            49|   Castlekeele|       Dursley|       Rugeley|            Slovenia|          NULL|          NULL|          NULL|          NULL|   Watkins|      Earle|    Sunday|   Ms.|02-04-1962|   >[paK^,A|\n",
      "| 12|witch_australian.csv|2025-04-04 13:43:51|Dumfries and Gall...|OU5A 3AY|           159|    Cunningham|    Killyleagh|        Bootle|       Côte d’Ivoire|          NULL|          NULL|          NULL|          NULL| Mcfarland|   Jonathon|     Berry|   Ms.|22-07-1935|   fV=gg>L_|\n",
      "| 13|        coat_tub.csv|2025-04-04 13:43:51|       County Antrim|CM0T 7DM|            55|    Hannahglen|    Failsworth|     Llandeilo|            Maldives|          NULL|          NULL|          NULL|          NULL|  Mcintosh|      Keila|    Jordan|   Sir|05-05-1989|\"L\"\"CD)gR~\"|\n",
      "| 14|combining_install...|2025-04-04 13:43:51|     South Glamorgan|ZY7R 7KR|            30|      Drumearn|    Trowbridge|       Warwick|British Indian Oc...|          NULL|          NULL|          NULL|          NULL|     Weeks|     Caroll|   Luciano|   Ms.|18-12-1938|   PZC}.X!0|\n",
      "| 15|accreditation_cup...|2025-04-04 13:43:51|           Hampshire|FI5F 2BQ|           164|     Clonallan|   Bridlington|    Barnstaple|          Tajikistan|          NULL|          NULL|          NULL|          NULL| Cervantes|      Lanie|     Lance|Master|24-03-1958|   7yT\\<iNA|\n",
      "| 16|authentic_former.csv|2025-04-04 13:43:51|          Merseyside|BG6F 1YO|           175|      Galbally|       Kinross|        Witney|   St. Kitts & Nevis|          NULL|          NULL|          NULL|          NULL|     Huber|      Alica|     Byron|Master|04-11-1956|   dIZOdI^||\n",
      "| 17|completely_attrib...|2025-04-04 13:43:51|          Shropshire|EC4L 4SR|           121|      Kinnegar|    Chelmsford|     Bracknell|               India|          NULL|          NULL|          NULL|          NULL|     Greer|       Enda|    Duncan|   Sir|27-04-1953|   c(F^.>/z|\n",
      "| 18|trips_appointment...|2025-04-04 13:43:51|       Mid Glamorgan|UC1N 1EM|            30|      Bankhall|       Verwood|     Chatteris|    Ascension Island|          NULL|          NULL|          NULL|          NULL|   Walters|  Marquetta|    Jessia|   Mr.|19-03-1958|  !LAg+HV\"\"|\n",
      "| 19| tunisia_outputs.csv|2025-04-04 13:43:51|        Bedfordshire|ZY8E 4FK|           111|   Ballynaloan|      Eyemouth|       Salford|         Afghanistan|          NULL|          NULL|          NULL|          NULL|      Wood|    Aundrea|    Oliver|  Miss|11-11-1933|   P}k[reOW|\n",
      "| 20| wiring_properly.csv|2025-04-04 13:43:51|         Oxfordshire|GU4K 9ZO|           141| Lisnascreghog|    Birmingham|    Eastbourne|    Christmas Island|          NULL|          NULL|          NULL|          NULL|     Moore|      Detra|    Thresa| Madam|10-05-1925|   E$0s!J)q|\n",
      "+---+--------------------+-------------------+--------------------+--------+--------------+--------------+--------------+--------------+--------------------+--------------+--------------+--------------+--------------+----------+-----------+----------+------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mimesis import Generic\n",
    "from mimesis.locales import Locale\n",
    "import datetime\n",
    "import os\n",
    "from mimesis.enums import TitleType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MimesisData\").getOrCreate()\n",
    "\n",
    "def in_virtualenv():\n",
    "    return os.environ.get('VIRTUAL_ENV') is not None\n",
    "\n",
    "# Initialise mimesis Generic provider with a seed for reproducibility\n",
    "data_generator = Generic(locale=Locale.EN_GB, seed=42)\n",
    "\n",
    "# Providers\n",
    "address_provider = data_generator.address\n",
    "person_provider = data_generator.person\n",
    "\n",
    "# Define the schema upfront  \n",
    "schema = StructType([\n",
    "    StructField(\"ID\", StringType(), True),\n",
    "    StructField(\"SOURCE_FILE\", StringType(), True),\n",
    "    StructField(\"TIME_STAMP\", StringType(), True),\n",
    "    StructField(\"Local_Authority\", StringType(), True),\n",
    "    StructField(\"Postcode\", StringType(), True),\n",
    "    StructField(\"Address_Line_1\", StringType(), True),\n",
    "    StructField(\"Address_Line_2\", StringType(), True),\n",
    "    StructField(\"Address_Line_3\", StringType(), True),\n",
    "    StructField(\"Address_Line_4\", StringType(), True),\n",
    "    StructField(\"Address_Line_5\", StringType(), True),\n",
    "    StructField(\"Address_Line_6\", StringType(), True),\n",
    "    StructField(\"Address_Line_7\", StringType(), True),\n",
    "    StructField(\"Address_Line_8\", StringType(), True),\n",
    "    StructField(\"Address_Line_9\", StringType(), True),\n",
    "    StructField(\"Last_Name\", StringType(), True),\n",
    "    StructField(\"Middlenames\", StringType(), True),\n",
    "    StructField(\"First_Name\", StringType(), True),\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"DOB\", StringType(), True),\n",
    "    StructField(\"guid\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Function to generate fake electoral data\n",
    "def generate_elector_data(n_rows):\n",
    "    data = {\n",
    "        \"Local_Authority\": [],\n",
    "        \"Postcode\": [],\n",
    "        \"Address_Line_2\": [],\n",
    "        \"Address_Line_3\": [],\n",
    "        \"Address_Line_4\": [],\n",
    "        \"Address_Line_5\": [],\n",
    "        \"Last_Name\": [],\n",
    "        \"Middlenames\": [],\n",
    "        \"First_Name\": [],\n",
    "        \"Title\": [],\n",
    "        \"guid\": [],\n",
    "        \"SOURCE_FILE\": [],\n",
    "        \"Address_Line_1\": [],\n",
    "        \"DOB\": [],\n",
    "        \"TIME_STAMP\": []\n",
    "    }\n",
    "\n",
    "    for i in range(n_rows):\n",
    "        # Generate address and personal data\n",
    "        data[\"Local_Authority\"].append(address_provider.region())\n",
    "        data[\"Postcode\"].append(address_provider.postal_code())\n",
    "        data[\"Address_Line_2\"].append(address_provider.street_name())\n",
    "        data[\"Address_Line_3\"].append(address_provider.city())\n",
    "        data[\"Address_Line_4\"].append(address_provider.city())\n",
    "        data[\"Address_Line_5\"].append(address_provider.country())\n",
    "        \n",
    "        # Generate names\n",
    "        data[\"Last_Name\"].append(person_provider.last_name())\n",
    "        data[\"Middlenames\"].append(person_provider.name())\n",
    "        data[\"First_Name\"].append(person_provider.name())\n",
    "        data[\"Title\"].append(person_provider.title(title_type=TitleType.TYPICAL))\n",
    "        \n",
    "        # Unique GUID for each entry\n",
    "        data[\"guid\"].append(person_provider.password())\n",
    "        \n",
    "        # Source file, placeholder for now\n",
    "        data[\"SOURCE_FILE\"].append(f'{person_provider.username(mask=\"l_l\")}.csv')\n",
    "        \n",
    "        # Address line 1 - Random number as address number\n",
    "        data[\"Address_Line_1\"].append(person_provider.random.randint(1, 200))\n",
    "\n",
    "        # Date of Birth: Randomly generate between ages 18-99\n",
    "        dob_year = person_provider.random.randint(1925, 2007)\n",
    "        dob_month = person_provider.random.randint(1, 12)\n",
    "        dob_day = person_provider.random.randint(1, 28)  # Using 28 here due to February having only 28 days\n",
    "        data[\"DOB\"].append(f\"{dob_day:02d}-{dob_month:02d}-{dob_year}\")\n",
    "        \n",
    "        # Timestamp of data generation\n",
    "        data[\"TIME_STAMP\"].append(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    return data\n",
    "\n",
    "# Generate fake data\n",
    "n_rows = 1000\n",
    "data = generate_elector_data(n_rows)\n",
    "\n",
    "# Create a DataFrame based on the generated data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Update some columns as a copy for certain rows\n",
    "same_street_rows = 10\n",
    "for i in range(same_street_rows):\n",
    "    df.at[n_rows - (i + 1), 'Address_Line_4'] = df.at[n_rows - 1, 'Local_Authority']\n",
    "    df.at[n_rows - (i + 1), 'Address_Line_3'] = df.at[n_rows - 1, 'Address_Line_3']\n",
    "    df.at[n_rows - (i + 1), 'Address_Line_2'] = df.at[n_rows - 1, 'Address_Line_2']\n",
    "    df.at[n_rows - (i + 1), 'Postcode'] = df.at[n_rows - 1, 'Postcode']\n",
    "    df.at[n_rows - (i + 1), 'SOURCE_FILE'] = df.at[n_rows - 1, 'SOURCE_FILE']\n",
    "\n",
    "# Adding extra columns for address continuity\n",
    "df['Address_Line_6'] = np.nan\n",
    "df['Address_Line_7'] = np.nan\n",
    "df['Address_Line_8'] = np.nan\n",
    "df['Address_Line_9'] = np.nan\n",
    "\n",
    "# Add ID column starting from 1\n",
    "df['ID'] = [str(i).zfill(len(str(n_rows))) for i in np.arange(1, n_rows + 1)]\n",
    "\n",
    "df = df[[\n",
    "    'ID', 'SOURCE_FILE', 'TIME_STAMP', 'Local_Authority', 'Postcode', 'Address_Line_1', 'Address_Line_2',\n",
    "    'Address_Line_3', 'Address_Line_4', 'Address_Line_5', 'Address_Line_6', 'Address_Line_7', 'Address_Line_8',\n",
    "    'Address_Line_9', 'Last_Name', 'Middlenames', 'First_Name', 'Title', 'DOB', 'guid'\n",
    "]]\n",
    "\n",
    "# Now either directly use PySpark or read from the CSV depending on the environment\n",
    "if in_virtualenv():\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: Pandas DataFrame -> CSV -> Spark DataFrame\")\n",
    "    file_path = \"electoral_data.csv\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "    population_df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "    population_df.show()\n",
    "else:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: spark.createDataFrame\")\n",
    "    pd.DataFrame.iteritems = pd.DataFrame.items\n",
    "    population_df = spark.createDataFrame(df)\n",
    "    population_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Conclusion\n",
    "\n",
    "In this notebook, we explored how to generate synthetic data using the `mimesis` library. We covered various classes, including `Person`, `Datetime`, `Finance`, `Address`, and `Transport`. These classes offer a rich set of features to generate realistic data for testing machine learning models or simulating real-world datasets. \n",
    "\n",
    "The `mimesis` library provides a flexible and powerful way to create diverse types of synthetic data, ensuring that the generated data is contextually appropriate and varied. By leveraging different locales, we can generate data that reflects the cultural and formatting norms of various regions, making it suitable for international applications.\n",
    "\n",
    "Additionally, we demonstrated how to integrate `mimesis` with PySpark to handle larger datasets in a distributed manner, showcasing the scalability of the data generation process.\n",
    "\n",
    "Feel free to explore and modify the code to suit your data generation needs. This notebook can be expanded with additional classes, more detailed data generation examples, and use cases, depending on the specific needs of the users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "\n",
    "* [Mimesis API](https://mimesis.name/v12.1.1/api.html)\n",
    "* [Medium Blog on Mimesis](https://medium.com/@tubelwj/mimesis-a-python-library-for-generating-test-sample-data-7809d894cbd9)\n",
    "* [Getting Started with Mimesis: A Modern Approach to Synthetic Data Generation](https://www.statology.org/getting-started-mimesis-modern-approach-synthetic-data-generation/)\n",
    "* [Synthpop: Syntheic Data in R](../ancillary-topics/synthpop_with_r)\n",
    "* [Faker: Synthetic Data in Python](../ancillary-topics/faker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
