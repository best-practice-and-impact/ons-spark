
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Spark Sessions &#8212; Spark at the ONS</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/tabs.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Example Spark Sessions" href="example-spark-sessions.html" />
    <link rel="prev" title="Content with notebooks" href="../templates/notebooks.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Spark at the ONS</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Introduction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Template pages
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../templates/markdown.html">
   Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../templates/notebooks.html">
   Content with notebooks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Spark overview
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Spark Sessions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="example-spark-sessions.html">
   Example Spark Sessions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Spark functions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-functions/union_dataframes_with_different_columns.html">
   Union two DataFrames with different columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-functions/sampling.html">
   Sampling:
   <code class="docutils literal notranslate">
    <span class="pre">
     .sample()
    </span>
   </code>
   and
   <code class="docutils literal notranslate">
    <span class="pre">
     sdf_sample()
    </span>
   </code>
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/spark-overview/spark-session-guidance.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/robertswh/Spark at the ONS"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/robertswh/Spark at the ONS/issues/new?title=Issue%20on%20page%20%2Fspark-overview/spark-session-guidance.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#architecture">
   Architecture
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-a-spark-session">
   Creating a Spark Session
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-default-parameters">
     Using default parameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specifying-configs">
     Specifying configs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#config-glossary">
   Config Glossary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#calculating-resource-allocation">
   Calculating Resource Allocation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#resource-allocation">
     Resource allocation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reserving-resource">
     Reserving resource
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="spark-sessions">
<h1>Spark Sessions<a class="headerlink" href="#spark-sessions" title="Permalink to this headline">¶</a></h1>
<section id="architecture">
<h2>Architecture<a class="headerlink" href="#architecture" title="Permalink to this headline">¶</a></h2>
<p>There are many versions of the diagram below on the internet. This version illustrates how we interact with data on the Cloudera cluster within the Data Access Plaform using Spark. If ONS staff are looking for more information online, note that our cluster runs on YARN.</p>
<figure class="align-default" id="id1">
<a class="reference internal image-reference" href="../../../images/spark_driver_executors.PNG"><img alt="Diagram that shows a CDSW program on an edge node linking to a resource manager and multiple worker nodes containing executors." src="../../../images/spark_driver_executors.PNG" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">CDSW container running on YARN</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>Each machine in a cluster is referred to as a node. We start with the edge node, which is sometimes called a gateway node because it’s our gateway or interface to the cluster. There is also a resource manager and some worker nodes.</p>
<ol class="simple">
<li><p>Our first step is to launch a Python or R CDSW session, which runs on the edge node.</p></li>
<li><p>Next from within the CDSW session we create a Spark session. Spark will communicate with the resource manager and allocate some resource to our Spark session in the form of executors.</p></li>
<li><p>We then write some Spark instructions in our CDSW session to process some data. Use the sparklyr package in R or the PySpark package for Python. These instructions form Spark jobs which are executed on worker nodes on the cluster by executors.</p></li>
<li><p>Finally, any results we have requested are moved back to the edge node for us to view because we can’t view data while it’s on an executor.</p></li>
</ol>
<p>One of the great features of Spark is that we’re able to scale up our resources to complete more expensive tasks, such as processing lots of data or running some complex algorithm. When we send a complex Spark job to the cluster the resource manager will automatically allocate more executors to help with the
job. It will also shut them down when they are not needed. This process of switching executors on and off is called dynamic allocation.</p>
<p>Remember we should stop the Spark session when we are finished to free up the cluster resource for others. This is done automatically when we stop our CDSW
session, or you can also do it by running <code class="docutils literal notranslate"><span class="pre">spark.stop()</span></code>.</p>
</section>
<section id="creating-a-spark-session">
<h2>Creating a Spark Session<a class="headerlink" href="#creating-a-spark-session" title="Permalink to this headline">¶</a></h2>
<p>There are many options when it comes to creating a Spark session. We recommend using the default parameters when getting started, you can then start adding other parameters when you learn more about how Spark works and how to tune your session to your specific needs.</p>
<section id="using-default-parameters">
<h3>Using default parameters<a class="headerlink" href="#using-default-parameters" title="Permalink to this headline">¶</a></h3>
<p>As a starting point you can create a Spark session with all the defaults. This is the bare minimum you need to create a Spark session and will work fine in most cases. Note you should give your session a sensible name, here we have called it <code class="docutils literal notranslate"><span class="pre">default-session</span></code>.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-UHl0aG9u" aria-selected="true" class="sphinx-tabs-tab code-tab group-tab" id="tab-0-UHl0aG9u" name="UHl0aG9u" role="tab" tabindex="0">Python</button><button aria-controls="panel-0-Ug==" aria-selected="false" class="sphinx-tabs-tab code-tab group-tab" id="tab-0-Ug==" name="Ug==" role="tab" tabindex="-1">R</button></div><div aria-labelledby="tab-0-UHl0aG9u" class="sphinx-tabs-panel code-tab group-tab" id="panel-0-UHl0aG9u" name="UHl0aG9u" role="tabpanel" tabindex="0"><div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;default-session&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-Ug==" class="sphinx-tabs-panel code-tab group-tab" hidden="true" id="panel-0-Ug==" name="Ug==" role="tabpanel" tabindex="0"><div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">sparklyr</span><span class="p">)</span>

<span class="n">default_config</span> <span class="o">&lt;-</span> <span class="nf">spark_config</span><span class="p">()</span>

<span class="n">sc</span> <span class="o">&lt;-</span> <span class="nf">spark_connect</span><span class="p">(</span>
    <span class="n">master</span> <span class="o">=</span> <span class="s">&quot;yarn-client&quot;</span><span class="p">,</span>
    <span class="n">app_name</span> <span class="o">=</span> <span class="s">&quot;default-session&quot;</span><span class="p">,</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">default_config</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
</section>
<section id="specifying-configs">
<h3>Specifying configs<a class="headerlink" href="#specifying-configs" title="Permalink to this headline">¶</a></h3>
<p>When you have a good grasp of how Spark works, you understand what processing needs doing and most importantly the data, you can look to introduce some customised configurations to your Spark session. The session builder will look something like this,</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-UHl0aG9u" aria-selected="true" class="sphinx-tabs-tab code-tab group-tab" id="tab-1-UHl0aG9u" name="UHl0aG9u" role="tab" tabindex="0">Python</button><button aria-controls="panel-1-Ug==" aria-selected="false" class="sphinx-tabs-tab code-tab group-tab" id="tab-1-Ug==" name="Ug==" role="tab" tabindex="-1">R</button></div><div aria-labelledby="tab-1-UHl0aG9u" class="sphinx-tabs-panel code-tab group-tab" id="panel-1-UHl0aG9u" name="UHl0aG9u" role="tabpanel" tabindex="0"><div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;custom-session&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;&lt;property-name&gt;&quot;</span><span class="p">,</span> <span class="o">&lt;</span><span class="nb">property</span><span class="o">-</span><span class="n">value</span><span class="o">&gt;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-Ug==" class="sphinx-tabs-panel code-tab group-tab" hidden="true" id="panel-1-Ug==" name="Ug==" role="tabpanel" tabindex="0"><div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">&lt;-</span> <span class="nf">spark_config</span><span class="p">()</span>
<span class="n">config</span><span class="o">$&lt;</span><span class="n">property</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span> <span class="o">&lt;-</span> <span class="o">&lt;</span><span class="n">property</span><span class="o">-</span><span class="n">value</span><span class="o">&gt;</span>

<span class="n">sc</span> <span class="o">&lt;-</span> <span class="nf">spark_connect</span><span class="p">(</span>
    <span class="n">master</span> <span class="o">=</span> <span class="s">&quot;yarn-client&quot;</span><span class="p">,</span>
    <span class="n">app_name</span> <span class="o">=</span> <span class="s">&quot;custom-session&quot;</span><span class="p">,</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">config</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
<p>The most popular configs to set are listed and explained in the <a class="reference external" href="#config-glossary">Config glossary</a> section below. Some example Spark configurations are given in [example Spark configurations] section.</p>
<p>See the page on <code class="docutils literal notranslate"><span class="pre">spark-defaults.conf</span></code> for setting these properties in other ways.</p>
<p>The <a class="reference external" href="https://spark.rstudio.com/guides/connections/">Configuring Spark Connections</a> page of the RStudio documentation gives a good introduction on this topic that builds on the guidance here.</p>
</section>
</section>
<section id="config-glossary">
<h2>Config Glossary<a class="headerlink" href="#config-glossary" title="Permalink to this headline">¶</a></h2>
<p>Some commonly used Spark and YARN properties are listed in this section.</p>
<p>For more details look at the official documentation for Spark configuration:
<a class="reference external" href="https://spark.apache.org/docs/2.4.0/configuration.html">https://spark.apache.org/docs/2.4.0/configuration.html</a></p>
<p>ONS runs Spark on YARN, that entails another set of configuration options documented here:
<a class="reference external" href="https://spark.apache.org/docs/2.4.0/running-on-yarn.html">https://spark.apache.org/docs/2.4.0/running-on-yarn.html</a></p>
<p>To view all of the parameters, both default and custom, associated with your Spark session use</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">getConf</span><span class="p">()</span><span class="o">.</span><span class="n">getAll</span><span class="p">()</span>
</pre></div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">sparkContext</span></code> is created automatically when calling <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code></p>
<p><em>Note that the values shown in brackets are the default values</em></p>
<p><strong>App Name:</strong><br />
<code class="docutils literal notranslate"><span class="pre">.appName()</span></code><br />
The Spark session is often referred to as a Spark application. This option gives your Spark session a meaningful name, which can be used to help others identify the purpose of your app.<br />
You should enter your app name as a string, so within ‘single’ or “double” inverted commas.</p>
<p><strong>Executor Memory:</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.executor.memory&quot;,</span> <span class="pre">1g)</span></code><br />
This is the amount of memory per Spark executor. Can be given in mebibytes (m) or gibibytes (g).</p>
<p><strong>Cores</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.executor.cores&quot;,</span> <span class="pre">1)</span></code><br />
This is the number of cores each executor can use.</p>
<p><strong>Executor Memory Overhead</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.yarn.executor.memoryOverhead&quot;,</span> <span class="pre">max(0.1</span> <span class="pre">*</span> <span class="pre">spark.executor.memory,</span> <span class="pre">348m))</span></code><br />
This sets the amount of additional memory allocated per executor for overheads.<br />
The default value is either 0.1 times the executor memory size, or 348MiB, whichever is greater.<br />
You might consider increasing the memory overhead, for example, if you are using User Defined Functions (UDFs) in your PySpark code.</p>
<p><strong>Dynamic Allocation</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.dynamicAllocation.enabled&quot;,</span> <span class="pre">&quot;true&quot;)</span></code><br />
This setting allows your Spark session to scale up or down by automatically adding and removing executors depending on your workload.<br />
In the DAP environments, dynamic allocation is enabled by default.</p>
<p><strong>Max Executors</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.dynamicAllocation.maxExecutors&quot;,</span> <span class="pre">)</span></code><br />
This sets the maximum number of executors that can be used in dynamic allocation. Spark has no default value for maxExecutors.<br />
Within DAP, minExecutors is set to 3, so maxExecutors cannot be set to less than 3.</p>
<p>Also note when specifying this config, Spark will reserve the maxExecutors for you so others cannot access these resources until you
stop your session- even if you don’t need them. See the <a class="reference external" href="#reserving">reserving</a> section of the calculations below for more details.</p>
<p><strong>Shuffle Service</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.shuffle.service.enabled&quot;,</span> <span class="pre">&quot;true&quot;)</span></code><br />
This ensures executors can be safely removed and is required for dynamic allocation. It is enabled by default in DAP.</p>
<p><strong>Hive Support</strong><br />
<code class="docutils literal notranslate"><span class="pre">.enableHiveSupport()</span></code><br />
This setting should be used if you want to interact with data stored in Hive tables.</p>
<p><strong>Shuffle Partitions</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.sql.shuffle.partitions&quot;,</span> <span class="pre">200)</span></code><br />
Sets the number of partitions to use for a DataFrame after a shuffle. The default is 200, which is too high for most use cases.</p>
<p><strong>Console Progress Bars</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.ui.showConsoleProgress&quot;,</span> <span class="pre">&quot;true&quot;)</span></code><br />
This setting is set to true by default in DAP, but should be set to false in order to correctly display output in CDSW.</p>
</section>
<section id="calculating-resource-allocation">
<h2>Calculating Resource Allocation<a class="headerlink" href="#calculating-resource-allocation" title="Permalink to this headline">¶</a></h2>
<p>Let’s take the large session from the <a class="reference external" href="http://np2rvlapxx507/DAP_CATS/guidance/-/blob/master/spark_session_sizes.ipynb">Example Spark Sessions</a> and explain the allocation of resource in more detail.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;large-session&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.executor.memory&quot;</span><span class="p">,</span> <span class="s2">&quot;10g&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.yarn.executor.memoryOverhead&quot;</span><span class="p">,</span> <span class="s2">&quot;1g&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.executor.cores&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.dynamicAllocation.enabled&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.dynamicAllocation.maxExecutors&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.shuffle.service.enabled&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.ui.showConsoleProgress&quot;</span><span class="p">,</span> <span class="s2">&quot;false&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">enableHiveSupport</span><span class="p">()</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
<section id="resource-allocation">
<h3>Resource allocation<a class="headerlink" href="#resource-allocation" title="Permalink to this headline">¶</a></h3>
<p>How much resource is allocated to this application? Here we are asking how many cores and memory is this application using?</p>
<p>Cores - We have requested 5 cores per executor using <code class="docutils literal notranslate"><span class="pre">spark.executor.cores</span></code> and 5 executors with <code class="docutils literal notranslate"><span class="pre">spark.dynamicAllocation.maxExecutors</span></code>. The sum is then:</p>
<p>5 cores per executor x 5 executors = 25 cores</p>
<p>Memory - Using <code class="docutils literal notranslate"><span class="pre">spark.executor.memory</span></code> we requested 10 GiB of memory (also called  <em>on-heap</em> memory) per executor. Using <code class="docutils literal notranslate"><span class="pre">spark.yarn.executor.memoryOverhead</span></code> we
requested 1 GiB of overhead memory (also called <em>off-heap</em> memory). As before, we requested 5 executors with <code class="docutils literal notranslate"><span class="pre">spark.dynamicAllocation.maxExecutors</span></code>. Now the sum is:</p>
<p>( 10 GiB + 1 GiB ) per executor x 5 executors = 55 GiB of memory</p>
</section>
<section id="reserving-resource">
<h3>Reserving resource<a class="headerlink" href="#reserving-resource" title="Permalink to this headline">¶</a></h3>
<p>An important point to remember about setting the <code class="docutils literal notranslate"><span class="pre">spark.dynamicAllocation.maxExecutors</span></code> option is that <em>although</em> Spark will increase and decrease the number of executors
we use at any point, the <em>maximum resource requested</em> will be reserved for the application.</p>
<p>That means that in the above example Spark will reserve 25 cores and 55 GiB
of memory for this application for the entirety of its duration, no matter if we are only utilising a single executor. This is not an issue here as 25 cores and 55 GiB isn’t
excessive for processing a large DataFrame. However, if <code class="docutils literal notranslate"><span class="pre">spark.dynamicAllocation.maxExecutors</span></code> was set to 500 requests from other DAP users might be rejected and the cluster
would be under significant strain.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./spark-overview"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../templates/notebooks.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Content with notebooks</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="example-spark-sessions.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Example Spark Sessions</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Wil Roberts & Adrian Prince<br/>
        
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>