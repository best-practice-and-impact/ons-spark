{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union two DataFrames with different columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The union of two DataFrames is the process of appending one DataFrame below another.\n",
    "\n",
    "The [PySpark `.union()` function](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.union.html) is equivalent to the SQL `UNION ALL` function, where both DataFrames must have the same number of columns. However the [sparklyr `sdf_bind_rows()` function](https://rdrr.io/github/rstudio/sparklyr/man/sdf_bind.html) can combine two DataFrames with different number of columns, by putting `NULL` values into the rows of data.\n",
    "\n",
    "Here's how we can use PySpark to mimic the behaviour of the `sdf_bind_rows()` function in sparklyr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"union-example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame of Wimbledon singles champions from 2017 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+--------+\n",
      "|tournament_year|              event|champion|\n",
      "+---------------+-------------------+--------+\n",
      "|           2017|Gentlemen's Singles| Federer|\n",
      "|           2018|Gentlemen's Singles|Djokovic|\n",
      "|           2019|Gentlemen's Singles|Djokovic|\n",
      "|           2017|    Ladies' Singles|Muguruza|\n",
      "|           2018|    Ladies' Singles|  Kerber|\n",
      "|           2019|    Ladies' Singles|   Halep|\n",
      "+---------------+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_schema =  \"\"\"\n",
    "    `tournament_year` int,\n",
    "    `event` string,\n",
    "    `champion` string\n",
    "\"\"\"\n",
    "\n",
    "df1 = spark.createDataFrame([\n",
    "    [2017, \"Gentlemen's Singles\", \"Federer\"],\n",
    "    [2018, \"Gentlemen's Singles\", \"Djokovic\"],\n",
    "    [2019, \"Gentlemen's Singles\", \"Djokovic\"],\n",
    "    [2017, \"Ladies' Singles\", \"Muguruza\"],\n",
    "    [2018, \"Ladies' Singles\", \"Kerber\"],\n",
    "    [2019, \"Ladies' Singles\", \"Halep\"],\n",
    "    ], \n",
    "    schema=df1_schema\n",
    ")\n",
    "\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to append 2020 data. However, there was no Wimbledon tournament in 2020. We'll just create two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|tournament_year|              event|\n",
      "+---------------+-------------------+\n",
      "|           2020|Gentlemen's Singles|\n",
      "|           2020|    Ladies' Singles|\n",
      "+---------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_schema = \"\"\"\n",
    "    `tournament_year` int,\n",
    "    `event` string\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.createDataFrame([\n",
    "    [2020, \"Gentlemen's Singles\"],\n",
    "    [2020, \"Ladies' Singles\"]\n",
    "    ],\n",
    "    schema=df2_schema\n",
    ")\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to union these DataFrames together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Union can only be performed on tables with the same number of columns, but the first table has 3 columns and the second table has 2 columns;;\\n'Union\\n:- LogicalRDD [tournament_year#0, event#1, champion#2], false\\n+- LogicalRDD [tournament_year#16, event#17], false\\n\"\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_joined = df1.union(df2)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error message says we need the same number of columns. So let's try adding a column to `df2` full of `Null` values before the union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tournament_year: integer (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      " |-- champion: string (nullable = true)\n",
      "\n",
      "+---------------+-------------------+--------+\n",
      "|tournament_year|              event|champion|\n",
      "+---------------+-------------------+--------+\n",
      "|           2017|Gentlemen's Singles| Federer|\n",
      "|           2018|Gentlemen's Singles|Djokovic|\n",
      "|           2019|Gentlemen's Singles|Djokovic|\n",
      "|           2017|    Ladies' Singles|Muguruza|\n",
      "|           2018|    Ladies' Singles|  Kerber|\n",
      "|           2019|    Ladies' Singles|   Halep|\n",
      "|           2020|Gentlemen's Singles|    null|\n",
      "|           2020|    Ladies' Singles|    null|\n",
      "+---------------+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined = df1.union(df2.withColumn(\"champion\", F.lit(None)))\n",
    "df_joined.printSchema()\n",
    "df_joined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time it worked. We get the result we were looking for. \n",
    "\n",
    "However, we need to be careful in doing this. What if the columns in `df2` were defined in a different order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+\n",
      "|              event|tournament_year|\n",
      "+-------------------+---------------+\n",
      "|Gentlemen's Singles|           2020|\n",
      "|    Ladies' Singles|           2020|\n",
      "+-------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_schema = \"\"\"\n",
    "    `event` string,\n",
    "    `tournament_year` int\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.createDataFrame([\n",
    "    [\"Gentlemen's Singles\", 2020],\n",
    "    [\"Ladies' Singles\", 2020]\n",
    "    ],\n",
    "    schema=df2_schema\n",
    ")\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tournament_year: string (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      " |-- champion: string (nullable = true)\n",
      "\n",
      "+-------------------+-------------------+--------+\n",
      "|    tournament_year|              event|champion|\n",
      "+-------------------+-------------------+--------+\n",
      "|               2017|Gentlemen's Singles| Federer|\n",
      "|               2018|Gentlemen's Singles|Djokovic|\n",
      "|               2019|Gentlemen's Singles|Djokovic|\n",
      "|               2017|    Ladies' Singles|Muguruza|\n",
      "|               2018|    Ladies' Singles|  Kerber|\n",
      "|               2019|    Ladies' Singles|   Halep|\n",
      "|Gentlemen's Singles|               2020|    null|\n",
      "|    Ladies' Singles|               2020|    null|\n",
      "+-------------------+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined = df1.union(df2.withColumn(\"champion\", F.lit(None)))\n",
    "df_joined.printSchema()\n",
    "df_joined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code runs, but the result isn't what we want. We should therefore write our code in a way that mitigates the risk of this happening. We might have the correct order now, but in future perhaps the order might change.\n",
    "\n",
    "We'll take the column order from the DataFrame with all the columns, `df1`, and force `df2` to have the same column order before doing the union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tournament_year: integer (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      " |-- champion: string (nullable = true)\n",
      "\n",
      "+---------------+-------------------+--------+\n",
      "|tournament_year|              event|champion|\n",
      "+---------------+-------------------+--------+\n",
      "|           2017|Gentlemen's Singles| Federer|\n",
      "|           2018|Gentlemen's Singles|Djokovic|\n",
      "|           2019|Gentlemen's Singles|Djokovic|\n",
      "|           2017|    Ladies' Singles|Muguruza|\n",
      "|           2018|    Ladies' Singles|  Kerber|\n",
      "|           2019|    Ladies' Singles|   Halep|\n",
      "|           2020|Gentlemen's Singles|    null|\n",
      "|           2020|    Ladies' Singles|    null|\n",
      "+---------------+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_order = df1.columns\n",
    "df_joined = df1.union(df2.withColumn(\"champion\", F.lit(None)).select(col_order))\n",
    "df_joined.printSchema()\n",
    "df_joined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one more example where we have a third DataFrame with different columns. Such as results from the 2021 tournament, which hasn't taken place yet (at the time or writing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|tournament_year|\n",
      "+---------------+\n",
      "|           2021|\n",
      "|           2021|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3_schema = \"\"\"\n",
    "    `tournament_year` int\n",
    "\"\"\"\n",
    "\n",
    "df3 = spark.createDataFrame([\n",
    "    [2021],\n",
    "    [2021]\n",
    "    ],\n",
    "    schema=df3_schema\n",
    ")\n",
    "\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a list of unique columns in all the DataFrames along with their types. We can use `set()` to get the unique column names and types, then convert into a dictionary to create key/value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'champion': 'string', 'event': 'string', 'tournament_year': 'int'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_dict = dict(set(df1.dtypes + df2.dtypes + df3.dtypes))\n",
    "col_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll create a function that checks to see if a DataFrame has all the columns we need for the union. If the DataFrame is missing a column we'll add an empty column with that name, and give it the correct type using `.cast()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_empty_columns(df, col_dict):\n",
    "    for col in col_dict.keys():\n",
    "        if col not in df.columns:\n",
    "            df = df.withColumn(col, F.lit(None).cast(col_dict[col]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we apply the function to all three DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = add_empty_columns(df1, col_dict)\n",
    "df2 = add_empty_columns(df2, col_dict)\n",
    "df3 = add_empty_columns(df3, col_dict)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to decide on a column order for the unions, we can get this from `col_dict.keys()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['champion', 'tournament_year', 'event']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_order = list(col_dict.keys())\n",
    "col_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, do the union. Note we use `.select(col_order)` after referencing each DataFrame to make sure the columns are in a consistent order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df1.select(col_order).union(df2.select(col_order)).union(df3.select(col_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- champion: string (nullable = true)\n",
      " |-- tournament_year: integer (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      "\n",
      "+--------+---------------+-------------------+\n",
      "|champion|tournament_year|              event|\n",
      "+--------+---------------+-------------------+\n",
      "| Federer|           2017|Gentlemen's Singles|\n",
      "|Djokovic|           2018|Gentlemen's Singles|\n",
      "|Djokovic|           2019|Gentlemen's Singles|\n",
      "|Muguruza|           2017|    Ladies' Singles|\n",
      "|  Kerber|           2018|    Ladies' Singles|\n",
      "|   Halep|           2019|    Ladies' Singles|\n",
      "|    null|           2020|Gentlemen's Singles|\n",
      "|    null|           2020|    Ladies' Singles|\n",
      "|    null|           2021|               null|\n",
      "|    null|           2021|               null|\n",
      "+--------+---------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined.printSchema()\n",
    "df_joined.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
