{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This hidden cell is used for local execution of the notebook file, it does not appear in the published book\n",
    "\n",
    "# Silence warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup working directory\n",
    "import os, re\n",
    "\n",
    "dir_match = re.search(\n",
    "    r\".+ons-spark$\",\n",
    "    str(os.getcwd())\n",
    ")\n",
    "\n",
    "if not dir_match: os.chdir('../..')\n",
    "\n",
    "# Setup Spark environment variables for local use\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pandas UDFs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When coding with Spark, you will generally want to try and use native Spark functions wherever possible (i.e. functions in `pyspark.sql.functions` for PySpark). However, there are instances where there may not be a Spark function available to do what you need. In cases such as this, the second best option is to use a Pandas UDF. \n",
    "\n",
    "### Why are Pandas UDFs better than Python UDFs?\n",
    "\n",
    "Ordinary Python UDFs are not particularly efficient in Spark as they do not make full use of the Spark cluster and can only be processed in the Python runtime. As the code for Python UDFs cannot be executed in the Java Virtual Machine (JVM), the platform which runs Spark, each row of the dataframe is serialised and deserialised between the Python runtime and the JVM. As can be imagined, this causes massive (de)serialisation overheads, high data copy in memory and is very slow!\n",
    "\n",
    "Pandas UDFs (also known as vectorised UDFs) can work on the Spark executors to process data in a distributed manner and allow for vectorised operations. This means that Pandas UDFs can work on the whole data partition at once instead of just one row at a time like Python UDFs. This vectorisation is achieved by using Apache Arrow to transfer data across the cluster between the JVM and the Python executors with very low data copy in memory and (de)serialisation overheads. Essentially, Apache Arrow acts as a middleman to store a single copy of the data which can be accessed by both Python and Java processes.\n",
    "\n",
    "### Types of Pandas UDFs\n",
    "\n",
    "Spark 2.4 is compatible with 3 types of Pandas UDFs:\n",
    "- Scalar\n",
    "- Grouped Map\n",
    "- Grouped Aggregate\n",
    "\n",
    "Spark 3.x is compatible with the additional types:\n",
    "- Scalar Iterator\n",
    "- Map\n",
    "- Cogroup Mapped\n",
    "\n",
    "This demo will cover the three types supported in Spark 2.4. Additional information on the other types for Spark 3.x can be found [here](https://towardsdatascience.com/pyspark-or-pandas-why-not-both-95523946ec7c).\n",
    "\n",
    "### Declaring Pandas UDFs in Spark\n",
    "\n",
    "You can create a Pandas UDF in a number of ways.\n",
    "- Using the `@pandas_udf(<type>, F.PandasUDFType.<type>)` decorator.\n",
    "- Assigning the UDF using `<udf_name>_udf = F.pandas_udf(<udf_name>, returnType = <type>)`\n",
    "- Using Python Type hints. Python hints can be used to make Pandas UDFs more descriptive. For more info see [here](https://www.databricks.com/blog/2020/05/20/new-pandas-udfs-and-python-type-hints-in-the-upcoming-release-of-apache-spark-3-0.html).\n",
    "\n",
    "This demo will use the `pandas_udf` decorator and Python hints to annotate the functions with the input and output data types.\n",
    "\n",
    "\n",
    "### Spark Setup for Pandas UDFs\n",
    "\n",
    "For Spark 3, to use Pandas UDFs you will have to install Pandas and PyArrow using:\n",
    "```\n",
    "pip install pandas\n",
    "pip install pyarrow\n",
    "```\n",
    "\n",
    "For Spark 2.4 you will need to install the older versions of Pandas and PyArrow using. We found the following versions to be the highest which will work with Pandas UDFs, although expect a deprecation warning:\n",
    "```\n",
    "pip install pandas==1.1.5\n",
    "pip install pyarrow==0.14.0\n",
    "```\n",
    "The [offical PySpark Usage Guide for Pandas with Apache Arrow](https://spark.apache.org/docs/2.4.7/sql-pyspark-pandas-with-arrow.html#compatibiliy-setting-for-pyarrow--0150-and-spark-23x-24x) advises that compatibility issues may occur with Pandas >0.19.2 and PyArrow >0.8.0, so if you are finding issues, it may be best to switch to these lower versions.\n",
    "\n",
    "You should also add configs to enable PyArrow optimisation and fallback if it is not installed. Even if you are not using Pandas UDFs the below configs can make the conversion between Pandas and Spark more efficient.\n",
    "\n",
    "```\n",
    ".config('spark.sql.execution.arrow.enabled', 'true')\n",
    ".config('spark.sql.execution.arrow.fallback.enabled', 'true')\n",
    "```\n",
    "\n",
    "For Spark 2.4 you will need to add the below additional configs to your Spark session for compatibility:\n",
    "\n",
    "```\n",
    ".config('spark.excutorEnv.ARROW_PRE_0_15_IPC_FORMAT', 1)\n",
    ".config('spark.workerEnv.ARROW_PRE_0_15_IPC_FORMAT', 1)\n",
    "```\n",
    "\n",
    "In our demo we are using a local Spark session and will be working with the animal rescue dataset used throughout in this book. We have used examples of Pandas UDFs applied to the rescue dataset only for the purpose of demonstration as there are Spark functions which in a real-life scenario would be used instead. For other simple examples of Pandas UDFs please see [Databricks Introduction to Pandas UDFs](https://www.databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html).\n",
    "\n",
    "Firstly, we need to import packages and set up a Spark session for PyArrow optimisation and compatibility with Spark 2.4. Then read the data, rename and add columns and if necessary remove nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_number</th>\n",
       "      <th>animal_group</th>\n",
       "      <th>easting_rounded</th>\n",
       "      <th>northing_rounded</th>\n",
       "      <th>lfb_easting</th>\n",
       "      <th>lfb_northing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139091</td>\n",
       "      <td>Dog</td>\n",
       "      <td>532350</td>\n",
       "      <td>170050</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275091</td>\n",
       "      <td>Fox</td>\n",
       "      <td>534750</td>\n",
       "      <td>167550</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2075091</td>\n",
       "      <td>Dog</td>\n",
       "      <td>528050</td>\n",
       "      <td>164950</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2872091</td>\n",
       "      <td>Horse</td>\n",
       "      <td>504650</td>\n",
       "      <td>190650</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3553091</td>\n",
       "      <td>Rabbit</td>\n",
       "      <td>554650</td>\n",
       "      <td>192350</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3742091</td>\n",
       "      <td>Unknown - Heavy Livestock Animal</td>\n",
       "      <td>549350</td>\n",
       "      <td>184950</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4011091</td>\n",
       "      <td>Dog</td>\n",
       "      <td>539050</td>\n",
       "      <td>186150</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4211091</td>\n",
       "      <td>Dog</td>\n",
       "      <td>541350</td>\n",
       "      <td>186650</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4306091</td>\n",
       "      <td>Squirrel</td>\n",
       "      <td>538750</td>\n",
       "      <td>163350</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4715091</td>\n",
       "      <td>Dog</td>\n",
       "      <td>535450</td>\n",
       "      <td>186750</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  incident_number                      animal_group  easting_rounded  \\\n",
       "0          139091                               Dog           532350   \n",
       "1          275091                               Fox           534750   \n",
       "2         2075091                               Dog           528050   \n",
       "3         2872091                             Horse           504650   \n",
       "4         3553091                            Rabbit           554650   \n",
       "5         3742091  Unknown - Heavy Livestock Animal           549350   \n",
       "6         4011091                               Dog           539050   \n",
       "7         4211091                               Dog           541350   \n",
       "8         4306091                          Squirrel           538750   \n",
       "9         4715091                               Dog           535450   \n",
       "\n",
       "   northing_rounded  lfb_easting  lfb_northing  \n",
       "0            170050       532066        180010  \n",
       "1            167550       532066        180010  \n",
       "2            164950       532066        180010  \n",
       "3            190650       532066        180010  \n",
       "4            192350       532066        180010  \n",
       "5            184950       532066        180010  \n",
       "6            186150       532066        180010  \n",
       "7            186650       532066        180010  \n",
       "8            163350       532066        180010  \n",
       "9            186750       532066        180010  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "spark = (SparkSession.builder.master(\"local\")\n",
    "         .appName(\"pandas_udfs\")\n",
    "         .config('spark.sql.execution.arrow.enabled', 'true')\n",
    "         .config('spark.sql.execution.arrow.fallback.enabled', 'true')\n",
    "         .config('spark.excutorEnv.ARROW_PRE_0_15_IPC_FORMAT', 1)\n",
    "         .config('spark.workerEnv.ARROW_PRE_0_15_IPC_FORMAT', 1)\n",
    "         .getOrCreate())\n",
    "\n",
    "import yaml\n",
    "with open(\"config.yaml\") as f:\n",
    "     config = yaml.safe_load(f)\n",
    "\n",
    "rescue_path_csv = config[\"rescue_path_csv\"]\n",
    "rescue = spark.read.csv(rescue_path_csv, header=True, inferSchema=True)\n",
    "\n",
    "rescue = rescue.select(F.col('IncidentNumber').alias('incident_number'),\n",
    "                       F.col('AnimalGroupParent').alias('animal_group'), \n",
    "                       F.col('Easting_rounded').alias('easting_rounded'), \n",
    "                       F.col('Northing_rounded').alias('northing_rounded'))\n",
    "\n",
    "rescue= rescue.withColumn('lfb_easting', lit(532066)).withColumn('lfb_northing', lit(180010))\n",
    "\n",
    "\n",
    "rescue.limit(10).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Pandas UDFs\n",
    "\n",
    "Scalar Pandas UDFs take in a `pandas.Series` and output a `pandas.Series`. \n",
    "\n",
    "Spark executes scalar Pandas UDFs by serialising each partition column into a `pandas.Series` object (basically splitting the data into batches). The UDF is then called on each of of these Series objects as a subset of the data and then results are concactenated together and returned as a `pandas.Series`. \n",
    "\n",
    "Be aware that scalar UDFs may cause incorrect results (if your dataframe is over multiple partitions) when calculating means and standard deviations. For more info on this and how to overcome this issue see [this towards data science post](https://towardsdatascience.com/pyspark-or-pandas-why-not-both-95523946ec7c).\n",
    "\n",
    "In the decorator of a scalar Pandas UDF the first argument is the data type of the output dataframe and the second argument is the UDF type. Here is a simple Pandas scalar UDF to find out the `distance` between the London Fire Brigade (lfb) and the location of an animal-related incident. The inputs to the function are Eastings and Northings which are types of coordinates that tell you how far East or North a point is; therefore, there are two points inputted for the lfb location and two points inputted for the animal-related incident. The function works to find the distance between these two points and converts the answer into 'km'. \n",
    "\n",
    "Please note that the following example has been used here to illustrate how to use a Pandas UDF, this is not necessarily the most efficient way to write this function as it can also be written in PySpark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_number</th>\n",
       "      <th>animal_group</th>\n",
       "      <th>easting_rounded</th>\n",
       "      <th>northing_rounded</th>\n",
       "      <th>lfb_easting</th>\n",
       "      <th>lfb_northing</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139091</td>\n",
       "      <td>Dog</td>\n",
       "      <td>532350</td>\n",
       "      <td>170050</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>9.964048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275091</td>\n",
       "      <td>Fox</td>\n",
       "      <td>534750</td>\n",
       "      <td>167550</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>12.745802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2075091</td>\n",
       "      <td>Dog</td>\n",
       "      <td>528050</td>\n",
       "      <td>164950</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>15.586271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2872091</td>\n",
       "      <td>Horse</td>\n",
       "      <td>504650</td>\n",
       "      <td>190650</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>29.408275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3553091</td>\n",
       "      <td>Rabbit</td>\n",
       "      <td>554650</td>\n",
       "      <td>192350</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>25.735436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  incident_number animal_group  easting_rounded  northing_rounded  \\\n",
       "0          139091          Dog           532350            170050   \n",
       "1          275091          Fox           534750            167550   \n",
       "2         2075091          Dog           528050            164950   \n",
       "3         2872091        Horse           504650            190650   \n",
       "4         3553091       Rabbit           554650            192350   \n",
       "\n",
       "   lfb_easting  lfb_northing   distance  \n",
       "0       532066        180010   9.964048  \n",
       "1       532066        180010  12.745802  \n",
       "2       532066        180010  15.586271  \n",
       "3       532066        180010  29.408275  \n",
       "4       532066        180010  25.735436  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pandas_udf(T.DoubleType(), F.PandasUDFType.SCALAR)\n",
    "def distance_to_incident(easting_rounded:pd.Series, lfb_easting:pd.Series, northing_rounded:pd.Series, lfb_northing:pd.Series)->pd.Series:\n",
    "    distance = ((easting_rounded - lfb_easting)**2 + (northing_rounded - lfb_northing)**2)**0.5\n",
    "    distance_km = distance/1000\n",
    "    return distance_km\n",
    "\n",
    "lfb_distance = rescue.withColumn(\"distance\", distance_to_incident('easting_rounded', 'lfb_easting', 'northing_rounded', 'lfb_northing'))\n",
    "lfb_distance.limit(5).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped Map Pandas UDFs\n",
    "\n",
    "Grouped map UDFs take in a pandas.DataFrame and output a pandas.DataFrame.\n",
    "\n",
    "Grouped Map UDFs use the split-apply-combine format. This is where data is first split into groups based on the `.groupby()` function. The UDF is then mapped over each group to return multiple Pandas dataframes. The results of the Pandas dataframes are then  combined and a new Spark dataframe is returned.\n",
    "\n",
    "In the decorator of a grouped map Pandas UDF the first argument is the schema of the output dataframe and the second argument is the UDF type. Here is a grouped map UDF to find the `distance` travelled by the London Fire Brigade compared to the overall mean `distance` they travel to an incident, grouped by `animal_group`. This example uses the outputted dataframe: `lfb_distance` from the scalar UDF example above. The output is in 'km'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_number</th>\n",
       "      <th>animal_group</th>\n",
       "      <th>easting_rounded</th>\n",
       "      <th>northing_rounded</th>\n",
       "      <th>lfb_easting</th>\n",
       "      <th>lfb_northing</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5363091</td>\n",
       "      <td>Bird</td>\n",
       "      <td>528650</td>\n",
       "      <td>177250</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>-63.244164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7051091</td>\n",
       "      <td>Bird</td>\n",
       "      <td>552350</td>\n",
       "      <td>186750</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>78.892991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9252091</td>\n",
       "      <td>Bird</td>\n",
       "      <td>529750</td>\n",
       "      <td>176650</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>-65.845336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13245091</td>\n",
       "      <td>Bird</td>\n",
       "      <td>519350</td>\n",
       "      <td>190750</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>39.306829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21760091</td>\n",
       "      <td>Bird</td>\n",
       "      <td>529750</td>\n",
       "      <td>180850</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>-79.380757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26715091</td>\n",
       "      <td>Bird</td>\n",
       "      <td>534750</td>\n",
       "      <td>180650</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>-76.906553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27109091</td>\n",
       "      <td>Bird</td>\n",
       "      <td>531350</td>\n",
       "      <td>161550</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>54.616543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27898091</td>\n",
       "      <td>Bird</td>\n",
       "      <td>516450</td>\n",
       "      <td>177350</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>32.580149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28382091</td>\n",
       "      <td>Bird</td>\n",
       "      <td>520950</td>\n",
       "      <td>184850</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>1.471315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30836091</td>\n",
       "      <td>Bird</td>\n",
       "      <td>523950</td>\n",
       "      <td>168550</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>17.531005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  incident_number animal_group  easting_rounded  northing_rounded  \\\n",
       "0         5363091         Bird           528650            177250   \n",
       "1         7051091         Bird           552350            186750   \n",
       "2         9252091         Bird           529750            176650   \n",
       "3        13245091         Bird           519350            190750   \n",
       "4        21760091         Bird           529750            180850   \n",
       "5        26715091         Bird           534750            180650   \n",
       "6        27109091         Bird           531350            161550   \n",
       "7        27898091         Bird           516450            177350   \n",
       "8        28382091         Bird           520950            184850   \n",
       "9        30836091         Bird           523950            168550   \n",
       "\n",
       "   lfb_easting  lfb_northing   distance  \n",
       "0       532066        180010 -63.244164  \n",
       "1       532066        180010  78.892991  \n",
       "2       532066        180010 -65.845336  \n",
       "3       532066        180010  39.306829  \n",
       "4       532066        180010 -79.380757  \n",
       "5       532066        180010 -76.906553  \n",
       "6       532066        180010  54.616543  \n",
       "7       532066        180010  32.580149  \n",
       "8       532066        180010   1.471315  \n",
       "9       532066        180010  17.531005  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pandas_udf(lfb_distance.schema, F.PandasUDFType.GROUPED_MAP)\n",
    "def dist_animal(pdf:pd.DataFrame) -> pd.DataFrame:\n",
    "    distance = pdf.distance\n",
    "    return pdf.assign(distance=((distance - distance.mean()))/ distance.mean() * 100)\n",
    "\n",
    "dist_by_animal = lfb_distance.groupBy('animal_group').apply(dist_animal)\n",
    "dist_by_animal.limit(10).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped Aggregate Pandas UDFs\n",
    "\n",
    "Grouped aggregate Pandas UDFs take in one or more pandas.Series and output a scalar. \n",
    "\n",
    "Grouped aggregate Pandas UDFs are used alongisde the `.groupby()` and `.agg()` functions and are similiar to the Spark `.agg()` function.\n",
    "\n",
    "In the decorator of a grouped aggregate Pandas UDF the first argument is the data type of the output dataframe and the second argument is the UDF type. Below is an example of a grouped aggregate Pandas UDF to find the mean distance travelled by the London Fire Brigade based on the `animal_group`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal_group</th>\n",
       "      <th>mean_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown - Animal rescue from water - Farm animal</td>\n",
       "      <td>29.518494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hedgehog</td>\n",
       "      <td>21.457480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bull</td>\n",
       "      <td>21.059503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deer</td>\n",
       "      <td>19.603281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cow</td>\n",
       "      <td>19.141692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Horse</td>\n",
       "      <td>19.112879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Budgie</td>\n",
       "      <td>18.338150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fish</td>\n",
       "      <td>17.896080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lizard</td>\n",
       "      <td>17.358752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sheep</td>\n",
       "      <td>16.884412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       animal_group  mean_distance\n",
       "0  Unknown - Animal rescue from water - Farm animal      29.518494\n",
       "1                                          Hedgehog      21.457480\n",
       "2                                              Bull      21.059503\n",
       "3                                              Deer      19.603281\n",
       "4                                               Cow      19.141692\n",
       "5                                             Horse      19.112879\n",
       "6                                            Budgie      18.338150\n",
       "7                                              Fish      17.896080\n",
       "8                                            Lizard      17.358752\n",
       "9                                             Sheep      16.884412"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pandas_udf(T.DoubleType(), F.PandasUDFType.GROUPED_AGG)\n",
    "def mean_distance(distance: pd.Series) -> T.DoubleType():\n",
    "    return distance.mean()\n",
    "\n",
    "mean_distance_travelled = (lfb_distance.groupBy('animal_group')\n",
    "      .agg(mean_distance(lfb_distance['distance']).alias('mean_distance'))\n",
    "      .orderBy('mean_distance', ascending = False))\n",
    "\n",
    "mean_distance_travelled.limit(10).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grouped aggregate Pandas UDF can also be used with the PySpark window functions. Each `pandas.Series` in the input represents a group or window. In Spark 2.4, the grouped aggregate UDF does not support partial aggregations with only an unbounded window supported. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_number</th>\n",
       "      <th>animal_group</th>\n",
       "      <th>easting_rounded</th>\n",
       "      <th>northing_rounded</th>\n",
       "      <th>lfb_easting</th>\n",
       "      <th>lfb_northing</th>\n",
       "      <th>distance</th>\n",
       "      <th>mean_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59442121</td>\n",
       "      <td>Unknown - Animal rescue from water - Farm animal</td>\n",
       "      <td>558450</td>\n",
       "      <td>189150</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>27.922304</td>\n",
       "      <td>29.518494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4149</td>\n",
       "      <td>Unknown - Animal rescue from water - Farm animal</td>\n",
       "      <td>552850</td>\n",
       "      <td>175450</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>21.278352</td>\n",
       "      <td>29.518494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>012249-30012019</td>\n",
       "      <td>Unknown - Animal rescue from water - Farm animal</td>\n",
       "      <td>571350</td>\n",
       "      <td>177650</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>39.354825</td>\n",
       "      <td>29.518494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144140091</td>\n",
       "      <td>Hedgehog</td>\n",
       "      <td>510750</td>\n",
       "      <td>177550</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>21.457480</td>\n",
       "      <td>21.457480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165500101</td>\n",
       "      <td>Bull</td>\n",
       "      <td>514650</td>\n",
       "      <td>191850</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>21.059503</td>\n",
       "      <td>21.059503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22442101</td>\n",
       "      <td>Deer</td>\n",
       "      <td>554750</td>\n",
       "      <td>192250</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>25.775598</td>\n",
       "      <td>19.603281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>110531091</td>\n",
       "      <td>Deer</td>\n",
       "      <td>509550</td>\n",
       "      <td>181250</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>22.550119</td>\n",
       "      <td>19.603281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77153091</td>\n",
       "      <td>Deer</td>\n",
       "      <td>507250</td>\n",
       "      <td>179950</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>24.816073</td>\n",
       "      <td>19.603281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>119220091</td>\n",
       "      <td>Deer</td>\n",
       "      <td>541250</td>\n",
       "      <td>159450</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>22.517981</td>\n",
       "      <td>19.603281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>181559091</td>\n",
       "      <td>Deer</td>\n",
       "      <td>555150</td>\n",
       "      <td>192650</td>\n",
       "      <td>532066</td>\n",
       "      <td>180010</td>\n",
       "      <td>26.318067</td>\n",
       "      <td>19.603281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   incident_number                                      animal_group  \\\n",
       "0         59442121  Unknown - Animal rescue from water - Farm animal   \n",
       "1             4149  Unknown - Animal rescue from water - Farm animal   \n",
       "2  012249-30012019  Unknown - Animal rescue from water - Farm animal   \n",
       "3        144140091                                          Hedgehog   \n",
       "4        165500101                                              Bull   \n",
       "5         22442101                                              Deer   \n",
       "6        110531091                                              Deer   \n",
       "7         77153091                                              Deer   \n",
       "8        119220091                                              Deer   \n",
       "9        181559091                                              Deer   \n",
       "\n",
       "   easting_rounded  northing_rounded  lfb_easting  lfb_northing   distance  \\\n",
       "0           558450            189150       532066        180010  27.922304   \n",
       "1           552850            175450       532066        180010  21.278352   \n",
       "2           571350            177650       532066        180010  39.354825   \n",
       "3           510750            177550       532066        180010  21.457480   \n",
       "4           514650            191850       532066        180010  21.059503   \n",
       "5           554750            192250       532066        180010  25.775598   \n",
       "6           509550            181250       532066        180010  22.550119   \n",
       "7           507250            179950       532066        180010  24.816073   \n",
       "8           541250            159450       532066        180010  22.517981   \n",
       "9           555150            192650       532066        180010  26.318067   \n",
       "\n",
       "   mean_distance  \n",
       "0      29.518494  \n",
       "1      29.518494  \n",
       "2      29.518494  \n",
       "3      21.457480  \n",
       "4      21.059503  \n",
       "5      19.603281  \n",
       "6      19.603281  \n",
       "7      19.603281  \n",
       "8      19.603281  \n",
       "9      19.603281  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "w = (Window.partitionBy('animal_group')\n",
    "           .rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing))\n",
    "\n",
    "rescue = (lfb_distance.withColumn('mean_distance', mean_distance(lfb_distance['distance']).over(w))\n",
    "                .orderBy('mean_distance', ascending=False))\n",
    "\n",
    "\n",
    "rescue.limit(10).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "For a more in-depth explaination of what happens under the hood of different types of Pandas UDFs see:\n",
    "- [Big Data is Just a Lot of Small Data: Using pandas UDF part 1](https://freecontent.manning.com/big-data-is-just-a-lot-of-small-data-using-pandas-udf/)\n",
    "- [Big Data is Just a Lot of Small Data: Using pandas UDF part 2](https://freecontent.manning.com/big-data-is-just-a-lot-of-small-data-using-pandas-udf-part-2/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f86e2960ba4043b8d9c398ca8efdccfab76ec7881c4276603dac047a68b75240"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
