{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faker: Synthetic Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction to Faker  \n",
    "`Faker` is a Python package that generates fake data such as names, addresses, emails, dates, credit card numbers, and more. It is similar to [`Mimesis`](../ancillary-topics/mimesis.html), another Python package for synthetic data generation.\n",
    "\n",
    "Faker is widely used for creating realistic test data for software development, data science, and machine learning projects. By generating synthetic data that mimics real-world information, you can test your applications, validate models, and protect sensitive information without exposing real data.\n",
    "\n",
    "This guide will also show how to use Faker with `PySpark` for generating synthetic data at scale, making it suitable for both small and big data applications.\n",
    "\n",
    "**How does Faker work?**\n",
    "\n",
    "Faker uses a modular system of \"providers,\" where each provider is responsible for generating a specific type of data (such as names, addresses, or dates). You can select different locales to generate data that matches the conventions of various countries, making it suitable for international applications. Faker also supports seeding, which allows you to generate reproducible datasets for debugging and testing.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "* Faker supports multiple locales, enabling you to generate data that matches the conventions and formats of different countries and regions.\n",
    "\n",
    "\n",
    "* To ensure reproducibility, Faker allows you to set a random seed. Setting this seed allows us to generate the exact same synthetic data as has been/will be shown in our examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Install and initialise Faker\n",
    "To start, we will need the `Faker` library to generate the dummy data. Additionally, we will use PySpark for working with Spark DataFrames in Python.\n",
    "\n",
    "This guide will also show how to use Faker with PySpark for generating synthetic data at scale, making it suitable for both small and big data applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further details on the Faker package, please visit the [official documentation](https://faker.readthedocs.io/en/master/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Check the version of the Faker package installed in your environment\n",
    "It is worth noting the version of the Faker package installed in your environment. This is important because different versions may have changes in functionality, seeding methods, or compatibility with other packages, which can affect reproducibility and integration with your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faker_version: 37.3.0\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "faker_version = pkg_resources.get_distribution(\"Faker\").version\n",
    "print(f\"faker_version: {faker_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Simple example of using Faker\n",
    "\n",
    "The following example demonstrates how to generate basic synthetic personal data using a seeded Faker instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: William Jennings\n",
      "Email: duncan32@example.net\n",
      "Address: 600 Charlie fort, New Joeside, DT79 0GS\n",
      "Job: Librarian, public\n",
      "Company: Bryan-Andrews\n",
      "Phone: 01314960116\n",
      "Birthday: 1947-08-03\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "\n",
    "# Initialise Faker with a specific locale and seed for reproducibility\n",
    "fake_uk = Faker('en_GB')\n",
    "fake_uk.seed_instance(42)\n",
    "\n",
    "print(\"Name:\", fake_uk.name())\n",
    "print(\"Email:\", fake_uk.email())\n",
    "print(\"Address:\", fake_uk.address().replace(\"\\n\", \", \")) # the address method has new line characters (\\n), hence, replace with \", \" to have all in one line\n",
    "print(\"Job:\", fake_uk.job())\n",
    "print(\"Company:\", fake_uk.company())\n",
    "print(\"Phone:\", fake_uk.phone_number())\n",
    "print(\"Birthday:\", fake_uk.date_of_birth(minimum_age=18, maximum_age=90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each call to a provider method (such as `fake_uk.name()` or `fake_uk.address()`) returns a realistic value that matches the selected locale. By combining different providers, you can quickly build complex and realistic synthetic datasets for your projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Faker localisation\n",
    "\n",
    "Faker has a great feature that allows it to generate data tailored to specific locales. To generate data for a specific country or region, simply pass the desired locale code (such as `'en_GB'` for the UK or `'fr_FR'` for France) as an argument when creating your Faker instance.\n",
    "\n",
    "The example below demonstrates how address formats differ across locales using Faker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US: 7171 Rhonda Squares Apt. 506, Wesleyton, LA 16408\n",
      "UK: 368 Griffiths wall, Lake Michelle, CO4W 7GQ\n",
      "France: 4, rue de Guillot, 48189 RivièreBourg\n",
      "Japan: 東京都中央区一ツ橋12丁目16番18号\n"
     ]
    }
   ],
   "source": [
    "# Create localised Faker instances\n",
    "fake_us = Faker('en_US')\n",
    "fake_uk = Faker('en_GB')\n",
    "fake_fr = Faker('fr_FR')\n",
    "fake_jp = Faker('ja_JP')\n",
    "\n",
    "print(\"US:\", fake_us.address().replace(\"\\n\", \", \"))\n",
    "print(\"UK:\", fake_uk.address().replace(\"\\n\", \", \"))\n",
    "print(\"France:\", fake_fr.address().replace(\"\\n\", \", \"))\n",
    "print(\"Japan:\", fake_jp.address().replace(\"\\n\", \", \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the differences in address formats:\n",
    "\n",
    "* US addresses include state abbreviations and ZIP codes.  \n",
    "* UK addresses use British postal codes.  \n",
    "* France addresses follow European conventions.  \n",
    "* Japan addresses are formatted with the correct characters and local conventions.\n",
    "\n",
    "\n",
    "For an up-to-date list of supported locales, you can check the [official documentation](https://fakerjs.dev/guide/localization.html#available-locales)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Faker’s provider architecture\n",
    "\n",
    "Faker utilises a modular system of \"providers,\" where each provider is responsible for generating a specific type of data. Let's take a closer look at how providers work and the types available by using fake data for the UK locale.\n",
    "\n",
    "\n",
    "The following example lists all available providers for a given Faker instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Faker Providers:\n",
      "- <faker.providers.user_agent.Provider object at 0x000001D7D59674C0>\n",
      "- <faker.providers.ssn.en_GB.Provider object at 0x000001D7D59675B0>\n",
      "- <faker.providers.sbn.Provider object at 0x000001D7D5967550>\n",
      "- <faker.providers.python.Provider object at 0x000001D7D5967400>\n",
      "- <faker.providers.profile.Provider object at 0x000001D7D5967490>\n",
      "- <faker.providers.phone_number.en_GB.Provider object at 0x000001D7D5967340>\n",
      "- <faker.providers.person.en_GB.Provider object at 0x000001D7D59673D0>\n",
      "- <faker.providers.passport.en_US.Provider object at 0x000001D7D5967100>\n",
      "- <faker.providers.misc.en_US.Provider object at 0x000001D7D5967310>\n",
      "- <faker.providers.lorem.la.Provider object at 0x000001D7D59672B0>\n",
      "- <faker.providers.job.en_US.Provider object at 0x000001D7D5967250>\n",
      "- <faker.providers.isbn.en_US.Provider object at 0x000001D7D59671F0>\n",
      "- <faker.providers.internet.en_GB.Provider object at 0x000001D7D5967190>\n",
      "- <faker.providers.geo.en_US.Provider object at 0x000001D7D5966FE0>\n",
      "- <faker.providers.file.Provider object at 0x000001D7D59670D0>\n",
      "- <faker.providers.emoji.Provider object at 0x000001D7D5967070>\n",
      "- <faker.providers.doi.Provider object at 0x000001D7D5967010>\n",
      "- <faker.providers.date_time.en_US.Provider object at 0x000001D7D5966FB0>\n",
      "- <faker.providers.currency.en_US.Provider object at 0x000001D7D5966F50>\n",
      "- <faker.providers.credit_card.en_US.Provider object at 0x000001D7D5966EF0>\n",
      "- <faker.providers.company.en_US.Provider object at 0x000001D7D5966E90>\n",
      "- <faker.providers.color.en_US.Provider object at 0x000001D7D5966E30>\n",
      "- <faker.providers.barcode.en_US.Provider object at 0x000001D7D5966DD0>\n",
      "- <faker.providers.bank.en_GB.Provider object at 0x000001D7D5966D70>\n",
      "- <faker.providers.automotive.en_GB.Provider object at 0x000001D7D5966D10>\n",
      "- <faker.providers.address.en_GB.Provider object at 0x000001D7D5966C80>\n"
     ]
    }
   ],
   "source": [
    "print(\"Available Faker Providers:\")\n",
    "for provider in fake_uk.providers:\n",
    "    print(f\"- {provider}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the list corresponds to a specific provider, such as:\n",
    "\n",
    "- **User Agent Provider:** Generates browser and device identification strings.  \n",
    "- **SSN Provider:** Creates valid-format social security numbers (US-specific).  \n",
    "- **SBN Provider:** Generates 9-digit Standard Book Numbers (used in older systems prior to 1974).  \n",
    "\n",
    "In addition to these, Faker includes other commonly used providers for generating various types of data:\n",
    "\n",
    "- **Person Provider:** Generates names, birthdates, and personal details.  \n",
    "- **Address Provider:** Produces realistic street addresses and postal codes.\n",
    "- **Internet Provider:** Generates email addresses, domain names, and URLs.\n",
    "\n",
    "You can explore the full list of available providers and their methods in the [official documentation](https://faker.readthedocs.io/en/master/providers.html), which offers detailed information and usage examples for each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Best practices for using Faker\n",
    "\n",
    "When working with Faker, keep the following best practices in mind:\n",
    "\n",
    "- Select locale-specific providers when generating data tailored to a particular region.\n",
    "- Combine different providers to generate more realistic and interconnected data.\n",
    "- Organise your fake data generation to align with the requirements of your application.\n",
    "- Explore the official documentation to learn about additional provider features and options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Generating a user profile with multiple Faker providers\n",
    "\n",
    "Now that we are familiar with how to set up Faker and its key features, let's explore how to use it in practice. In the following example, we will build a typical fake dataset using data generated for the UK locale to create user profiles. This will demonstrate how to combine multiple providers to generate rich and interconnected data for more complex structures.\n",
    "\n",
    "\n",
    "The example below shows how to generate a DataFrame of user profiles with multiple attributes using Faker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>email</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>postcode</th>\n",
       "      <th>job</th>\n",
       "      <th>company</th>\n",
       "      <th>username</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William Jennings</td>\n",
       "      <td>35</td>\n",
       "      <td>francisdavidson@example.org</td>\n",
       "      <td>600 Charlie fort</td>\n",
       "      <td>New Joeside</td>\n",
       "      <td>DT79 0GS</td>\n",
       "      <td>Librarian, public</td>\n",
       "      <td>Bryan-Andrews</td>\n",
       "      <td>timothy16</td>\n",
       "      <td>http://butler-gough.info/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benjamin Simpson</td>\n",
       "      <td>42</td>\n",
       "      <td>fisherteresa@example.net</td>\n",
       "      <td>Studio 31 Irene forks</td>\n",
       "      <td>Jasonbury</td>\n",
       "      <td>S4 5GQ</td>\n",
       "      <td>Marine scientist</td>\n",
       "      <td>Davies Ltd</td>\n",
       "      <td>johnronald</td>\n",
       "      <td>http://www.lamb-scott.co.uk/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ricky Lloyd-Duncan</td>\n",
       "      <td>67</td>\n",
       "      <td>wilsonryan@example.com</td>\n",
       "      <td>Flat 13K Kelly parks</td>\n",
       "      <td>Youngmouth</td>\n",
       "      <td>M23 9SY</td>\n",
       "      <td>Oceanographer</td>\n",
       "      <td>Lloyd-Turner</td>\n",
       "      <td>dgreen</td>\n",
       "      <td>http://www.walsh.biz/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr Jasmine Smith</td>\n",
       "      <td>53</td>\n",
       "      <td>daviesgeoffrey@example.net</td>\n",
       "      <td>Studio 51s Steele alley</td>\n",
       "      <td>Donnaburgh</td>\n",
       "      <td>E4W 2QG</td>\n",
       "      <td>Solicitor, Scotland</td>\n",
       "      <td>Bell, Anderson and Jones</td>\n",
       "      <td>murraymohammad</td>\n",
       "      <td>http://www.shaw.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norman Sharp-Stewart</td>\n",
       "      <td>52</td>\n",
       "      <td>scottknowles@example.net</td>\n",
       "      <td>89 Arnold plains</td>\n",
       "      <td>Lake Graeme</td>\n",
       "      <td>SG57 1JJ</td>\n",
       "      <td>Bonds trader</td>\n",
       "      <td>Brown-Naylor</td>\n",
       "      <td>thomashammond</td>\n",
       "      <td>http://www.howe.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  age                        email  \\\n",
       "0      William Jennings   35  francisdavidson@example.org   \n",
       "1      Benjamin Simpson   42     fisherteresa@example.net   \n",
       "2    Ricky Lloyd-Duncan   67       wilsonryan@example.com   \n",
       "3      Dr Jasmine Smith   53   daviesgeoffrey@example.net   \n",
       "4  Norman Sharp-Stewart   52     scottknowles@example.net   \n",
       "\n",
       "                    street         city  postcode                  job  \\\n",
       "0         600 Charlie fort  New Joeside  DT79 0GS    Librarian, public   \n",
       "1    Studio 31 Irene forks    Jasonbury    S4 5GQ     Marine scientist   \n",
       "2     Flat 13K Kelly parks   Youngmouth   M23 9SY        Oceanographer   \n",
       "3  Studio 51s Steele alley   Donnaburgh   E4W 2QG  Solicitor, Scotland   \n",
       "4         89 Arnold plains  Lake Graeme  SG57 1JJ         Bonds trader   \n",
       "\n",
       "                    company        username                       website  \n",
       "0             Bryan-Andrews       timothy16     http://butler-gough.info/  \n",
       "1                Davies Ltd      johnronald  http://www.lamb-scott.co.uk/  \n",
       "2              Lloyd-Turner          dgreen         http://www.walsh.biz/  \n",
       "3  Bell, Anderson and Jones  murraymohammad          http://www.shaw.com/  \n",
       "4              Brown-Naylor   thomashammond          http://www.howe.com/  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "fake_uk = Faker('en_GB')\n",
    "fake_uk.seed_instance(42)\n",
    "\n",
    "n_rows = 100\n",
    "\n",
    "\n",
    "def generate_user_profile():\n",
    "    \"\"\" Function to generate a user profile \"\"\"\n",
    "    return {\n",
    "        'name': fake_uk.name(),\n",
    "        'age': fake_uk.random_int(min=18, max=80),\n",
    "        'email': fake_uk.email(),\n",
    "        \n",
    "        'street': fake_uk.street_address().replace(\"\\n\", \" \"),\n",
    "        'city': fake_uk.city(),\n",
    "        'postcode': fake_uk.postcode(),\n",
    "        \n",
    "        'job': fake_uk.job(),\n",
    "        'company': fake_uk.company(),\n",
    "        \n",
    "        'username': fake_uk.user_name(),\n",
    "        'website': fake_uk.url()\n",
    "    }\n",
    " \n",
    "profiles = [generate_user_profile() for _ in range(n_rows)]\n",
    " \n",
    "df = pd.DataFrame(profiles)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Using synthetic data with big data frameworks\n",
    "\n",
    "Generating synthetic data at scale is essential for testing big data pipelines, validating distributed systems, and simulating real-world scenarios. In this section, we provide two worked examples of using Faker with PySpark: the first demonstrates a simple integration, while the second adds additional features to reflect more realistic and complex datasets.\n",
    "\n",
    "#### 7.1. Using synthetic data with PySpark\n",
    "\n",
    "Demonstrate how to create synthetic data in PySpark and use it within Spark DataFrames.\n",
    "\n",
    "\n",
    "The following example shows how to generate a simple synthetic dataset and load it into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfaker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Faker\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal[2]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSynthetic Data Example\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Check if in virtual environment\u001b[39;00m\n\u001b[0;32m      9\u001b[0m is_in_venv \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVIRTUAL_ENV\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\dapcats_guidance\\ons-spark\\.venv\\lib\\site-packages\\pyspark\\sql\\session.py:556\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    554\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[1;32md:\\dapcats_guidance\\ons-spark\\.venv\\lib\\site-packages\\pyspark\\core\\context.py:523\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 523\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[1;32md:\\dapcats_guidance\\ons-spark\\.venv\\lib\\site-packages\\pyspark\\core\\context.py:205\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m     )\n\u001b[1;32m--> 205\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    208\u001b[0m         master,\n\u001b[0;32m    209\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    220\u001b[0m     )\n",
      "File \u001b[1;32md:\\dapcats_guidance\\ons-spark\\.venv\\lib\\site-packages\\pyspark\\core\\context.py:444\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 444\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[1;32md:\\dapcats_guidance\\ons-spark\\.venv\\lib\\site-packages\\pyspark\\java_gateway.py:108\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m--> 108\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkRuntimeError(\n\u001b[0;32m    112\u001b[0m         errorClass\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJAVA_GATEWAY_EXITED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    113\u001b[0m         messageParameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    114\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# !pip install pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from faker import Faker\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"Synthetic Data Example\").getOrCreate()\n",
    "\n",
    "# Check if in virtual environment\n",
    "is_in_venv = os.getenv('VIRTUAL_ENV') is not None\n",
    "\n",
    "fake_uk = Faker('en_GB')\n",
    "fake_uk.seed_instance(42)\n",
    "\n",
    "n_rows = 1000\n",
    "\n",
    "data = [\n",
    "    (\n",
    "        fake_uk.name(),\n",
    "        fake_uk.address().replace(\"\\n\", \", \"), \n",
    "        fake_uk.email()\n",
    "    ) \n",
    "    for _ in range(n_rows)\n",
    "    ]\n",
    "\n",
    "columns = [\"Name\", \"Address\", \"Email\"]\n",
    "\n",
    "if not is_in_venv:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: spark.createDataFrame\")\n",
    "    df_spark = spark.createDataFrame(data, schema=columns)\n",
    "else:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: Pandas DataFrame -> CSV -> Spark DataFrame\")\n",
    "    df_pd = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    file_path = \"personal_data_temp.csv\"\n",
    "    df_pd.to_csv(file_path, index=False)\n",
    "    df_spark = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "df_spark.show(5)\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application to Big Data:**\n",
    "\n",
    "This example can be extended to generate large datasets (millions of records) that can be processed in parallel using PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Generate synthetic data with more features\n",
    "\n",
    "While Faker provides a wide range of data types, it may not cover every feature you need for your use case. In this example, we combine Faker-generated data with custom-created features (such as mode of transport, education level, etc.) to build a more comprehensive and realistic dataset.\n",
    "\n",
    "\n",
    "This example demonstrates how to generate a more complex synthetic dataset with additional categorical features and missing values, and load it directly into a Spark DataFrame.\n",
    "\n",
    "We will generate synthetic data with the following additional features:\n",
    "1. Mode of Transportation (Car, Public Transport, Walking, etc.)  \n",
    "2. Highest Education (High School, Bachelor's, Master's, PhD, etc.)  \n",
    "3. Marital Status (Single, Married, Divorced, Widowed)  \n",
    "4. Favorite High Street Supermarket (Tesco, Sainsbury's, Asda, etc.)  \n",
    "5. Pet Ownership (Yes, No - with type of pet if Yes)  \n",
    "\n",
    "We will also simulate some missing data in the dataset, which is commonly encountered in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>City</th>\n",
       "      <th>Email</th>\n",
       "      <th>Mode_of_Transport</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Supermarket</th>\n",
       "      <th>Pet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William Jennings</td>\n",
       "      <td>2 Sian streets, New Maryton, E3 8ZA</td>\n",
       "      <td>L8G 7YL</td>\n",
       "      <td>Port Samchester</td>\n",
       "      <td>ricky23@example.com</td>\n",
       "      <td>Car</td>\n",
       "      <td>None</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr Josh Pritchard</td>\n",
       "      <td>Studio 16, Lynn hill, Melissaborough, BR0X 4DJ</td>\n",
       "      <td>S4 5GQ</td>\n",
       "      <td>Rhysview</td>\n",
       "      <td>johnronald@example.net</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>High School</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Morrisons</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leigh Randall</td>\n",
       "      <td>0 Alexander circles, New Guy, W67 4FJ</td>\n",
       "      <td>NW8M 9RQ</td>\n",
       "      <td>East Natasha</td>\n",
       "      <td>dgreen@example.org</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lorraine Palmer</td>\n",
       "      <td>Studio 01, Read junctions, West Tracyburgh, AB...</td>\n",
       "      <td>MK9H 5GX</td>\n",
       "      <td>New Brandonfort</td>\n",
       "      <td>griffithslinda@example.com</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Married</td>\n",
       "      <td>Waitrose</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>June Sharp</td>\n",
       "      <td>782 Hill rest, Arnoldside, SM3Y 6QT</td>\n",
       "      <td>W1D 1PA</td>\n",
       "      <td>New Gerald</td>\n",
       "      <td>hammondjulia@example.org</td>\n",
       "      <td>Public Transport</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Single</td>\n",
       "      <td>Asda</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                                            Address  \\\n",
       "0   William Jennings                2 Sian streets, New Maryton, E3 8ZA   \n",
       "1  Dr Josh Pritchard     Studio 16, Lynn hill, Melissaborough, BR0X 4DJ   \n",
       "2      Leigh Randall              0 Alexander circles, New Guy, W67 4FJ   \n",
       "3    Lorraine Palmer  Studio 01, Read junctions, West Tracyburgh, AB...   \n",
       "4         June Sharp                782 Hill rest, Arnoldside, SM3Y 6QT   \n",
       "\n",
       "   Postcode             City                       Email Mode_of_Transport  \\\n",
       "0   L8G 7YL  Port Samchester         ricky23@example.com               Car   \n",
       "1    S4 5GQ         Rhysview      johnronald@example.net  Public Transport   \n",
       "2  NW8M 9RQ     East Natasha          dgreen@example.org  Public Transport   \n",
       "3  MK9H 5GX  New Brandonfort  griffithslinda@example.com  Public Transport   \n",
       "4   W1D 1PA       New Gerald    hammondjulia@example.org  Public Transport   \n",
       "\n",
       "     Education Marital_Status Supermarket   Pet  \n",
       "0         None        Widowed       Tesco   Cat  \n",
       "1  High School        Widowed   Morrisons   Cat  \n",
       "2          PhD        Married        None  None  \n",
       "3      Primary        Married    Waitrose  None  \n",
       "4      Primary         Single        Asda   Dog  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from faker import Faker\n",
    "from faker.generator import random\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialise Spark session\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"SyntheticDataForBigData\").getOrCreate()\n",
    "\n",
    "# Check if in virtual environment\n",
    "is_in_venv = os.getenv('VIRTUAL_ENV') is not None\n",
    "\n",
    "fake_uk = Faker('en_GB')\n",
    "fake_uk.seed_instance(42)\n",
    "\n",
    "n_samples = 1000   \n",
    "\n",
    "# Create lists of categories for features not captured in the Faker library\n",
    "mode_of_transport = ['Car', 'Public Transport', 'Walking', 'Cycling', 'Taxi']\n",
    "education_levels = ['Primary', 'High School', 'Vocational', 'Bachelor\\'s', 'Master\\'s', 'PhD']\n",
    "marital_status = ['Single', 'Married', 'Divorced', 'Widowed']\n",
    "supermarkets = ['Tesco', 'Sainsbury\\'s', 'Asda', 'Morrisons', 'Waitrose']\n",
    "pets = ['Dog', 'Cat', 'None']\n",
    "\n",
    "# Generate synthetic data with the new features\n",
    "data = []\n",
    "for _ in range(n_samples):\n",
    "    name = fake_uk.name()\n",
    "    address = fake_uk.address()\n",
    "    postcode = fake_uk.postcode()\n",
    "    city = fake_uk.city()\n",
    "    email = fake_uk.email()\n",
    "    transport = fake_uk.random_element(mode_of_transport)\n",
    "    education = fake_uk.random_element(education_levels)\n",
    "    marital = fake_uk.random_element(marital_status)\n",
    "    supermarket = fake_uk.random_element(supermarkets)\n",
    "    pet = fake_uk.random_element(pets)\n",
    "    \n",
    "    # Simulating missing data by randomly omitting some features\n",
    "    if random.random() < 0.1:\n",
    "        transport = None\n",
    "    if random.random() < 0.1:\n",
    "        education = None\n",
    "    if random.random() < 0.1:\n",
    "        marital = None\n",
    "    if random.random() < 0.1:\n",
    "        supermarket = None\n",
    "    if random.random() < 0.1:\n",
    "        pet = None\n",
    "        \n",
    "    data.append([name, address, postcode, city, email, transport, education, marital, supermarket, pet])\n",
    "\n",
    "\n",
    "columns = ['Name', 'Address', 'Postcode', 'City', 'Email', 'Mode_of_Transport', 'Education', 'Marital_Status', 'Supermarket', 'Pet']\n",
    "\n",
    "if not is_in_venv:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: spark.createDataFrame\")\n",
    "    synthetic_spark_df = spark.createDataFrame(data, schema=columns)\n",
    "else:\n",
    "    print(f\"is_in_venv: {is_in_venv} | Spark DataFrame to be created from: Pandas DataFrame -> CSV -> Spark DataFrame\")\n",
    "    df_pd = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    file_path = \"synthetic_data_temp.csv\"\n",
    "    df_pd.to_csv(file_path, index=False)\n",
    "    synthetic_spark_df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "synthetic_spark_df.show(5)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Generating synthetic data is a crucial tool for testing algorithms, saving resources, and maintaining privacy. Faker offers various providers to generate synthetic data on Python and big data frameworks like `PySpark`  can help handle large datasets efficiently.\n",
    "\n",
    "\n",
    "### References and further reading\n",
    "* [Faker Documentation (Python)](https://faker.readthedocs.io/en/master/)\n",
    "* [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/index.html)\n",
    "* [Synthpop: Synthetic Data in R](../ancillary-topics/synthpop_with_r)\n",
    "* [Mimesis: Synthetic Data in Python](../ancillary-topics/mimesis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
