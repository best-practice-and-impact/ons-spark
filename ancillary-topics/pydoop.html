
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Pydoop: HDFS to pandas &#8212; Spark at the ONS</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Naming Conflicts in Module Imports" href="module-imports.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-95MGHSRD0S"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-95MGHSRD0S');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Spark at the ONS</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Introduction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Spark overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-overview/spark-start.html">
   Getting Started with Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-overview/when-to-use-spark.html">
   When To Use Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-overview/spark-session-guidance.html">
   Guidance on Spark Sessions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-overview/example-spark-sessions.html">
   Example Spark Sessions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-overview/spark-defaults.html">
   Configuration Hierarchy and
   <code class="docutils literal notranslate">
    <span class="pre">
     spark-defaults.conf
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-overview/data-types.html">
   Data Types in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-overview/creating-dataframes.html">
   Creating DataFrames Manually
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-overview/data-storage.html">
   Data Storage
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to PySpark
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../pyspark-intro/pyspark-intro.html">
   Introduction to PySpark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pyspark-intro/reading-data-pyspark.html">
   Reading Data in PySpark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pyspark-intro/returning-data.html">
   Returning Data from Cluster to Driver
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pyspark-intro/f-col.html">
   Reference columns by name:
   <code class="docutils literal notranslate">
    <span class="pre">
     F.col()
    </span>
   </code>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to sparklyr
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../sparklyr-intro/sparklyr-intro.html">
   Introduction to sparklyr
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sparklyr-intro/reading-data-sparklyr.html">
   Reading Data in sparklyr
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sparklyr-intro/sparklyr-functions.html">
   Using Spark functions in sparklyr
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Spark functions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-functions/union-dataframes-with-different-columns.html">
   Union two DataFrames with different columns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-functions/padding.html">
   Add leading zeros with
   <code class="docutils literal notranslate">
    <span class="pre">
     lpad()
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-functions/sampling.html">
   Sampling:
   <code class="docutils literal notranslate">
    <span class="pre">
     .sample()
    </span>
   </code>
   and
   <code class="docutils literal notranslate">
    <span class="pre">
     sdf_sample()
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-functions/pivot-tables.html">
   Pivot tables in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-functions/rounding.html">
   Rounding differences in Python, R and Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-functions/window-functions.html">
   Window Functions in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-functions/cross-joins.html">
   Cross Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-functions/arrays.html">
   Arrays Functions in PySpark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-functions/writing-data.html">
   Writing Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-functions/job-description.html">
   Set Spark Job Description
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Understanding and Optimising Spark
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-concepts/optimisation-tips.html">
   Ideas for optimising Spark code
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-concepts/spark-application-and-ui.html">
   Spark Application and UI
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-concepts/shuffling.html">
   Shuffling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-concepts/join-concepts.html">
   Optimising Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-concepts/salted-joins.html">
   Salted Joins
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-concepts/partitions.html">
   Managing Partitions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-concepts/persistence.html">
   Persisting in Spark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-concepts/cache.html">
   Caching
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../raw-notebooks/checkpoint-staging/checkpoint-staging.html">
   Checkpoint
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-concepts/garbage-collection.html">
   Garbage Collection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-concepts/df-order.html">
   Spark DataFrames Are Not Ordered
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../spark-concepts/exercises.html">
   Exercises
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Testing and Debugging
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../testing-debugging/spark-errors.html">
   Understanding and Handling Spark Errors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../testing-debugging/unit-testing.html">
   Unit Testing in Spark
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Ancillary Topics
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="visualisation.html">
   Spark and Visualisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-imports.html">
   Naming Conflicts in Module Imports
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Pydoop: HDFS to pandas
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ancillary-topics/pydoop.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/best-practice-and-impact/ons-spark"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/best-practice-and-impact/ons-spark/issues/new?title=Issue%20on%20page%20%2Fancillary-topics/pydoop.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/best-practice-and-impact/ons-spark/main?urlpath=tree/docs/ancillary-topics/pydoop.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pydoop-setup">
   Pydoop Setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reading-files">
   Reading files
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#writing-files">
   Writing files
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#other-useful-functions">
   Other Useful Functions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#isfile-isdir-and-ls-see-if-a-file-directory-exists-and-list-files">
     <code class="docutils literal notranslate">
      <span class="pre">
       isfile()
      </span>
     </code>
     ,
     <code class="docutils literal notranslate">
      <span class="pre">
       isdir()
      </span>
     </code>
     and
     <code class="docutils literal notranslate">
      <span class="pre">
       ls()
      </span>
     </code>
     : See if a file/directory exists and list files
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#getsize-file-size-in-bytes">
     <code class="docutils literal notranslate">
      <span class="pre">
       getsize()
      </span>
     </code>
     : File size in bytes
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#limitations">
   Limitations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-resources">
   Further Resources
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="pydoop-hdfs-to-pandas">
<h1>Pydoop: HDFS to pandas<a class="headerlink" href="#pydoop-hdfs-to-pandas" title="Permalink to this headline">¶</a></h1>
<p>The usual way to interact with data stored in the Hadoop Distributed File System (HDFS) is to use Spark.</p>
<p>Some datasets are small enough that they can be easily handled with pandas. One method is to start a Spark session, read in the data as PySpark DataFrame with <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameReader.csv.html"><code class="docutils literal notranslate"><span class="pre">spark.read.csv()</span></code></a>, then convert to a pandas DataFrame with <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.toPandas.html"><code class="docutils literal notranslate"><span class="pre">.toPandas()</span></code></a>.</p>
<p>The <a class="reference external" href="https://crs4.github.io/pydoop/">Pydoop</a>
package allows you to bypass Spark and read in the data directly to a pandas DataFrame. Remember that your data will have to be able to fit into the driver memory, so do not use this for big datasets. Guidance on when to use Spark and when to consider alternatives is in the <a class="reference internal" href="../spark-overview/when-to-use-spark.html"><span class="doc std std-doc">When To Use Spark</span></a> article.</p>
<div class="section" id="pydoop-setup">
<h2>Pydoop Setup<a class="headerlink" href="#pydoop-setup" title="Permalink to this headline">¶</a></h2>
<p>Pydoop can be installed in the same way as any other package, e.g. with <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">pydoop</span></code>. If using CDSW you need to use <code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span></code> to ensure that Python 3 is being used.</p>
<p>Then import <code class="docutils literal notranslate"><span class="pre">hdfs</span></code> from Pydoop, as well as pandas; note that PySpark is not being imported:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pydoop.hdfs</span> <span class="k">as</span> <span class="nn">hdfs</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="reading-files">
<h2>Reading files<a class="headerlink" href="#reading-files" title="Permalink to this headline">¶</a></h2>
<p>This example will use a CSV stored in the ONS training area on HDFS. You can read in other file types that are supported by pandas, e.g. <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html">json</a> or <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html">Excel</a>.</p>
<p>Reading in the data is then a two stage process; first open the file with <code class="docutils literal notranslate"><span class="pre">hdfs.open()</span></code>, then read in as a pandas DataFrame with <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"><code class="docutils literal notranslate"><span class="pre">pd.read_csv()</span></code></a>. If a <code class="docutils literal notranslate"><span class="pre">with</span></code> statement is used you do not need to explicitly close the file with <code class="docutils literal notranslate"><span class="pre">f.close()</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">file_path</span> <span class="o">=</span> <span class="s2">&quot;/training/animal_rescue.csv&quot;</span>
<span class="k">with</span> <span class="n">hdfs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pandas_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">pandas_df</span></code> is now a pandas DataFrame loaded in the driver memory and all the usual methods will work.</p>
<p>e.g. we can preview the first five rows and columns of the DataFrame with <a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html"><code class="docutils literal notranslate"><span class="pre">.iloc</span></code></a> and <a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html"><code class="docutils literal notranslate"><span class="pre">.head()</span></code></a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pandas_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>IncidentNumber</th>
      <th>DateTimeOfCall</th>
      <th>CalYear</th>
      <th>FinYear</th>
      <th>TypeOfIncident</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>139091</td>
      <td>01/01/2009 03:01</td>
      <td>2009</td>
      <td>2008/09</td>
      <td>Special Service</td>
    </tr>
    <tr>
      <th>1</th>
      <td>275091</td>
      <td>01/01/2009 08:51</td>
      <td>2009</td>
      <td>2008/09</td>
      <td>Special Service</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2075091</td>
      <td>04/01/2009 10:07</td>
      <td>2009</td>
      <td>2008/09</td>
      <td>Special Service</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2872091</td>
      <td>05/01/2009 12:27</td>
      <td>2009</td>
      <td>2008/09</td>
      <td>Special Service</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3553091</td>
      <td>06/01/2009 15:23</td>
      <td>2009</td>
      <td>2008/09</td>
      <td>Special Service</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Get count of rows and columns with <a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html"><code class="docutils literal notranslate"><span class="pre">.shape()</span></code></a>; as we are in pandas not Spark the concept of lazy evaluation does not apply:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pandas_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(5898, 26)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="writing-files">
<h2>Writing files<a class="headerlink" href="#writing-files" title="Permalink to this headline">¶</a></h2>
<p>You can write files with Pydoop in a similar way to reading them. One advantage of this is that the CSV will be written as one file, whereas using <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameWriter.csv.html"><code class="docutils literal notranslate"><span class="pre">df.write.csv()</span></code></a> in PySpark will <a class="reference internal" href="../spark-functions/writing-data.html"><span class="doc std std-doc">write out a partitioned CSV</span></a>.</p>
<p>Another difference is that CSV files from pandas will have an index written by default, which you may want to remove.</p>
<p>First of all, get the path to write out to; e.g. if using the ONS development and testing environment the following code will get a path to your own user area on HDFS:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">username</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HADOOP_USER_NAME&quot;</span><span class="p">)</span> 
<span class="n">write_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;/user/</span><span class="si">{</span><span class="n">username</span><span class="si">}</span><span class="s2">/rescue_copy.csv&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>Similar to reading, use <code class="docutils literal notranslate"><span class="pre">hdfs.open()</span></code>, then <a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html"><code class="docutils literal notranslate"><span class="pre">.to_csv()</span></code></a>. Importantly, we are using <code class="docutils literal notranslate"><span class="pre">wt</span></code> for the <code class="docutils literal notranslate"><span class="pre">mode</span></code> option when opening the file, where <code class="docutils literal notranslate"><span class="pre">w</span></code> means <code class="docutils literal notranslate"><span class="pre">write</span></code> and <code class="docutils literal notranslate"><span class="pre">t</span></code> means <code class="docutils literal notranslate"><span class="pre">text</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">hdfs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">write_path</span><span class="p">,</span> <span class="s2">&quot;wt&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pandas_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The file will now be stored on HDFS; to check you can read it in, or open it using a user interface such as Hadoop User Experience (HUE).</p>
</div>
<div class="section" id="other-useful-functions">
<h2>Other Useful Functions<a class="headerlink" href="#other-useful-functions" title="Permalink to this headline">¶</a></h2>
<p>Pydoop has lots of functions; see the <a class="reference external" href="https://crs4.github.io/pydoop/index.html">documentation</a> for a full list. A couple of examples are given below.</p>
<div class="section" id="isfile-isdir-and-ls-see-if-a-file-directory-exists-and-list-files">
<h3><code class="docutils literal notranslate"><span class="pre">isfile()</span></code>, <code class="docutils literal notranslate"><span class="pre">isdir()</span></code> and <code class="docutils literal notranslate"><span class="pre">ls()</span></code>: See if a file/directory exists and list files<a class="headerlink" href="#isfile-isdir-and-ls-see-if-a-file-directory-exists-and-list-files" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">hdfs.path.isdir(dir_path)</span></code> will return <code class="docutils literal notranslate"><span class="pre">True</span></code> if a file exists:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hdfs</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">write_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>It returns <code class="docutils literal notranslate"><span class="pre">False</span></code> if the file does not exist:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hdfs</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="s2">&quot;/not/a_file&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>False
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">isdir()</span></code> works in a similar way, but for directories rather than files</p>
<p><code class="docutils literal notranslate"><span class="pre">ls()</span></code> lists files in the specified directory. You may be familiar with the this command from Unix.</p>
</div>
<div class="section" id="getsize-file-size-in-bytes">
<h3><code class="docutils literal notranslate"><span class="pre">getsize()</span></code>: File size in bytes<a class="headerlink" href="#getsize-file-size-in-bytes" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">getsize()</span></code> returns the file size in bytes. For large files, bytes are often not a practical unit to use so you may want to divide it to get it in KB or MB:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">size</span> <span class="o">=</span> <span class="n">hdfs</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">write_path</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.79 MB
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">rm()</span></code> is used to delete files and directories, and is another command you may know from Unix. Be careful, there is no recovery option with this!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hdfs</span><span class="o">.</span><span class="n">rm</span><span class="p">(</span><span class="n">write_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Verify that this has been removed by checking that <code class="docutils literal notranslate"><span class="pre">isfile()</span></code> returns <code class="docutils literal notranslate"><span class="pre">False</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hdfs</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">write_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>False
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="limitations">
<h2>Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline">¶</a></h2>
<p>Remember that your pandas DataFrame is stored in the driver memory, rather than the Spark cluster, so some larger datasets are not able to be read in in this way. You can read in the data using <code class="docutils literal notranslate"><span class="pre">spark.read.csv()</span></code> and then subset the data by filtering or <a class="reference internal" href="../spark-functions/sampling.html"><span class="doc std std-doc">taking a sample</span></a> first, then converting to pandas with <code class="docutils literal notranslate"><span class="pre">.toPandas()</span></code>.</p>
<p>CSV files that are saved from PySpark will often be partitioned, so to use this method you would have to write a loop that reads in all the files in the directory, so in this case you may prefer to read and convert with PySpark first.</p>
<p>This method works for reading in files from a directory on HDFS, but not for Hive tables. In theory you can read the underlying parquet files but it is much easier just to read in using PySpark using <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameReader.table.html"><code class="docutils literal notranslate"><span class="pre">spark.read.table()</span></code></a> then convert with <code class="docutils literal notranslate"><span class="pre">.toPandas</span></code>.</p>
</div>
<div class="section" id="further-resources">
<h2>Further Resources<a class="headerlink" href="#further-resources" title="Permalink to this headline">¶</a></h2>
<p>Spark at the ONS Articles:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../spark-overview/when-to-use-spark.html"><span class="doc std std-doc">When To Use Spark</span></a></p></li>
<li><p><a class="reference internal" href="../spark-functions/writing-data.html"><span class="doc std std-doc">Writing Data</span></a></p></li>
<li><p><a class="reference internal" href="../spark-functions/sampling.html"><span class="doc std std-doc">Sampling</span></a></p></li>
</ul>
<p>PySpark Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameReader.csv.html"><code class="docutils literal notranslate"><span class="pre">spark.read.csv()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.toPandas.html"><code class="docutils literal notranslate"><span class="pre">.toPandas()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameWriter.csv.html"><code class="docutils literal notranslate"><span class="pre">.write.csv()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameReader.table.html"><code class="docutils literal notranslate"><span class="pre">spark.read.table()</span></code></a></p></li>
</ul>
<p>Pydoop Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://crs4.github.io/pydoop/">Pydoop</a></p></li>
</ul>
<p>pandas Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"><code class="docutils literal notranslate"><span class="pre">pd.read_csv()</span></code></a></p></li>
<li><p><a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html"><code class="docutils literal notranslate"><span class="pre">pd.read_json()</span></code></a></p></li>
<li><p><a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html"><code class="docutils literal notranslate"><span class="pre">pd.read_excel()</span></code></a></p></li>
<li><p><a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html"><code class="docutils literal notranslate"><span class="pre">.iloc</span></code></a></p></li>
<li><p><a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html"><code class="docutils literal notranslate"><span class="pre">.head()</span></code></a></p></li>
<li><p><a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html"><code class="docutils literal notranslate"><span class="pre">.shape()</span></code></a></p></li>
<li><p><a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html"><code class="docutils literal notranslate"><span class="pre">.to_csv()</span></code></a></p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ancillary-topics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="module-imports.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Naming Conflicts in Module Imports</p>
        </div>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Wil Roberts & Adrian Prince<br/>
        
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>