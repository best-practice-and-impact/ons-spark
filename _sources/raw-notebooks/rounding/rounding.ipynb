{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rounding differences in Python, R and Spark\n",
    "\n",
    "Python, R and Spark have different ways of rounding numbers which end in $.5$; Python and R round to the **nearest even integer** (sometimes called *bankers rounding*), whereas Spark will round **away from zero** (up in the conventional mathematical way for positive numbers, and round down for negative numbers), in the same way as in Excel.\n",
    "\n",
    "This can be confusing when using PySpark and sparklyr if you are used to the behaviour in Python and R.\n",
    "\n",
    "### Comparison of rounding methods\n",
    "\n",
    "Create a DataFrame with numbers all ending in `.5`, both positive and negative, using [`spark.range()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.range.html)/[`sdf_seq()`](https://spark.rstudio.com/packages/sparklyr/latest/reference/sdf_seq.html) and then dividing the `id` column by `2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|half_id|\n",
      "+-------+\n",
      "|   -3.5|\n",
      "|   -2.5|\n",
      "|   -1.5|\n",
      "|   -0.5|\n",
      "|    0.5|\n",
      "|    1.5|\n",
      "|    2.5|\n",
      "|    3.5|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "spark = (SparkSession.builder.master(\"local[2]\")\n",
    "         .appName(\"rounding\")\n",
    "         .getOrCreate())\n",
    "\n",
    "sdf = spark.range(-7, 8, 2).select((F.col(\"id\") / 2).alias(\"half_id\"))\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "library(sparklyr)\n",
    "library(dplyr)\n",
    "\n",
    "sc <- sparklyr::spark_connect(\n",
    "    master = \"local[2]\",\n",
    "    app_name = \"rounding\",\n",
    "    config = sparklyr::spark_config())\n",
    "\n",
    "sdf <- sparklyr:::sdf_seq(sc, -7, 8, 2) %>%\n",
    "    sparklyr::mutate(half_id = id / 2) %>%\n",
    "    sparklyr::select(half_id)\n",
    "    \n",
    "sdf %>%\n",
    "    sparklyr::collect() %>%\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round using Spark with [`F.round()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.round.html)/[`round()`](https://spark.apache.org/docs/latest/api/sql/index.html#round); this will round away from zero (up for positive numbers and down for negative):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>half_id</th>\n",
       "      <th>spark_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.5</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.5</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   half_id  spark_round\n",
       "0     -3.5         -4.0\n",
       "1     -2.5         -3.0\n",
       "2     -1.5         -2.0\n",
       "3     -0.5         -1.0\n",
       "4      0.5          1.0\n",
       "5      1.5          2.0\n",
       "6      2.5          3.0\n",
       "7      3.5          4.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = sdf.withColumn(\"spark_round\", F.round(\"half_id\"))\n",
    "sdf.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "sdf <- sdf %>%\n",
    "    sparklyr::mutate(spark_round = round(half_id))\n",
    "\n",
    "sdf %>%\n",
    "    sparklyr::collect() %>%\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try using Python/R; this will use the bankers method of rounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>half_id</th>\n",
       "      <th>spark_round</th>\n",
       "      <th>python_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.5</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   half_id  spark_round  python_round\n",
       "0     -3.5         -4.0          -4.0\n",
       "1     -2.5         -3.0          -2.0\n",
       "2     -1.5         -2.0          -2.0\n",
       "3     -0.5         -1.0          -0.0\n",
       "4      0.5          1.0           0.0\n",
       "5      1.5          2.0           2.0\n",
       "6      2.5          3.0           2.0\n",
       "7      3.5          4.0           4.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = sdf.toPandas()\n",
    "pdf[\"python_round\"] = round(pdf[\"half_id\"], 0)\n",
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "tdf <- sdf %>%\n",
    "    sparklyr::collect() %>%\n",
    "    sparklyr::mutate(r_round = round(half_id)) %>%\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two methods have returned different results, despite both using functions named `round()`.\n",
    "\n",
    "Just like in Python, pandas and numpy also use bankers rounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>half_id</th>\n",
       "      <th>spark_round</th>\n",
       "      <th>python_round</th>\n",
       "      <th>pd_round</th>\n",
       "      <th>np_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.5</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   half_id  spark_round  python_round  pd_round  np_round\n",
       "0     -3.5         -4.0          -4.0      -4.0      -4.0\n",
       "1     -2.5         -3.0          -2.0      -2.0      -2.0\n",
       "2     -1.5         -2.0          -2.0      -2.0      -2.0\n",
       "3     -0.5         -1.0          -0.0      -0.0      -0.0\n",
       "4      0.5          1.0           0.0       0.0       0.0\n",
       "5      1.5          2.0           2.0       2.0       2.0\n",
       "6      2.5          3.0           2.0       2.0       2.0\n",
       "7      3.5          4.0           4.0       4.0       4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[\"pd_round\"] = pdf[\"half_id\"].round()\n",
    "pdf[\"np_round\"] = np.round(pdf[\"half_id\"])\n",
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the Python and R style of bankers rounding in Spark with [`F.bround()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bround.html)/[`bround()`](https://spark.apache.org/docs/latest/api/sql/index.html#bround):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>half_id</th>\n",
       "      <th>spark_round</th>\n",
       "      <th>spark_bround</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.5</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   half_id  spark_round  spark_bround\n",
       "0     -3.5         -4.0          -4.0\n",
       "1     -2.5         -3.0          -2.0\n",
       "2     -1.5         -2.0          -2.0\n",
       "3     -0.5         -1.0           0.0\n",
       "4      0.5          1.0           0.0\n",
       "5      1.5          2.0           2.0\n",
       "6      2.5          3.0           2.0\n",
       "7      3.5          4.0           4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = sdf.withColumn(\"spark_bround\", F.bround(\"half_id\"))\n",
    "sdf.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "sdf <- sdf %>%\n",
    "    sparklyr::mutate(spark_bround = bround(half_id))\n",
    "\n",
    "sdf %>%\n",
    "    sparklyr::collect() %>%\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other information on rounding\n",
    "\n",
    "#### UDFs and `spark_apply()`\n",
    "\n",
    "[User Defined Functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.udf.html) (UDFs) in Python, and R code ran on the Spark cluster with [`spark_apply()`](https://spark.rstudio.com/packages/sparklyr/latest/reference/spark_apply.html) will use bankers rounding, in common with Python and R.\n",
    "\n",
    "#### Python 2\n",
    " \n",
    "The rounding method changed to bankers rounding in Python 3. In Python 2, it used the round away from zero method, the same as Spark. It is strongly recommended to use Python 3 for any new code development. Spark 3 has dropped support for Python 2.\n",
    "\n",
    "#### Other common software\n",
    "\n",
    "Both Excel and SPSS Statistics use the Spark method of rounding away from zero. If you are new to coding and are learning Python or R predominately to use Spark, be careful when using regular Python or R functions.\n",
    "\n",
    "#### Testing\n",
    "\n",
    "Given that there are different ways of rounding depending on the language used, it is a good idea to thoroughly [unit test](../testing-debugging/unit-testing) your functions to ensure that they behave as expected.\n",
    "\n",
    "### Further Resources\n",
    "\n",
    "Spark at the ONS Articles:\n",
    "- [Unit Testing in Spark](../testing-debugging/unit-testing)\n",
    "\n",
    "PySpark Documentation:\n",
    "- [`spark.range()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.range.html)\n",
    "- [`F.round()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.round.html)\n",
    "- [`F.bround()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.bround.html)\n",
    "- [User Defined Functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.udf.html) \n",
    "\n",
    "sparklyr Documentation:\n",
    "- [`sdf_seq()`](https://spark.rstudio.com/packages/sparklyr/latest/reference/sdf_seq.html)\n",
    "- [`spark_apply()`](https://spark.rstudio.com/packages/sparklyr/latest/reference/spark_apply.html)\n",
    "\n",
    "Spark SQL Documentation:\n",
    "- [`round`](https://spark.apache.org/docs/latest/api/sql/index.html#round)\n",
    "- [`bround`](https://spark.apache.org/docs/latest/api/sql/index.html#bround)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
