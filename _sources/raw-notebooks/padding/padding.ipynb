{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add leading zeros with `lpad()`\n",
    "\n",
    "There are some datasets that consist of code columns, which are fixed width and are stored as strings even though they look like numbers. For instance, the data might have values such as `\"000123\"` and `\"456789\"`.\n",
    "\n",
    "However, sometimes these can appear as integers which will lose the initial zeros. So `\"000123\"` becomes `123`. Commonly this can happen if at some point the data is manipulated in Excel and later read in a CSV file; it can also happen if the column is converted to a numeric type. An ONS example is [Standard Industrial Classification (SIC)](https://www.ons.gov.uk/methodology/classificationsandstandards/ukstandardindustrialclassificationofeconomicactivities/uksic2007). SIC codes are five digits, but some begin with $0$.\n",
    "\n",
    "There is an easy way to change this back into the correct format: [`F.lpad()`](https://spark.apache.org/docs/latest/api/python//reference/api/pyspark.sql.functions.lpad.html) from the `functions` package in PySpark and [`lpad()`](https://spark.apache.org/docs/latest/api/sql/index.html#lpad) inside `mutate()` in sparklyr. This will add a string that you specify to the start, making every value a fixed width string. For instance, `\"123\"` becomes `\"000123\"` but `\"456789\"` remains the same.\n",
    "\n",
    "### Example: Incident Numbers\n",
    "\n",
    "The Animal Rescue data has an `incident_number` column, which is unique and of variable length. We will add leading zeros to this column to make it of a consistent length.\n",
    "\n",
    "First, start a Spark session and read in the Animal Rescue data, filter on `Police` and select the relevant columns (note that the output displayed is for PySpark; the sparklyr output may be formatted slightly differently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+\n",
      "|incident_number|origin_of_call|\n",
      "+---------------+--------------+\n",
      "|      146647151|        Police|\n",
      "|       66969111|        Police|\n",
      "|      103407111|        Police|\n",
      "|      137525091|        Police|\n",
      "|      158794091|        Police|\n",
      "+---------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"padding\").getOrCreate()\n",
    "\n",
    "with open(\"../../../config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "rescue_path = config[\"rescue_path\"]\n",
    "rescue = (spark.read.parquet(rescue_path)\n",
    "          .filter(F.col(\"origin_of_call\") == \"Police\")\n",
    "          .orderBy(\"date_time_of_call\")\n",
    "          .select(\"incident_number\", \"origin_of_call\"))\n",
    "rescue.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "library(sparklyr)\n",
    "\n",
    "sc <- sparklyr::spark_connect(\n",
    "    master = \"local[2]\",\n",
    "    app_name = \"padding\",\n",
    "    config = sparklyr::spark_config())\n",
    "\n",
    "config <- yaml::yaml.load_file(\"ons-spark/config.yaml\")\n",
    "\n",
    "rescue <- sparklyr::spark_read_parquet(sc, config$rescue_path) %>%\n",
    "    sparklyr::filter(origin_of_call == \"Police\") %>%\n",
    "    dplyr::arrange(date_time_of_call) %>%\n",
    "    sparklyr::select(incident_number, origin_of_call)\n",
    "\n",
    "rescue %>%\n",
    "    head(5) %>%\n",
    "    sparklyr::collect() %>%\n",
    "    print()    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to `lpad()` will most often be either a string or an integer. In this example, `incident_number` is a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- incident_number: string (nullable = true)\n",
      " |-- origin_of_call: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescue.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "pillar::glimpse(rescue)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [`length()`](https://spark.apache.org/docs/latest/api/python//reference/api/pyspark.sql.functions.length.html) to demonstrate that the `incident_number` column is not always the same size:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|incident_no_length|count|\n",
      "+------------------+-----+\n",
      "|                 6|    1|\n",
      "|                 7|    6|\n",
      "|                 8|   57|\n",
      "|                 9|   65|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescue = rescue.withColumn(\"incident_no_length\", F.length(\"incident_number\"))\n",
    "rescue.groupBy(\"incident_no_length\").count().orderBy(\"incident_no_length\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "rescue <- rescue %>%\n",
    "    sparklyr::mutate(incident_no_length = length(incident_number))\n",
    "\n",
    "rescue %>%\n",
    "    dplyr::group_by(incident_no_length, origin_of_call) %>%\n",
    "    dplyr::summarise(count = n()) %>%\n",
    "    head(5) %>%\n",
    "    sparklyr::collect() %>%\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the `incident_number` column to be a string with a fixed width of $9$, with zeros at the start if the length is shorter than this.\n",
    "\n",
    "`lpad()` takes three arguments. The first argument, `col` is the column name, the second, `len` is the fixed width of the string, and the third, `pad`, the value to pad it with if it is too short, often `\"0\"`. The data type returned from `lpad()` will always be a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+------------------+------------------+\n",
      "|incident_number|origin_of_call|incident_no_length|padded_incident_no|\n",
      "+---------------+--------------+------------------+------------------+\n",
      "|         955141|        Police|                 6|         000955141|\n",
      "|        7003121|        Police|                 7|         007003121|\n",
      "|        6311101|        Police|                 7|         006311101|\n",
      "|        5930131|        Police|                 7|         005930131|\n",
      "|        3223101|        Police|                 7|         003223101|\n",
      "+---------------+--------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------------+--------------+------------------+------------------+\n",
      "|incident_number|origin_of_call|incident_no_length|padded_incident_no|\n",
      "+---------------+--------------+------------------+------------------+\n",
      "|      205017101|        Police|                 9|         205017101|\n",
      "|      207037111|        Police|                 9|         207037111|\n",
      "|      135844101|        Police|                 9|         135844101|\n",
      "|      216289101|        Police|                 9|         216289101|\n",
      "|      145879151|        Police|                 9|         145879151|\n",
      "+---------------+--------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescue = rescue.withColumn(\"padded_incident_no\", F.lpad(F.col(\"incident_number\"), 9, \"0\"))\n",
    "rescue.orderBy(\"incident_no_length\").show(5)\n",
    "rescue.orderBy(\"incident_no_length\", ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "rescue <- rescue %>%\n",
    "    sparklyr::mutate(padded_incident_no = lpad(incident_number, 9, \"0\"))\n",
    "\n",
    "rescue %>%\n",
    "    dplyr::arrange(incident_no_length) %>%\n",
    "    head(5) %>%\n",
    "    sparklyr::collect() %>%\n",
    "    print()\n",
    "\n",
    "rescue %>%\n",
    "    dplyr::arrange(desc(incident_no_length)) %>%\n",
    "    head(5) %>%\n",
    "    sparklyr::collect() %>%\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful; if you set the fixed width to be too short you can lose data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+------------------+------------------+----------------+\n",
      "|incident_number|origin_of_call|incident_no_length|padded_incident_no|too_short_inc_no|\n",
      "+---------------+--------------+------------------+------------------+----------------+\n",
      "|      114153091|        Police|                 9|         114153091|             114|\n",
      "|      138096091|        Police|                 9|         138096091|             138|\n",
      "|      110211101|        Police|                 9|         110211101|             110|\n",
      "|      101172091|        Police|                 9|         101172091|             101|\n",
      "|      102278091|        Police|                 9|         102278091|             102|\n",
      "+---------------+--------------+------------------+------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescue = rescue.withColumn(\"too_short_inc_no\", F.lpad(F.col(\"incident_number\"), 3, \"0\"))\n",
    "rescue.orderBy(\"incident_no_length\", ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "rescue <- rescue %>%\n",
    "    sparklyr::mutate(too_short_inc_no = lpad(incident_number, 3, \"0\"))\n",
    "\n",
    "rescue %>%\n",
    "    dplyr::arrange(desc(incident_no_length)) %>%\n",
    "    head(5) %>%\n",
    "    sparklyr::collect() %>%\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have values other than zero for the last argument and they do not have to be width 1, although there are fewer use cases for this. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+------------------+------------------+----------------+--------------+\n",
      "|incident_number|origin_of_call|incident_no_length|padded_incident_no|too_short_inc_no| silly_example|\n",
      "+---------------+--------------+------------------+------------------+----------------+--------------+\n",
      "|         955141|        Police|                 6|         000955141|             955|xyzxyzxy955141|\n",
      "|        7003121|        Police|                 7|         007003121|             700|xyzxyzx7003121|\n",
      "|        6311101|        Police|                 7|         006311101|             631|xyzxyzx6311101|\n",
      "|        5930131|        Police|                 7|         005930131|             593|xyzxyzx5930131|\n",
      "|        3223101|        Police|                 7|         003223101|             322|xyzxyzx3223101|\n",
      "+---------------+--------------+------------------+------------------+----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescue = rescue.withColumn(\"silly_example\", F.lpad(F.col(\"incident_number\"), 14, \"xyz\"))\n",
    "rescue.orderBy(\"incident_no_length\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "rescue <- rescue %>%\n",
    "    sparklyr::mutate(silly_example = lpad(incident_number, 14, \"xyz\"))\n",
    "    \n",
    "rescue %>%\n",
    "    dplyr::arrange(incident_no_length) %>%\n",
    "    head(5) %>%\n",
    "    sparklyr::collect() %>%\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding on the right: `rpad()`\n",
    "\n",
    "There is also a similar function, [`F.rpad()`](https://spark.apache.org/docs/latest/api/python//reference/api/pyspark.sql.functions.rpad.html), that works in the same way with identical arguments, just padding to the right instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|incident_number|right_padded_inc_no|\n",
      "+---------------+-------------------+\n",
      "|      146647151|          146647151|\n",
      "|       66969111|          669691110|\n",
      "|      103407111|          103407111|\n",
      "|      137525091|          137525091|\n",
      "|      158794091|          158794091|\n",
      "+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescue = rescue.withColumn(\"right_padded_inc_no\", F.rpad(F.col(\"incident_number\"), 9, \"0\"))\n",
    "rescue.select(\"incident_number\", \"right_padded_inc_no\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "rescue <- rescue %>%\n",
    "    sparklyr::mutate(right_padded_inc_no = rpad(incident_number, 9, \"0\"))\n",
    "    \n",
    "rescue %>%\n",
    "    dplyr::arrange(right_padded_inc_no) %>%\n",
    "    sparklyr::select(incident_number, right_padded_inc_no) %>%\n",
    "    head(5) %>%\n",
    "    sparklyr::collect() %>%\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Resources\n",
    "\n",
    "PySpark Documentation:\n",
    "- [`F.lpad()`](https://spark.apache.org/docs/latest/api/python//reference/api/pyspark.sql.functions.lpad.html)\n",
    "- [`F.rpad()`](https://spark.apache.org/docs/latest/api/python//reference/api/pyspark.sql.functions.rpad.html)\n",
    "- [`F.length()`](https://spark.apache.org/docs/latest/api/python//reference/api/pyspark.sql.functions.length.html)\n",
    "\n",
    "Spark SQL Documentation:\n",
    "- [`lpad`](https://spark.apache.org/docs/latest/api/sql/index.html#lpad)\n",
    "- [`rpad`](https://spark.apache.org/docs/latest/api/sql/index.html#rpad)\n",
    "- [`length`](https://spark.apache.org/docs/latest/api/sql/index.html#length)\n",
    "\n",
    "Spark in ONS material:\n",
    "- Spark SQL Functions in sparklyr: note that `lpad`/`rpad` are inherited directly from Spark SQL and need to be used inside `mutate()`, rather than imported from the sparklyr package as standalone functions\n",
    "\n",
    "Other links:\n",
    "- [ONS Standard Industrial Classification (SIC)](https://www.ons.gov.uk/methodology/classificationsandstandards/ukstandardindustrialclassificationofeconomicactivities/uksic2007)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
