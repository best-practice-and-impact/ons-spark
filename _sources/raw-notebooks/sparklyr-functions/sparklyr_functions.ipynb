{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db4fd63",
   "metadata": {},
   "source": [
    "## Using Spark functions in sparklyr\n",
    "\n",
    "The sparklyr package allows you to use the dplyr style functions when working on the cluster with sparklyr DataFrames. The key difference to working with tibbles or base R DataFrames is that the Spark cluster will be used for processing, rather than the CDSW session. This means that you can handle much larger data.\n",
    "\n",
    "You can also make use of [Spark functions](https://spark.apache.org/docs/latest/api/sql/index.html) directly when using sparklyr. To do this, wrap them in a relevant `dplyr` command, for instance, `mutate()` or `filter()`. Note that these functions are not part of an actual R package and so you can't prefix them with the package name with `::`.\n",
    "\n",
    "There are a large number of Spark functions and the authors of this article have not verified them all; versioning and implementation differences mean that not all might be available.\n",
    "\n",
    "Remember: you can't use these functions on a tibble or base R DataFrame as R cannot interpret them. They can only be processed on the Spark cluster.\n",
    "\n",
    "### Selected practical examples\n",
    "\n",
    "Set up a Spark session and read the Animal Rescue data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d721363",
   "metadata": {},
   "source": [
    "```r\n",
    "library(sparklyr)\n",
    "library(dplyr)\n",
    "\n",
    "sc <- sparklyr::spark_connect(\n",
    "    master = \"local[2]\",\n",
    "    app_name = \"sparklyr-functions\",\n",
    "    config = sparklyr::spark_config())\n",
    "        \n",
    "config <- yaml::yaml.load_file(\"ons-spark/config.yaml\")\n",
    "\n",
    "rescue <- sparklyr::spark_read_parquet(sc, config$rescue_path) %>%\n",
    "    sparklyr::select(date_time_of_call, animal_group, property_category)\n",
    "    \n",
    "pillar::glimpse(rescue)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae62ae4",
   "metadata": {},
   "source": [
    "#### Cast to date: `to_date()`\n",
    "\n",
    "`to_date()` changes the column type to date with the chosen format. This must be wrapped in a valid `dplyr` command, such as `mutate()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf75aba9",
   "metadata": {},
   "source": [
    "```r\n",
    "rescue <- rescue %>% \n",
    "    sparklyr::mutate(date_of_call = to_date(date_time_of_call, \"dd/MM/yyyy\"))\n",
    "\n",
    "rescue %>%\n",
    "    sparklyr::select(date_time_of_call, date_of_call) %>%\n",
    "    head(5) %>%\n",
    "    sparklyr::collect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda783cb",
   "metadata": {},
   "source": [
    "#### Capitalise first letter of each word: `initcap()`\n",
    "\n",
    "`initcap()` capitalises the first letter of each word, and can be useful when data cleansing.\n",
    "\n",
    "In the Animal Rescue data the values in the `animal_group` column do not always begin with a capital letter. In this example, `initcap()` can be combined with `filter()` to return all cats, regardless of case:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f10517b",
   "metadata": {},
   "source": [
    "```r\n",
    "cats <- rescue %>% sparklyr::filter(initcap(animal_group) == \"Cat\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da366fd2",
   "metadata": {},
   "source": [
    "Show that both `\"cat\"` and `\"Cat\"` are included in this DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f82e5",
   "metadata": {},
   "source": [
    "```r\n",
    "cats %>%\n",
    "    dplyr::group_by(animal_group) %>%\n",
    "    dplyr::summarise(n())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec85df3",
   "metadata": {},
   "source": [
    "#### `concat_ws()`: a Spark version of `paste()`\n",
    "\n",
    "`concat_ws()` works in a similar way to the base R function `paste()`; the separator is the first argument:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c51397a",
   "metadata": {},
   "source": [
    "```r\n",
    "rescue <- rescue %>% sparklyr::mutate(animal_property = concat_ws(\": \", animal_group, property_category))\n",
    "\n",
    "rescue %>%\n",
    "    sparklyr::select(animal_group, property_category, animal_property) %>%\n",
    "    head(5) %>%\n",
    "    sparklyr::collect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7d883",
   "metadata": {},
   "source": [
    "## Further Resources\n",
    "\n",
    "Spark SQL Documentation:\n",
    "- [`to_date`](https://spark.apache.org/docs/latest/api/sql/index.html#to_date)\n",
    "- [`initcap`](https://spark.apache.org/docs/latest/api/sql/index.html#initcap)\n",
    "- [`concat_ws`](https://spark.apache.org/docs/latest/api/sql/index.html#concat_ws)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
