{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alice White python function \n",
    "\n",
    "```Python\n",
    "def stratified_random_sample(sampling_frame, strata, unit, i):\n",
    "    random.seed(i)\n",
    "    sampling_frame = sampling_frame.withColumn('random_number',f.rand())\n",
    "\n",
    "    window_spec = Window.partitionBy(strata).orderBy(f.col('random_number'))\n",
    "\n",
    "    sampling_frame = (sampling_frame.withColumn(f'{unit}_sampled{i}',\n",
    "                                               f.when((f.col('random_number_rank') <= f.col('required_ss')), 1)\n",
    "                                               .otherwise(9)))\n",
    "    sampling_frame = sampling_frame.drop('random_number', 'random_number_rank')\n",
    "\n",
    "    return sampling_frame\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"sampling\").getOrCreate()\n",
    "\n",
    "with open(\"../../../config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "#rescue_path = \n",
    "rescue_path = \"../../data/animal_rescue.csv\"\n",
    "rescue = spark.read.csv(rescue_path, header=True, inferSchema=True)\n",
    "rescue = rescue.withColumnRenamed('AnimalGroupParent','animal_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+-------+-------+---------------+---------+--------------+---------------------+-----------------------+--------------------+-----------+------------------+--------------------+-----------------+--------------------------+--------------------+---------+--------------------+-----------+----------+-------------+----------------+---------+----------+---------------+----------------+\n",
      "|IncidentNumber|  DateTimeOfCall|CalYear|FinYear| TypeOfIncident|PumpCount|PumpHoursTotal|HourlyNotionalCost(£)|IncidentNotionalCost(£)|    FinalDescription|animal_type|      OriginofCall|        PropertyType| PropertyCategory|SpecialServiceTypeCategory|  SpecialServiceType| WardCode|                Ward|BoroughCode|   Borough|StnGroundName|PostcodeDistrict|Easting_m|Northing_m|Easting_rounded|Northing_rounded|\n",
      "+--------------+----------------+-------+-------+---------------+---------+--------------+---------------------+-----------------------+--------------------+-----------+------------------+--------------------+-----------------+--------------------------+--------------------+---------+--------------------+-----------+----------+-------------+----------------+---------+----------+---------------+----------------+\n",
      "|        139091|01/01/2009 03:01|   2009|2008/09|Special Service|      1.0|           2.0|                  255|                  510.0|DOG WITH JAW TRAP...|        Dog|Person (land line)|House - single oc...|         Dwelling|      Other animal assi...|Animal assistance...|E05011467|Crystal Palace & ...|  E09000008|   Croydon|      Norbury|            SE19|     null|      null|         532350|          170050|\n",
      "|        275091|01/01/2009 08:51|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|ASSIST RSPCA WITH...|        Fox|Person (land line)|            Railings|Outdoor Structure|      Other animal assi...|Animal assistance...|E05000169|            Woodside|  E09000008|   Croydon|     Woodside|            SE25| 534785.0|  167546.0|         534750|          167550|\n",
      "|       2075091|04/01/2009 10:07|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|DOG CAUGHT IN DRA...|        Dog|   Person (mobile)|      Pipe or drain |Outdoor Structure|      Animal rescue fro...|Animal rescue fro...|E05000558|  Carshalton Central|  E09000029|    Sutton|   Wallington|             SM5| 528041.0|  164923.0|         528050|          164950|\n",
      "|       2872091|05/01/2009 12:27|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|HORSE TRAPPED IN ...|      Horse|   Person (mobile)|Intensive Farming...|  Non Residential|      Animal rescue fro...|Animal rescue fro...|E05000330|           Harefield|  E09000017|Hillingdon|      Ruislip|             UB9| 504689.0|  190685.0|         504650|          190650|\n",
      "|       3553091|06/01/2009 15:23|   2009|2008/09|Special Service|      1.0|           1.0|                  255|                  255.0|RABBIT TRAPPED UN...|     Rabbit|   Person (mobile)|House - single oc...|         Dwelling|      Other animal assi...|Animal assistance...|E05000310|            Gooshays|  E09000016|  Havering|  Harold Hill|             RM3|     null|      null|         554650|          192350|\n",
      "+--------------+----------------+-------+-------+---------------+---------+--------------+---------------------+-----------------------+--------------------+-----------+------------------+--------------------+-----------------+--------------------------+--------------------+---------+--------------------+-----------+----------+-------------+----------------+---------+----------+---------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescue.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraction = 0.1\n",
    "row_count = round(rescue.count() * fraction)\n",
    "row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescue.withColumn(\"rand_no\", F.rand()).orderBy(\"rand_no\").limit(row_count).drop(\"rand_no\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find a strata:\n",
    "What is a reasonable strata to sample by?\n",
    "Alex used animal type-This could work\n",
    "How could we generalise this so that it can work for any number of strata, dictionary?\n",
    "\n",
    "Check the github code for stratified sampling in pyspark, one input variable is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|animal_type|count|\n",
      "+-----------+-----+\n",
      "|        Cat| 2909|\n",
      "|       Bird| 1100|\n",
      "|        Dog| 1008|\n",
      "|      Other|  643|\n",
      "|        Fox|  238|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rescue.groupBy('animal_type').agg(F.count('animal_type').alias('count')).sort('count',ascending = False).show()\n",
    "\n",
    "# strata_dict = rescue.select('animal_type').distinct().collect()\n",
    "restructured = rescue.withColumn('animal_type',F.when(F.col('animal_type') == 'Cat','Cat')\n",
    "                                                .when(F.col('animal_type') == 'Bird','Bird')\n",
    "                                                .when(F.col('animal_type') == 'Dog','Dog')\n",
    "                                                .when(F.col('animal_type') == 'Fox','Fox')\n",
    "                                                .otherwise('Other'))\n",
    "restructured.groupBy('animal_type').agg(F.count('animal_type').alias('count')).sort('count',ascending = False).show()\n",
    "\n",
    "restructured = restructured.withColumn('sample_size',F.when(F.col('animal_type') == 'Cat',20)\n",
    "                                                .when(F.col('animal_type') == 'Bird',15)\n",
    "                                                .when(F.col('animal_type') == 'Dog',10)\n",
    "                                                .when(F.col('animal_type') == 'Fox',2)\n",
    "                                                .otherwise(5))\n",
    "# restructured.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "restructured = restructured.withColumn('random_number',F.rand())\n",
    "window_spec = Window.partitionBy('animal_type').orderBy('random_number')\n",
    "restructured = restructured.withColumn(\"strata_rank\",F.rank().over(Window.partitionBy('animal_type').orderBy('random_number')))\n",
    "\n",
    "restructured = (restructured.withColumn('sampled',F.when((F.col('strata_rank') <= F.col('sample_size')), 1)\n",
    "                                    .otherwise(0)))\n",
    "\n",
    "sample = restructured.filter(F.col('sampled') == 1)\n",
    "\n",
    "# restructured.filter(F.col('strata_rank') <= F.col('required_ss'))\n",
    "# sampling_frame = (restructured.withColumn('sampled',\n",
    "#                                                f.when((f.col('random_number_rank') <= f.col('required_ss')), 1)\n",
    "#                                                .otherwise(9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+\n",
      "|animal_type|sample_size|count|\n",
      "+-----------+-----------+-----+\n",
      "|        Cat|         20|   20|\n",
      "|       Bird|         15|   15|\n",
      "|        Dog|         10|   10|\n",
      "|      Other|          5|    5|\n",
      "|        Fox|          2|    2|\n",
      "+-----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample.groupBy('animal_type','sample_size').agg(F.count('animal_type').alias('count')).sort('count',ascending = False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cat': 100, 'Dog': 20, 'Bird': 15, 'Fox': 49, 'Other': 0}\n",
      "+-----------+-----+\n",
      "|animal_type|count|\n",
      "+-----------+-----+\n",
      "|        Cat| 2909|\n",
      "|       Bird| 1100|\n",
      "|        Dog| 1008|\n",
      "|      Other|  643|\n",
      "|        Fox|  238|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rescue.groupBy('animal_type').agg(F.count('animal_type').alias('count')).sort('count',ascending = False).show()\n",
    "\n",
    "# strata_dict = rescue.select('animal_type').distinct().collect()\n",
    "strata_dict = {'Cat':100, 'Dog':20,'Bird':15, 'Fox': 49,'Other':0}\n",
    "print(strata_dict)\n",
    "restructured = rescue.withColumn('animal_type',F.when(F.col('animal_type') == 'Cat','Cat')\n",
    "                                                .when(F.col('animal_type') == 'Bird','Bird')\n",
    "                                                .when(F.col('animal_type') == 'Dog','Dog')\n",
    "                                                .when(F.col('animal_type') == 'Fox','Fox')\n",
    "                                                .otherwise('Other'))\n",
    "\n",
    "restructured.groupBy('animal_type').agg(F.count('animal_type').alias('count')).sort('count',ascending = False).show()\n",
    "\n",
    "# restructured = restructured.withColumn('sample_size',F.when(F.col('animal_type') == 'Cat',20)\n",
    "#                                                 .when(F.col('animal_type') == 'Bird',15)\n",
    "#                                                 .when(F.col('animal_type') == 'Dog',10)\n",
    "#                                                 .when(F.col('animal_type') == 'Fox',2)\n",
    "#                                                 .otherwise(5))\n",
    "# restructured.show()\n",
    "\n",
    "# Chain is an external package from itertools\n",
    "from itertools import chain\n",
    "mapping_expr = F.create_map([F.lit(x) for x in chain(*strata_dict.items())]) \n",
    "restructured = restructured.withColumn(\"sample_size\", \n",
    "              mapping_expr[F.col(\"animal_type\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "restructured = restructured.withColumn('random_number',F.rand())\n",
    "window_spec = Window.partitionBy('animal_type').orderBy('random_number')\n",
    "restructured = restructured.withColumn(\"strata_rank\",F.rank().over(Window.partitionBy('animal_type').orderBy('random_number')))\n",
    "\n",
    "restructured = (restructured.withColumn('sampled',F.when((F.col('strata_rank') <= F.col('sample_size')), 1)\n",
    "                                    .otherwise(0)))\n",
    "\n",
    "sample = restructured.filter(F.col('sampled') == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+\n",
      "|animal_type|sample_size|count|\n",
      "+-----------+-----------+-----+\n",
      "|        Cat|        100|  100|\n",
      "|        Fox|         49|   49|\n",
      "|        Dog|         20|   20|\n",
      "|       Bird|         15|   15|\n",
      "+-----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample.groupBy('animal_type','sample_size').agg(F.count('animal_type').alias('count')).sort('count',ascending = False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning an exact sample per strata\n",
    "If you are wishing to use a form of stratified sampling where an exact number of samples are needed per strata, this can be implemented using a window function. More details and examples using window functions can be found in the [window function page](https://best-practice-and-impact.github.io/ons-spark/spark-functions/window-functions.html). We found that the simplest way of returning an exact number of samples per strata is to create a column for each strata with the number of samples required. To simplify this example we have reduced the number of animals in the `animal_type` column to 5: Bird; Cat; Dog; Fox; and Other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|animal_type|count|\n",
      "+-----------+-----+\n",
      "|        Cat| 2909|\n",
      "|       Bird| 1100|\n",
      "|        Dog| 1008|\n",
      "|      Other|  643|\n",
      "|        Fox|  238|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing to simplify the number of animals in the `animal_type` column\n",
    "simplified_animal_types = rescue.withColumn('animal_type',F.when(~F.col('animal_type').isin(['Cat','Bird','Dog','Fox']),'Other')\n",
    "                                              .otherwise(F.col('animal_type')))\n",
    "\n",
    "# Counting the number of animals in each group\n",
    "simplified_animal_types.groupBy('animal_type').agg(F.count('animal_type').alias('count')).sort('count',ascending = False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "# Preprocessing to simplify the number of animals in the `animal_type` column\n",
    "simplified_animal_types <-rescue %>% sparklyr::mutate(animal_type = case_when(!animal_group %in% c('Cat','Bird','Dog','Fox') ~ 'Other',\n",
    "                                                       .default = animal_group))\n",
    "\n",
    "# Counting the number of animals in each group\n",
    "simplified_animal_types %>%\n",
    "        dplyr::group_by(animal_type) %>%\n",
    "        dplyr::count(animal_type,name = 'row_count') %>%\n",
    "        sdf_sort('animal_type')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create our column which has the required number of samples per strata. This can be done simply using `F.when` statements, however this may not be viable when you are sampling across a lot of variables as this would require a `when` statement for each distinct value. A work around to this can be done using UDFs or a mapping function however, the efficiency of this has not been assessed. We will also give each row a randomly generated number from a uniform distribution which is used to order the rows per strata.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample_size column for each strata \n",
    "simplified_animal_types = (simplified_animal_types.withColumn('sample_size',F.when(F.col('animal_type') == 'Bird',15)\n",
    "                                                .when(F.col('animal_type') == 'Cat',20)\n",
    "                                                .when(F.col('animal_type') == 'Dog',10)\n",
    "                                                .when(F.col('animal_type') == 'Fox',2)\n",
    "                                                .when(F.col('animal_type') == 'Other',5)\n",
    "                                                .otherwise(0))\n",
    "                                                .withColumn('random_number',F.rand())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "simplified_animal_types <- simplified_animal_types %>% \n",
    "                            sparklyr::mutate(sample_size = case_when(\n",
    "                                            animal_type == 'Bird' ~ 15,\n",
    "                                            animal_type == 'Cat' ~ 20,\n",
    "                                            animal_type == 'Dog' ~ 10,\n",
    "                                            animal_type == 'Fox' ~ 2,\n",
    "                                            animal_type == 'Other' ~ 5,\n",
    "                                            .default = 0)) %>%\n",
    "                            sparklyr::mutate(random_number = rand())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a window function, we create a column `strata_rank` which will rank each of the random numbers from `random_number` column in order. From this, we create a final column `sampled` which will contain a `1` if the ranked value of a random number is less than or equal to the required sample size for each strata. Otherwise it will contain a `0`. To obtain our final sample, we simply filter on the `sampled` column and extract all rows where this equals `1`. We can check the number of entries per sample by using a aggregating function (`agg`) and a `groupBy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+\n",
      "|animal_type|sample_size|count|\n",
      "+-----------+-----------+-----+\n",
      "|        Cat|         20|   20|\n",
      "|       Bird|         15|   15|\n",
      "|        Dog|         10|   10|\n",
      "|      Other|          5|    5|\n",
      "|        Fox|          2|    2|\n",
      "+-----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "# use Window function to rank based on size of random number\n",
    "simplified_animal_types = simplified_animal_types.withColumn(\"strata_rank\",F.rank().over(Window.partitionBy('animal_type').orderBy('random_number')))\n",
    "# Set sampled column to 1 if rank is lower than sample_size, 0 otherwise\n",
    "simplified_animal_types = (simplified_animal_types.withColumn('sampled',F.when((F.col('strata_rank') <= F.col('sample_size')), 1)\n",
    "                                    .otherwise(0)))\n",
    " \n",
    "# Take our sample by filtering where `sampled` is 1\n",
    "sample = simplified_animal_types.filter(F.col('sampled') == 1)\n",
    "# Count rows in sample\n",
    "sample.groupBy('animal_type','sample_size').agg(F.count('animal_type').alias('count')).sort('count',ascending = False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "\n",
    "simplified_animal_types <- simplified_animal_types %>% \n",
    "              dplyr::group_by(animal_type) %>%\n",
    "              sparklyr::mutate(strata_rank = rank(desc(random_number))) %>%\n",
    "              dplyr::ungroup()\n",
    "\n",
    "simplified_animal_types <- simplified_animal_types %>% sparklyr::mutate(sampled = case_when(\n",
    "              strata_rank <= sample_size ~ 1,\n",
    "              .default = 0))\n",
    "\n",
    "sampled <- simplified_animal_types %>% sparklyr::filter(sampled == 1)\n",
    "\n",
    "sampled %>%\n",
    "        dplyr::group_by(animal_type,sample_size) %>%\n",
    "        dplyr::count(animal_type,name = 'row_count') %>%\n",
    "        sdf_sort('animal_type')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be pointed out that using a Window function and partitioning by a strata can lead to issues in datasets which have large skews. If one strata is significantly larger than others, this could also cause memory overflow issues on the executors resulting in spark sessions crashing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying the required sample column\n",
    "For pyspark, we can simplify the creation of the required sample column by using dictionaries. This does require the use of the `itertools` package and `chain` function to map the values within the column. A similar work around may also be possible in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+\n",
      "|animal_type|sample_size|count|\n",
      "+-----------+-----------+-----+\n",
      "|        Cat|         20| 2909|\n",
      "|       Bird|         15| 1100|\n",
      "|        Dog|         10| 1008|\n",
      "|      Other|          5|  643|\n",
      "|        Fox|          2|  238|\n",
      "+-----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "# Create dictionary\n",
    "strata_dictionary = {'Bird':15, 'Cat':20, 'Dog':10, 'Fox': 2, 'Other':5}\n",
    "\n",
    "\n",
    "mapping_example = rescue.withColumn('animal_type',F.when(~F.col('animal_type').isin(['Cat','Bird','Dog','Fox']),'Other')\n",
    "                                              .otherwise(F.col('animal_type')))\n",
    "\n",
    "mapping_expr = F.create_map([F.lit(x) for x in chain(*strata_dictionary.items())]) \n",
    "mapping_example = mapping_example.withColumn(\"sample_size\", \n",
    "              mapping_expr[F.col(\"animal_type\")])\n",
    "\n",
    "mapping_example.groupBy('animal_type','sample_size').agg(F.count('animal_type').alias('count')).sort('count',ascending = False).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
