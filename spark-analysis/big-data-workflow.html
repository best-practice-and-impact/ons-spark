

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Big data workflow &#8212; Spark at the ONS</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/accessibility.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-95MGHSRD0S"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-95MGHSRD0S');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'spark-analysis/big-data-workflow';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Interpolation in Spark" href="interpolation.html" />
    <link rel="prev" title="Exercises" href="../spark-concepts/exercises.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Spark at the ONS - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Spark at the ONS - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Spark overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../spark-overview/spark-start.html">Getting Started with Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-overview/when-to-use-spark.html">When To Use Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-overview/spark-session-guidance.html">Guidance on Spark Sessions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-overview/example-spark-sessions.html">Example Spark Sessions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-overview/spark-defaults.html">Configuration Hierarchy and <code class="docutils literal notranslate"><span class="pre">spark-defaults.conf</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-overview/data-types.html">Data Types in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-overview/creating-dataframes.html">Creating DataFrames Manually</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-overview/reading-and-writing-data-spark.html">Reading and Writing Data in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-overview/data-storage.html">Data Storage</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to PySpark</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../pyspark-intro/pyspark-intro.html">Introduction to PySpark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pyspark-intro/returning-data.html">Returning Data from Cluster to Driver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pyspark-intro/f-col.html">Reference columns by name: <code class="docutils literal notranslate"><span class="pre">F.col()</span></code></a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to sparklyr</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../sparklyr-intro/sparklyr-intro.html">Introduction to sparklyr</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sparklyr-intro/sparklyr-functions.html">Using Spark functions in sparklyr</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Spark functions</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/union-dataframes-with-different-columns.html">Union two DataFrames with different columns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/padding.html">Add leading zeros with <code class="docutils literal notranslate"><span class="pre">lpad()</span></code></a></li>

<li class="toctree-l1"><a class="reference internal" href="../spark-functions/sampling.html">Sampling: an overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/pivot-tables.html">Pivot tables in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/rounding.html">Rounding differences in Python, R and Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/window-functions.html">Window Functions in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/cross-joins.html">Cross Joins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/arrays.html">Arrays Functions in PySpark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/date-functions.html">Date functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/writing-data.html">Writing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/job-description-notebook.html">Set Spark Job Description</a></li>




<li class="toctree-l1"><a class="reference internal" href="../spark-functions/median.html">Median in Spark</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Understanding and Optimising Spark</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/optimisation-tips.html">Ideas for optimising Spark code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/spark-application-and-ui.html">Spark Application and UI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/groups-not-loops.html">Groups not Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/shuffling.html">Shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/join-concepts.html">Optimising Joins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/salted-joins.html">Salted Joins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/partitions.html">Managing Partitions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/persistence.html">Persisting in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/cache.html">Caching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/checkpoint-staging.html">Checkpoints and Staging Tables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/garbage-collection.html">Garbage Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/df-order.html">Spark DataFrames Are Not Ordered</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/exercises.html">Exercises</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Analysis in Spark</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Big data workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="interpolation.html">Interpolation in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="logistic-regression.html">Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualisation.html">Spark and Visualisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="flags.html">Flags in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="bin-continuous-variable.html">Data binning</a></li>
<li class="toctree-l1"><a class="reference internal" href="cramer_v.html">Calculating Cramér’s V from a Spark DataFrame</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Testing and Debugging</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../testing-debugging/spark-errors.html">Understanding and Handling Spark Errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing-debugging/unit-testing.html">Unit Testing in Spark</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ancillary Topics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ancillary-topics/module-imports.html">Naming Conflicts in Module Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ancillary-topics/pydoop.html">Pydoop: HDFS to pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ancillary-topics/creating-a-SQL-view-in-HDFS.html">Creating a SQL view in HDFS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ancillary-topics/pandas-udfs.html">Pandas UDFs</a></li>
</ul>

        </div>
    </nav></div>
            <div class="bd-sidebar__bottom">
                <!-- To handle the deprecated key -->
                
                <div class="navbar_extra_footer">
                <div>
        <p>Book version 2022.6</p>
    </div>
    
                </div>
                
            </div>
        </div>
        <div id="rtd-footer-container"></div>
    </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/best-practice-and-impact/ons-spark" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/best-practice-and-impact/ons-spark/issues/new?title=Issue%20on%20page%20%2Fspark-analysis/big-data-workflow.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/spark-analysis/big-data-workflow.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Big data workflow</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#general-workflow-and-project-planning">General workflow and project planning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plan-your-analysis">1. Plan your analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#version-control-your-code-using-git-and-apply-rap-good-practice">2. Version control your code using Git and apply RAP good practice</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-code-reviews">3. Use code reviews</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-exploration-and-quality">Data exploration and quality</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#be-aware-of-the-size-of-your-dataset">4. Be aware of the size of your dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reduce-the-size-of-your-dataset-to-use-fewer-compute-resources">5. Reduce the size of your dataset to use fewer compute resources</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#consider-creating-synthetic-data-to-work-on">6. Consider creating synthetic data to work on</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ensure-that-duplicates-are-removed-early-on-in-the-pipeline">7. Ensure that duplicates are removed early on in the pipeline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-big-data-profiling-tools-to-check-data-quality-dimensions-where-possible">8. Use big data profiling tools to check data quality dimensions where possible</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spark-optimisation">Spark optimisation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-spark-functions-where-possible">9. Use Spark functions where possible</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimise-joins">10. Optimise joins</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#consider-data-partitioning">11. Consider data <span class="xref myst">partitioning</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#become-familiar-with-the-spark-ui">12. Become familiar with the Spark UI</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="big-data-workflow">
<h1>Big data workflow<a class="headerlink" href="#big-data-workflow" title="Permalink to this heading">#</a></h1>
<p>Working with big data efficiently presents a major challenge to analysts. In particular, working with large datasets can use large amounts of computational resource, which can be very expensive. Inefficient code or working practices can unnecessarily increase the costs of running your analysis, as well as the time it takes you to run your code. However, there are good practices that can be employed to help minimise costs without sacrificing the quality of your analysis. We have produced this page as a general guide to best practice in working with big data, including tips for general workflow and managing pipeline development, working with samples and subsets of your data, and optimising analysis with Spark.</p>
<section id="general-workflow-and-project-planning">
<h2>General workflow and project planning<a class="headerlink" href="#general-workflow-and-project-planning" title="Permalink to this heading">#</a></h2>
<section id="plan-your-analysis">
<h3>1. Plan your analysis<a class="headerlink" href="#plan-your-analysis" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>A simplified version of the process of developing a new pipeline might look something like this:</p></li>
</ul>
<figure class="align-default" id="bigdatapipelinestages">
<a class="reference internal image-reference" href="../_images/big_data_pipeline_stages.png"><img alt="Diagram showing potentials steps in the process of developing a new big data pipeline." src="../_images/big_data_pipeline_stages.png" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 40 </span><span class="caption-text">Big data pipeline development stages</span><a class="headerlink" href="#bigdatapipelinestages" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Splitting your development into clearly defined stages like this will help with applying some of the tips we have below for keeping your resource use to a minimum. For example, working with small samples or subsets of your data in the EDA, detailed analysis and development phases.</p></li>
</ul>
</section>
<section id="version-control-your-code-using-git-and-apply-rap-good-practice">
<h3>2. <a class="reference external" href="https://gitlab-app-l-01/DAP_CATS/guidance/-/wikis/Git-and-GitLab">Version control</a> your code using Git and apply <a class="reference external" href="https://best-practice-and-impact.github.io/qa-of-code-guidance/intro.html">RAP good practice</a><a class="headerlink" href="#version-control-your-code-using-git-and-apply-rap-good-practice" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>This will make it easier to track what has and hasn’t already been done and for others to understand what your code is doing.</p></li>
<li><p>It is a good idea to agree on a coding plan including code style for the project and Git branch strategies in advance.</p></li>
<li><p>Ensure code is readable, well documented, and follows a logical structure.</p></li>
</ul>
</section>
<section id="use-code-reviews">
<h3>3. Use <a class="reference external" href="https://best-practice-and-impact.github.io/qa-of-code-guidance/peer_review.html">code reviews</a><a class="headerlink" href="#use-code-reviews" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Peer review of code should be used to quality assure and improve your code. A fresh pair of eyes may also be able to spot places where things could be done more efficiently to save computing resource.</p></li>
<li><p>This also helps other members of your team understand the code in detail and can help build capability in the team. It is important to avoid situations where a single developer is relied upon to understand, write and maintain all code as this can cause major problems if that person is away or leaves the team.</p></li>
</ul>
</section>
</section>
<section id="data-exploration-and-quality">
<h2>Data exploration and quality<a class="headerlink" href="#data-exploration-and-quality" title="Permalink to this heading">#</a></h2>
<section id="be-aware-of-the-size-of-your-dataset">
<h3>4. Be aware of the size of your dataset<a class="headerlink" href="#be-aware-of-the-size-of-your-dataset" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>How many rows and columns does your dataset have?</p></li>
<li><p>If the dataset is relatively small (less than a few million rows) use Python or R for analysis instead of PySpark or SparklyR.</p></li>
<li><p>Consider also switching to using Python or R at points in your pipeline where data becomes small due to filtering or aggregation to save resource. See the <a class="reference internal" href="../spark-overview/when-to-use-spark.html"><span class="doc std std-doc">‘When to use Spark’</span></a> page of this book for more information.</p></li>
<li><p>Is the size of the data likely to grow over time? If this is the case you should consider how you will minimise resource use as the amount of data to process increases.</p></li>
</ul>
</section>
<section id="reduce-the-size-of-your-dataset-to-use-fewer-compute-resources">
<h3>5. Reduce the size of your dataset to use fewer compute resources<a class="headerlink" href="#reduce-the-size-of-your-dataset-to-use-fewer-compute-resources" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Generally, it is unnecessary and not good practice to carry out the majority of the analysis stages outlined in the figure above on a full dataset, especially if it is very large.</p></li>
<li><p>Keep the size of your data in the EDA, detailed analysis and development stages as small as possible to conserve resource.</p></li>
<li><p>Consider <a class="reference internal" href="../spark-functions/sampling.html"><span class="doc std std-doc">taking samples of your data</span></a>, especially in the EDA phase.</p>
<ul>
<li><p>Use a simple <a class="reference external" href="https://www.calculator.net/sample-size-calculator.html">sample size calculator</a> to estimate the size of the sample to take.</p></li>
<li><p>Ideally, you should take a sample small enough that you can use Python or R for analysis instead of PySpark/SparklyR.</p></li>
<li><p>You can validate your sample by comparing descriptive statistics to the full dataset.</p></li>
</ul>
</li>
<li><p>Aggregate data where possible.</p>
<ul>
<li><p>This can be done in any stage of analysis and may even form part of your regular production pipeline.</p></li>
<li><p>You can also use aggregation to help find edge cases that might not be captured by sampling your data. This can be particularly useful in the EDA phase to ensure that these extreme cases are not missed in the development of your pipeline.</p></li>
</ul>
</li>
<li><p>Consider what data you really need and filter this out as early as possible to reduce the size of your data.</p></li>
</ul>
</section>
<section id="consider-creating-synthetic-data-to-work-on">
<h3>6. Consider creating synthetic data to work on<a class="headerlink" href="#consider-creating-synthetic-data-to-work-on" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Create minimal size dummy data containing edge cases to work with in the development phase.</p></li>
<li><p>The <a class="reference external" href="https://faker.readthedocs.io/en/master/">Faker</a> package for Python and <a class="reference external" href="https://rdrr.io/cran/fakeR/src/R/fakeR.R">fakeR</a> package for R can be used to generate synthetic data for you to use.</p></li>
<li><p>Synthetic datasets can also be used for testing or peer reviewing code to help QA either code or analysis.</p></li>
</ul>
<p>The diagram below has suggestions for where taking samples, subsets or creating synthetic data may be appropriate at each stage in your pipeline development.</p>
<figure class="align-default" id="bigdatapipelinedatasize">
<a class="reference internal image-reference" href="../_images/big_data_pipeline_datasize.png"><img alt="A diagram showing rough guidelines for the size of data to use at each phase of development for your pipeline." src="../_images/big_data_pipeline_datasize.png" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 41 </span><span class="caption-text">Using samples/subsets or synthetic data in your pipeline development</span><a class="headerlink" href="#bigdatapipelinedatasize" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="ensure-that-duplicates-are-removed-early-on-in-the-pipeline">
<h3>7. Ensure that duplicates are removed early on in the pipeline<a class="headerlink" href="#ensure-that-duplicates-are-removed-early-on-in-the-pipeline" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>This can help reduce your data size early on.</p></li>
<li><p>Make sure your code does not create any duplicates e.g. when joining data sources together.</p></li>
</ul>
</section>
<section id="use-big-data-profiling-tools-to-check-data-quality-dimensions-where-possible">
<h3>8. Use big data profiling tools to check <a class="reference external" href="https://www.gov.uk/government/publications/the-government-data-quality-framework/the-government-data-quality-framework#Data-quality-dimensions">data quality dimensions</a> where possible<a class="headerlink" href="#use-big-data-profiling-tools-to-check-data-quality-dimensions-where-possible" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://aws.amazon.com/blogs/big-data/testing-data-quality-at-scale-with-pydeequ/">PyDeequ</a> or <a class="reference external" href="https://greatexpectations.io/">Great Expectations</a> are useful profiling tools that can be used with PySpark.</p></li>
<li><p>We are not currently aware of any similar profiling packages that are compatible with SparklyR. As a result, if you are an R user, you will need to create code to examine your data quality dimensions yourself. We recommend that you consider the other tips in this guide to help minimise your resource use when doing so.</p></li>
</ul>
</section>
</section>
<section id="spark-optimisation">
<h2>Spark optimisation<a class="headerlink" href="#spark-optimisation" title="Permalink to this heading">#</a></h2>
<p>The following section contains some more advanced suggestions you can consider applying to your pipeline to further optimise your code and minimise resource use. These are most likely to be useful in the ‘Development’ phase of working on your pipeline. Our general tips for Spark optimisation can be found on the <a class="reference internal" href="../spark-concepts/optimisation-tips.html"><span class="doc std std-doc">Ideas for optimising Spark code</span></a> page of the book.</p>
<section id="use-spark-functions-where-possible">
<h3>9. Use Spark functions where possible<a class="headerlink" href="#use-spark-functions-where-possible" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Spark</span> <span class="pre">ML</span></code> functions (<a class="reference external" href="https://spark.apache.org/docs/latest/ml-guide.html">MLlib</a>) contain a range of tools for processing and analysing big data efficiently.</p></li>
<li><p>You can also assemble <code class="docutils literal notranslate"><span class="pre">Spark</span> <span class="pre">ML</span></code> operations into an <a class="reference external" href="https://spark.apache.org/docs/latest/ml-pipeline.html">ML pipeline</a>. These pipelines can be saved and reloaded later to re-run analysis or to apply analysis to a new set of data.</p></li>
<li><p>See the <a class="reference internal" href="logistic-regression.html"><span class="doc std std-doc">Logistic regression</span></a> page of this book for some examples of applying <code class="docutils literal notranslate"><span class="pre">Spark</span> <span class="pre">ML</span></code> functions to a dataset and setting up a <code class="docutils literal notranslate"><span class="pre">Spark</span> <span class="pre">ML</span></code> analysis pipeline.</p></li>
</ul>
</section>
<section id="optimise-joins">
<h3>10. Optimise joins<a class="headerlink" href="#optimise-joins" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Be aware of how the size of your data changes when joining other sources at various points in your pipeline.</p></li>
<li><p>Follow the guidance on the <a class="reference internal" href="../spark-concepts/join-concepts.html"><span class="doc std std-doc">optimising joins</span></a> page of this book.</p></li>
</ul>
</section>
<section id="consider-data-partitioning">
<h3>11. Consider data <a class="reference internal" href="../spark-concepts/partitions.html"><span class="doc std std-doc">partitioning</span></a><a class="headerlink" href="#consider-data-partitioning" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Spark splits data into partitions to perform parallel processing.</p></li>
<li><p>Having too many or too few partitions may cause performance issues in your code.</p></li>
<li><p>There is no set rule for how many partitions your data should have. As a general guide, the optimum size for a partition is often suggested to be 100-200MB and the number of partitions should be a multiple of the number of nodes in your <a class="reference internal" href="../spark-overview/spark-session-guidance.html"><span class="doc std std-doc">Spark session</span></a>.</p></li>
<li><p>It may be beneficial to change how your data is partitioned at various points in your pipeline. For example if your full dataset contains 200 million rows, it may be reasonable to have 200 partitions. However, if later on in your pipeline this data is aggregated so that there are now only around 2 million rows, repartitioning your data on to a smaller number of partitions could improve performance and reduce the compute resource used.</p></li>
<li><p>Aim to make sure data is kept in roughly equal partition sizes throughout the pipeline.</p>
<ul>
<li><p>This may also involve repartitioning your data at appropriate points due to <span class="xref myst">skewed data</span></p></li>
<li><p>Identifying variables in your data that are skewed during the EDA phase of your pipeline development may help in avoiding or identifying this issue later in the development stage.</p></li>
</ul>
</li>
<li><p>Be aware of the difference between <a class="reference internal" href="../spark-concepts/shuffling.html"><span class="doc std std-doc"><em>narrow</em> and <em>wide</em> transformations</span></a> in Spark and how <em>wide</em> transformations can increase the number of partitions in your data.</p>
<ul>
<li><p>If you are using Spark 2.X, you may need to repartition after performing such operations or consider changing the <code class="docutils literal notranslate"><span class="pre">spark.sql.shuffle.partitions</span></code> from the default (200) in your <a class="reference internal" href="../spark-overview/spark-defaults.html"><span class="doc std std-doc">Spark config</span></a>.</p></li>
<li><p>If you are using Spark 3.X, ensure <a class="reference external" href="https://spark.apache.org/docs/latest/sql-performance-tuning.html#adaptive-query-execution">Adaptive Query Excution (AQE)</a> is switched on by setting <code class="docutils literal notranslate"><span class="pre">spark.sql.adaptive.enabled</span></code> to <code class="docutils literal notranslate"><span class="pre">true</span></code> in your <a class="reference internal" href="../spark-overview/spark-defaults.html"><span class="doc std std-doc">Spark config</span></a>. This will automatically coalesce post-shuffle partitions.</p></li>
</ul>
</li>
</ul>
</section>
<section id="become-familiar-with-the-spark-ui">
<h3>12. Become familiar with the Spark UI<a class="headerlink" href="#become-familiar-with-the-spark-ui" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The <a class="reference internal" href="../spark-concepts/spark-application-and-ui.html"><span class="doc std std-doc">Spark UI</span></a> is used to monitor the status and resource consumption of your Spark cluster and can be a useful tool for troubleshooting slow Spark code.</p></li>
<li><p>Check the size of the execution plan regularly</p>
<ul>
<li><p>Do this either by examining the DAG (Directed Acyclic Graph) in the Spark UI or by using <code class="docutils literal notranslate"><span class="pre">df.explain()</span></code>/<code class="docutils literal notranslate"><span class="pre">explain(df)</span></code> in PySpark/SparklyR.</p></li>
<li><p>Overly long execution plans can cause performance issues.</p></li>
<li><p>Consider using <a class="reference internal" href="../spark-concepts/checkpoint-staging.html"><span class="doc std std-doc">checkpoints and staging tables</span></a> at appropriate points in your code to break the lineage in these cases.</p></li>
</ul>
</li>
</ul>
<p>This is not an exhaustive list and not all of these tips will necessarily be applicable to every pipeline. But in general, having a good plan in place for your analysis, keeping data as small as possible during development, and improving your understanding of Spark can all help to minimise resource use when working with big data.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./spark-analysis"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../spark-concepts/exercises.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Exercises</p>
      </div>
    </a>
    <a class="right-next"
       href="interpolation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Interpolation in Spark</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#general-workflow-and-project-planning">General workflow and project planning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plan-your-analysis">1. Plan your analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#version-control-your-code-using-git-and-apply-rap-good-practice">2. Version control your code using Git and apply RAP good practice</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-code-reviews">3. Use code reviews</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-exploration-and-quality">Data exploration and quality</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#be-aware-of-the-size-of-your-dataset">4. Be aware of the size of your dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reduce-the-size-of-your-dataset-to-use-fewer-compute-resources">5. Reduce the size of your dataset to use fewer compute resources</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#consider-creating-synthetic-data-to-work-on">6. Consider creating synthetic data to work on</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ensure-that-duplicates-are-removed-early-on-in-the-pipeline">7. Ensure that duplicates are removed early on in the pipeline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-big-data-profiling-tools-to-check-data-quality-dimensions-where-possible">8. Use big data profiling tools to check data quality dimensions where possible</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spark-optimisation">Spark optimisation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-spark-functions-where-possible">9. Use Spark functions where possible</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimise-joins">10. Optimise joins</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#consider-data-partitioning">11. Consider data <span class="xref myst">partitioning</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#become-familiar-with-the-spark-ui">12. Become familiar with the Spark UI</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Analysis Standards and Pipelines in Quality and Improvement, Office for National Statistics
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>