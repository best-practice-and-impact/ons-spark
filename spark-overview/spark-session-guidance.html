

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Guidance on Spark Sessions &#8212; Spark at the ONS</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/accessibility.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/tabs.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-95MGHSRD0S"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-95MGHSRD0S');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'spark-overview/spark-session-guidance';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Example Spark Sessions" href="example-spark-sessions.html" />
    <link rel="prev" title="When To Use Spark" href="when-to-use-spark.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Spark at the ONS - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Spark at the ONS - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Spark overview</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="spark-start.html">Getting Started with Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="when-to-use-spark.html">When To Use Spark</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Guidance on Spark Sessions</a></li>
<li class="toctree-l1"><a class="reference internal" href="example-spark-sessions.html">Example Spark Sessions</a></li>
<li class="toctree-l1"><a class="reference internal" href="spark-defaults.html">Configuration Hierarchy and <code class="docutils literal notranslate"><span class="pre">spark-defaults.conf</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="data-types.html">Data Types in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="creating-dataframes.html">Creating DataFrames Manually</a></li>
<li class="toctree-l1"><a class="reference internal" href="reading-and-writing-data-spark.html">Reading and Writing Data in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-storage.html">Data Storage</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to PySpark</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../pyspark-intro/pyspark-intro.html">Introduction to PySpark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pyspark-intro/returning-data.html">Returning Data from Cluster to Driver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pyspark-intro/f-col.html">Reference columns by name: <code class="docutils literal notranslate"><span class="pre">F.col()</span></code></a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to sparklyr</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../sparklyr-intro/sparklyr-intro.html">Introduction to sparklyr</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sparklyr-intro/sparklyr-functions.html">Using Spark functions in sparklyr</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Spark functions</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/union-dataframes-with-different-columns.html">Union two DataFrames with different columns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/padding.html">Add leading zeros with <code class="docutils literal notranslate"><span class="pre">lpad()</span></code></a></li>

<li class="toctree-l1"><a class="reference internal" href="../spark-functions/sampling.html">Sampling: an overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/pivot-tables.html">Pivot tables in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/rounding.html">Rounding differences in Python, R and Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/window-functions.html">Window Functions in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/cross-joins.html">Cross Joins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/arrays.html">Arrays Functions in PySpark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/date-functions.html">Date functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/writing-data.html">Writing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-functions/job-description-notebook.html">Set Spark Job Description</a></li>




<li class="toctree-l1"><a class="reference internal" href="../spark-functions/median.html">Median in Spark</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Understanding and Optimising Spark</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/optimisation-tips.html">Ideas for optimising Spark code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/spark-application-and-ui.html">Spark Application and UI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/groups-not-loops.html">Groups not Loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/shuffling.html">Shuffling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/join-concepts.html">Optimising Joins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/salted-joins.html">Salted Joins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/partitions.html">Managing Partitions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/persistence.html">Persisting in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/cache.html">Caching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/checkpoint-staging.html">Checkpoints and Staging Tables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/garbage-collection.html">Garbage Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/df-order.html">Spark DataFrames Are Not Ordered</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-concepts/exercises.html">Exercises</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Analysis in Spark</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../spark-analysis/big-data-workflow.html">Big data workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-analysis/interpolation.html">Interpolation in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-analysis/logistic-regression.html">Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-analysis/visualisation.html">Spark and Visualisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-analysis/flags.html">Flags in Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-analysis/bin-continuous-variable.html">Data binning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-analysis/cramer_v.html">Calculating Cramér’s V from a Spark DataFrame</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Testing and Debugging</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../testing-debugging/spark-errors.html">Understanding and Handling Spark Errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing-debugging/unit-testing.html">Unit Testing in Spark</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ancillary Topics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ancillary-topics/module-imports.html">Naming Conflicts in Module Imports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ancillary-topics/pydoop.html">Pydoop: HDFS to pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ancillary-topics/creating-a-SQL-view-in-HDFS.html">Creating a SQL view in HDFS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ancillary-topics/pandas-udfs.html">Pandas UDFs</a></li>
</ul>

        </div>
    </nav></div>
            <div class="bd-sidebar__bottom">
                <!-- To handle the deprecated key -->
                
                <div class="navbar_extra_footer">
                <div>
        <p>Book version 2022.6</p>
    </div>
    
                </div>
                
            </div>
        </div>
        <div id="rtd-footer-container"></div>
    </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/best-practice-and-impact/ons-spark" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/best-practice-and-impact/ons-spark/issues/new?title=Issue%20on%20page%20%2Fspark-overview/spark-session-guidance.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/spark-overview/spark-session-guidance.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Guidance on Spark Sessions</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-for-cluster-mode">Architecture for cluster mode</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-spark-session">Creating a Spark Session</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-default-parameters">Using default parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#specifying-configs">Specifying configs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#config-glossary">Config Glossary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-resource-allocation">Calculating Resource Allocation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resource-allocation">Resource allocation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reserving-resource">Reserving resource</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-resources">Further Resources</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="guidance-on-spark-sessions">
<h1>Guidance on Spark Sessions<a class="headerlink" href="#guidance-on-spark-sessions" title="Permalink to this heading">#</a></h1>
<p>Usually when using Spark we are looking to process large amounts of data and so we connect to a cluster, this is known as <a class="reference external" href="https://spark.apache.org/docs/latest/cluster-overview.html">cluster mode</a>. An alternative is to use local mode, where Spark runs on a single machine such as a personal laptop. The examples in this book use local mode for simplicity and accessibility for others to run the code.</p>
<section id="architecture-for-cluster-mode">
<h2>Architecture for cluster mode<a class="headerlink" href="#architecture-for-cluster-mode" title="Permalink to this heading">#</a></h2>
<p>For detailed information about running Spark in cluster mode, please see the <a class="reference external" href="https://spark.apache.org/docs/latest/cluster-overview.html">official documentation</a>. If ONS staff are looking for more information online, note that our cluster runs on YARN.</p>
<p>Below is a simplified version of the architecture for a brief discussion on how a Spark session is set up. As always in this book, we assume the reader is using Python or R.</p>
<figure class="align-default" id="architecture">
<a class="reference internal image-reference" href="../_images/simple_spark_cluster.PNG"><img alt="Diagram that shows a driver program on an edge node linking to a resource manager and multiple worker nodes containing executors." src="../_images/simple_spark_cluster.PNG" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Simplified Spark cluster running on YARN</span><a class="headerlink" href="#architecture" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Each element in a cluster is referred to as a node. In a Spark cluster, the <em>edge node</em> is where the user interacts with the cluster through the driver program. There is also the aptly named <em>resource manager</em> within this architecture and some <em>worker nodes</em> where the processing of data happens.</p>
<ol class="arabic simple">
<li><p>Our first step is to launch a Python or R instance, which is the driver program running on the edge node.</p></li>
<li><p>Next from within the driver program we import the PySpark/sparklyr package then create a Spark session. Spark will communicate with the resource manager and allocate some resource to our Spark session in the form of executors.</p></li>
<li><p>We then write some Spark instructions in the driver to process some data. These instructions form Spark jobs which are executed by executors on worker nodes within the cluster.</p></li>
<li><p>Finally, any results we have requested are moved back to the edge node for us to view. Remember we cannot view data while it is on an executor.</p></li>
</ol>
<p>One of the great features of Spark is that we are able to scale up our resources to complete more expensive tasks, such as processing lots of data or running some complex algorithm. When we send a complex Spark job to the cluster the resource manager will automatically allocate more executors to help with the
job. It will also shut them down when they are not needed. This process of switching executors on and off is called dynamic allocation.</p>
</section>
<section id="creating-a-spark-session">
<h2>Creating a Spark Session<a class="headerlink" href="#creating-a-spark-session" title="Permalink to this heading">#</a></h2>
<p>There are many options when it comes to creating a Spark session. We recommend using the default parameters when getting started, you can then start adding other parameters when you learn more about how Spark works and how to tune your session to your specific needs.</p>
<p>Remember we should stop the Spark session when we are finished to free up the cluster resource for others. This is often done automatically when we stop our driver program, or you can also do it by running <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.stop.html"><code class="docutils literal notranslate"><span class="pre">spark.stop()</span></code></a>/<a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/spark-connections.html"><code class="docutils literal notranslate"><span class="pre">spark_disconnect()</span></code></a> in Python/R.</p>
</section>
<section id="using-default-parameters">
<h2>Using default parameters<a class="headerlink" href="#using-default-parameters" title="Permalink to this heading">#</a></h2>
<p>As a starting point you can create a Spark session with all the defaults, by leaving the optional properties blank in <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html#pyspark.sql.SparkSession.builder"><code class="docutils literal notranslate"><span class="pre">SparkSession.builder</span></code></a>/<a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/spark-connections.html"><code class="docutils literal notranslate"><span class="pre">spark_connect()</span></code></a>. This is the bare minimum you need to create a Spark session and will work fine in most cases. Note you should give your session a sensible name, here we have called it <code class="docutils literal notranslate"><span class="pre">default-session</span></code>.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-UHl0aG9u" aria-selected="true" class="sphinx-tabs-tab code-tab group-tab" id="tab-0-UHl0aG9u" name="UHl0aG9u" role="tab" tabindex="0">Python</button><button aria-controls="panel-0-Ug==" aria-selected="false" class="sphinx-tabs-tab code-tab group-tab" id="tab-0-Ug==" name="Ug==" role="tab" tabindex="-1">R</button></div><div aria-labelledby="tab-0-UHl0aG9u" class="sphinx-tabs-panel code-tab group-tab" id="panel-0-UHl0aG9u" name="UHl0aG9u" role="tabpanel" tabindex="0"><div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;default-session&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-Ug==" class="sphinx-tabs-panel code-tab group-tab" hidden="true" id="panel-0-Ug==" name="Ug==" role="tabpanel" tabindex="0"><div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">sparklyr</span><span class="p">)</span>

<span class="n">default_config</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">spark_config</span><span class="p">()</span>

<span class="n">sc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">spark_connect</span><span class="p">(</span>
<span class="w">    </span><span class="n">master</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;yarn-client&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">app_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;default-session&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">default_config</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
</section>
<section id="specifying-configs">
<h2>Specifying configs<a class="headerlink" href="#specifying-configs" title="Permalink to this heading">#</a></h2>
<p>When you have a good grasp of how Spark works, you understand what processing needs doing and most importantly you understand the data, you can look to introduce some customised configurations to your Spark session. You can do this using a <span class="xref myst"><code class="docutils literal notranslate"><span class="pre">spark-defaults.conf</span></code> configuration file</span>, or put the properties in the session builder, like this:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-UHl0aG9u" aria-selected="true" class="sphinx-tabs-tab code-tab group-tab" id="tab-1-UHl0aG9u" name="UHl0aG9u" role="tab" tabindex="0">Python</button><button aria-controls="panel-1-Ug==" aria-selected="false" class="sphinx-tabs-tab code-tab group-tab" id="tab-1-Ug==" name="Ug==" role="tab" tabindex="-1">R</button></div><div aria-labelledby="tab-1-UHl0aG9u" class="sphinx-tabs-panel code-tab group-tab" id="panel-1-UHl0aG9u" name="UHl0aG9u" role="tabpanel" tabindex="0"><div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;custom-session&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;&lt;property-name&gt;&quot;</span><span class="p">,</span> <span class="o">&lt;</span><span class="nb">property</span><span class="o">-</span><span class="n">value</span><span class="o">&gt;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-Ug==" class="sphinx-tabs-panel code-tab group-tab" hidden="true" id="panel-1-Ug==" name="Ug==" role="tabpanel" tabindex="0"><div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">config</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">spark_config</span><span class="p">()</span>
<span class="n">config</span><span class="o">$&lt;</span><span class="n">property</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="o">&lt;</span><span class="n">property</span><span class="o">-</span><span class="n">value</span><span class="o">&gt;</span>

<span class="n">sc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">spark_connect</span><span class="p">(</span>
<span class="w">    </span><span class="n">master</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;yarn-client&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">app_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;custom-session&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">config</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
<p>Some of the most popular configs to set are listed and explained in the <span class="xref myst">Config glossary</span> section below. Some example Spark configurations are given in the <a class="reference internal" href="example-spark-sessions.html"><span class="doc std std-doc">Example Spark Sessions</span></a> article.</p>
<p>See the page on <a class="reference internal" href="spark-defaults.html"><span class="doc std std-doc">Configuration Hierarchy and <code class="docutils literal notranslate"><span class="pre">spark-defaults.conf</span></code></span></a> for more details on setting these properties in other ways.</p>
<p>The <a class="reference external" href="https://spark.rstudio.com/guides/connections/">Configuring Spark Connections</a> page of the RStudio documentation gives a good introduction on this topic that builds on the guidance here.</p>
</section>
<section id="config-glossary">
<h2>Config Glossary<a class="headerlink" href="#config-glossary" title="Permalink to this heading">#</a></h2>
<p>Some commonly used Spark and YARN properties are listed in this section.</p>
<p>For more details look at the official documentation for <a class="reference external" href="https://spark.apache.org/docs/latest/configuration.html">Spark configuration</a></p>
<p>ONS runs Spark on YARN, that entails another <a class="reference external" href="https://spark.apache.org/docs/latest/running-on-yarn.html">set of configuration options</a> documented here.</p>
<p>To view all of the parameters, both default and custom, associated with your Spark session use <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.SparkConf.getAll.html"><code class="docutils literal notranslate"><span class="pre">spark.sparkContext.getConf().getAll()</span></code></a>.</p>
<p>Note that <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.SparkContext.html"><code class="docutils literal notranslate"><span class="pre">sparkContext</span></code></a> is created automatically when calling <a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html"><code class="docutils literal notranslate"><span class="pre">SparkSession</span></code></a></p>
<p><em>The values shown in brackets are common default values</em></p>
<p><strong>App Name</strong><br />
<code class="docutils literal notranslate"><span class="pre">.appName()</span></code><br />
The Spark session is often referred to as a Spark application. This option gives your Spark session a meaningful name, which can be used to help others identify the purpose of your app.<br />
You should enter your app name as a string, so within ‘single’ or “double” inverted commas.</p>
<p><strong>Executor Memory</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.executor.memory&quot;,</span> <span class="pre">1g)</span></code><br />
This is the amount of memory per Spark executor. Can be given in mebibytes (m) or gibibytes (g).</p>
<p><strong>Cores</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.executor.cores&quot;,</span> <span class="pre">1)</span></code><br />
This is the number of cores each executor can use.</p>
<p><strong>Executor Memory Overhead</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.yarn.executor.memoryOverhead&quot;,</span> <span class="pre">max(0.1</span> <span class="pre">*</span> <span class="pre">spark.executor.memory,</span> <span class="pre">348m))</span></code><br />
This sets the amount of additional memory allocated per executor for overheads.<br />
The default value is either 0.1 times the executor memory size, or 348MiB, whichever is greater.<br />
You might consider increasing the memory overhead, for example, if you are using User Defined Functions (UDFs) in your PySpark code.</p>
<p><strong>Dynamic Allocation</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.dynamicAllocation.enabled&quot;,</span> <span class="pre">&quot;true&quot;)</span></code><br />
This setting allows your Spark session to scale up or down by automatically adding and removing executors depending on your workload.<br />
In many Spark environments, dynamic allocation is enabled by default.</p>
<p><strong>Max Executors</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.dynamicAllocation.maxExecutors&quot;,</span> <span class="pre">)</span></code><br />
This sets the maximum number of executors that can be used in dynamic allocation. Spark has no default value for maxExecutors.</p>
<p>Also note when specifying this config, Spark will reserve the maxExecutors for you so others cannot access these resources until you
stop your session- even if you don’t need them. See the <span class="xref myst">reserving</span> section of the calculations below for more details.</p>
<p><strong>Shuffle Service</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.shuffle.service.enabled&quot;,</span> <span class="pre">&quot;true&quot;)</span></code><br />
This property helps with processes like switching executors off safely using dynamic allocation by making use of shuffle files.</p>
<p><strong>Hive Support</strong><br />
<code class="docutils literal notranslate"><span class="pre">.enableHiveSupport()</span></code><br />
This property is set by default and should be used if you want to interact with data stored in Hive tables.</p>
<p><strong>Shuffle Partitions</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.sql.shuffle.partitions&quot;,</span> <span class="pre">200)</span></code><br />
Sets the number of partitions to use for a DataFrame after a shuffle. This is a key property to adjust depending on size of the DataFrame, e.g. see <span class="xref myst">Ideas for Optimising Spark</span>.</p>
<p><strong>Console Progress Bars</strong><br />
<code class="docutils literal notranslate"><span class="pre">.config(&quot;spark.ui.showConsoleProgress&quot;,</span> <span class="pre">&quot;true&quot;)</span></code><br />
Setting this property to <code class="docutils literal notranslate"><span class="pre">False</span></code> is a popular one for CDSW 1.6 where outputs are sometimes obscured by the progress bar in the console.</p>
</section>
<section id="calculating-resource-allocation">
<h2>Calculating Resource Allocation<a class="headerlink" href="#calculating-resource-allocation" title="Permalink to this heading">#</a></h2>
<p>Let’s take the large session from the <a class="reference internal" href="example-spark-sessions.html"><span class="doc std std-doc">Example Spark Sessions</span></a> and explain the allocation of resource in more detail.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;large-session&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.executor.memory&quot;</span><span class="p">,</span> <span class="s2">&quot;10g&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.yarn.executor.memoryOverhead&quot;</span><span class="p">,</span> <span class="s2">&quot;1g&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.executor.cores&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.dynamicAllocation.enabled&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.dynamicAllocation.maxExecutors&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.shuffle.service.enabled&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.ui.showConsoleProgress&quot;</span><span class="p">,</span> <span class="s2">&quot;false&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">enableHiveSupport</span><span class="p">()</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="resource-allocation">
<h2>Resource allocation<a class="headerlink" href="#resource-allocation" title="Permalink to this heading">#</a></h2>
<p>When asking <em>how much resource is allocated to this application?</em>, we generally mean how many cores and memory is this application using?</p>
<p><strong>Cores</strong> - We have requested 5 cores per executor using <code class="docutils literal notranslate"><span class="pre">spark.executor.cores</span></code> and 5 executors with <code class="docutils literal notranslate"><span class="pre">spark.dynamicAllocation.maxExecutors</span></code>. The sum is then:</p>
<p>5 cores per executor x 5 executors = 25 cores</p>
<p><strong>Memory</strong> - Using <code class="docutils literal notranslate"><span class="pre">spark.executor.memory</span></code> we requested 10 GiB of memory per executor. Using <code class="docutils literal notranslate"><span class="pre">spark.yarn.executor.memoryOverhead</span></code> we
requested 1 GiB of overhead memory. As before, we requested 5 executors with <code class="docutils literal notranslate"><span class="pre">spark.dynamicAllocation.maxExecutors</span></code>. Now the sum is:</p>
<p>( 10 GiB + 1 GiB ) per executor x 5 executors = 55 GiB of memory</p>
<p>This does not mean we have the full 55 GiB available to process data. The topic of memory management in Spark applications is complex and beyond the scope of this book. Please see the <a class="reference external" href="https://spark.apache.org/docs/3.2.1/tuning.html#memory-management-overview">official documentation</a> for more information.</p>
</section>
<section id="reserving-resource">
<h2>Reserving resource<a class="headerlink" href="#reserving-resource" title="Permalink to this heading">#</a></h2>
<p>An important point to remember about setting the <code class="docutils literal notranslate"><span class="pre">spark.dynamicAllocation.maxExecutors</span></code> option is that <em>although</em> Spark will increase and decrease the number of executors
we use at any point, the <em>maximum resource requested</em> will be reserved for the application.</p>
<p>That means that in the above example Spark will reserve 25 cores and 55 GiB
of memory for this application for the entirety of its duration, no matter if we are only utilising a single executor. This is not an issue here as 25 cores and 55 GiB isn’t
excessive for processing a large DataFrame. However, if <code class="docutils literal notranslate"><span class="pre">spark.dynamicAllocation.maxExecutors</span></code> was set to 500 requests from other users on the same cluster might be rejected and the cluster
would be under significant strain.</p>
</section>
<section id="further-resources">
<h2>Further Resources<a class="headerlink" href="#further-resources" title="Permalink to this heading">#</a></h2>
<p>Spark at the ONS Articles:</p>
<ul class="simple">
<li><p><a class="reference internal" href="example-spark-sessions.html"><span class="doc std std-doc">Example Spark Sessions</span></a></p></li>
<li><p><a class="reference internal" href="spark-defaults.html"><span class="doc std std-doc">Configuration Hierarchy and <code class="docutils literal notranslate"><span class="pre">spark-defaults.conf</span></code></span></a></p></li>
</ul>
<p>PySpark Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html"><code class="docutils literal notranslate"><span class="pre">SparkSession</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html#pyspark.sql.SparkSession.builder"><code class="docutils literal notranslate"><span class="pre">SparkSession.builder</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.stop.html"><code class="docutils literal notranslate"><span class="pre">spark.stop()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.SparkContext.html"><code class="docutils literal notranslate"><span class="pre">spark.sparkContext</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.SparkConf.getAll.html"><code class="docutils literal notranslate"><span class="pre">spark.sparkContext.getConf().getAll()</span></code></a></p></li>
</ul>
<p>sparklyr and tidyverse Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.rstudio.com/packages/sparklyr/latest/reference/spark-connections.html"><code class="docutils literal notranslate"><span class="pre">spark_connect</span></code>/<code class="docutils literal notranslate"><span class="pre">spark_disconnect()</span></code></a></p></li>
<li><p><a class="reference external" href="https://spark.rstudio.com/guides/connections/">Configuring Spark Connections</a></p></li>
</ul>
<p>Spark Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/configuration.html">Spark Configuration</a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/running-on-yarn.html">Running Spark on YARN</a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./spark-overview"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="when-to-use-spark.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">When To Use Spark</p>
      </div>
    </a>
    <a class="right-next"
       href="example-spark-sessions.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Example Spark Sessions</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-for-cluster-mode">Architecture for cluster mode</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-spark-session">Creating a Spark Session</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-default-parameters">Using default parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#specifying-configs">Specifying configs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#config-glossary">Config Glossary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-resource-allocation">Calculating Resource Allocation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resource-allocation">Resource allocation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reserving-resource">Reserving resource</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-resources">Further Resources</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Analysis Standards and Pipelines in Quality and Improvement, Office for National Statistics
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>